# 微服务

整合黑马的springcloud课程和其他的组件学习

# 认识微服务
区分一下单体架构和分布式架构的区别：

+ 单体架构：简单方便，但是高度耦合，扩展性差，适合小型项目
+ 分布式架构：松耦合，扩展性好，但是架构复杂，难度大，适合大型互联网项目

微服务则是一种经过良好架构设计的分布式架构方案。

SpringCloud则是微服务方案的具体实现。

下面项目使用的版本是Hoxton.SR10，对应的SpringBoot版本是2.3.x版本。

**微服务拆分的原则：**

+ 不同的微服务，不要重复开发相同业务
+ 微服务数据独立，不要访问其他的数据库
+ 微服务将自己的业务暴露成接口，供其他微服务调用

以项目cloud-demo为例：

![1725353822014-f884832e-ea13-4310-baca-c88d35d8608a.png](1725353822014-f884832e-ea13-4310-baca-c88d35d8608a-611897.png)

每个微服务都有自己独立的数据库，通过接口进行微服务的互相调用。

需求：order-service中的根据id查询订单业务，要求在查询订单的同时，根据订单中包含的userId查询出用户信息，一起返回

实现：通过注入的RestTemplate调用接口查询uesr-service中的接口，返回数据

```java
public Order queryOrderById(Long orderId) {
    // 1.查询订单
    Order order = orderMapper.findById(orderId);
    // 2.利用RestTemplate发起http请求，查询用户
    // 2.1.url路径
    String url = "http://localhost:8081/user/" + order.getUserId();
    // 2.2.发送http请求，实现远程调用
    User user = restTemplate.getForObject(url, User.class);
    // 3.封装user到Order
    order.setUser(user);
    // 4.返回
    return order;
}
```

服务提供者：一次业务中，被其他微服务调用的服务。（提供接口方）

服务消费者：一次业务中，调用其他微服务的服务。（消费接口）



# Eureka注册中心
如果user-service配置了多个实例，有不同的ip和端口号，那么

+ order-service调用的时候该如何得知user-service的ip和端口号？
+ 调用的时候如何选择？
+ 如何得知user-service是否健康？

这些问题都需要注册中心来解决。

![1725354645089-ec4a41b8-1255-4a14-b2b6-f74ef5bad759.png](1725354645089-ec4a41b8-1255-4a14-b2b6-f74ef5bad759-280082.png)

### Eureka的作用
服务注册：服务启动后将自己的信息注册到Eureka-server中，保存服务名称到实例地址的映射表

服务发现：根据服务名称，拉取实例地址列表

调用时如何选择？可以选择负载均衡算法拉取一个实例地址。

如何知道是否健康？每隔一段时间向Eureka-server报告自己的状态，称为心跳

### 搭建Eureka
搭建Eureka的步骤：搭建服务端、服务注册、服务发现

1. 搭建服务端

服务端搭建需要新建一个单独的模块。

导入依赖

```xml
<dependency>
  <groupId>org.springframework.cloud</groupId>
  <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>
```

启动类添加注解@EnableEurekaServer，开启eureka的服务注册功能。

application.yml配置文件：

```yaml
server:
  port: 10086 # 服务端口
spring:
  application:
    name: eurekaserver # eureka的服务名称
eureka:
  client:
    service-url:  # eureka的地址信息
      defaultZone: http://127.0.0.1:10086/eureka
```

2. 服务注册

将微服务注册到Eureka Server中。

引入依赖：

```xml
<dependency>
  <groupId>org.springframework.cloud</groupId>
  <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
```

application.yml配置eureka server地址：

```yaml
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
```

启动多个实例测试是否注册（虚拟机参数添加-DServer.port）

3. 服务拉取

先按照上面将服务正常注册到Eureka Server中。

给RestTemplate添加@LoadBalanced注解，实现负载均衡的效果

然后将之前ip+端口的方式替换为服务名称就可以实现服务的拉取，并且还会进行负载均衡。

```java
@Autowired
private RestTemplate restTemplate;

public Order queryOrderById(Long orderId) {
    // 1.查询订单
    Order order = orderMapper.findById(orderId);
    // 2.利用RestTemplate发起http请求，查询用户
    // 2.1.url路径
    String url = "http://USERSERVICE/user/" + order.getUserId();
    // 2.2.发送http请求，实现远程调用
    User user = restTemplate.getForObject(url, User.class);
    // 3.封装user到Order
    order.setUser(user);
    // 4.返回
    return order;
}

```



# Ribbon负载均衡
为什么使用@LoadBalanced就可以实现负载均衡呢？

原理：SpringCloud底层使用了Ribbon组件，实现负载均衡。

SpringCloudRibbon的底层采用了一个拦截器，拦截了RestTemplate发出的请求，对地址做了修改。用一幅图来总结一下：

![1725356245361-7c116e1f-1cef-4a11-84e8-3d4015b827a9.png](1725356245361-7c116e1f-1cef-4a11-84e8-3d4015b827a9-449072.png)

**负载均衡策略：**

负载均衡的规则都定义在IRule接口中，而IRule有很多不同的实现类：![1725356315736-ea5f4625-cfe0-41fd-9837-11e0b82199b1.png](1725356315736-ea5f4625-cfe0-41fd-9837-11e0b82199b1-670735.png)

不同规则的含义如下：

| **内置负载均衡规则类** | **规则描述** |
| --- | --- |
| RoundRobinRule | 简单轮询服务列表来选择服务器。它是Ribbon默认的负载均衡规则。 |
| AvailabilityFilteringRule | 对以下两种服务器进行忽略：   （1）在默认情况下，这台服务器如果3次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续30秒，如果再次连接失败，短路的持续时间就会几何级地增加。  （2）并发数过高的服务器。如果一个服务器的并发连接数过高，配置了AvailabilityFilteringRule规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的..ActiveConnectionsLimit属性进行配置。 |
| WeightedResponseTimeRule | 为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。 |
| **ZoneAvoidanceRule** | 以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询。 |
| BestAvailableRule | 忽略那些短路的服务器，并选择并发数较低的服务器。 |
| RandomRule | 随机选择一个可用的服务器。 |
| RetryRule | 重试机制的选择逻辑 |


**自定义负载均衡策略：**

+ 代码方式：

```java
@Bean
public IRule randomRule(){
    return new RandomRule();
}
```

+ 配置文件方式：

```yaml
userservice: # 给某个微服务配置负载均衡规则，这里是userservice服务
  ribbon:
    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 
```

一般使用默认的规则，不用自行修改

**饥饿加载：**

Ribbon默认采用懒加载，只有在第一次访问的时候才创建LoadBalanceClinet，请求时间很长。饥饿加载则是在启动的时候就会创建，降低第一次访问的时间。

```yaml
ribbon:
  eager-load:
    enabled: true
    clients: userservice
```





# LoadBalancer
[SpringCloud之 LoadBalancer和Feign负载均衡_feignblockingloadbalancerclient-CSDN博客](https://blog.csdn.net/qq15035899256/article/details/129350492)

[OpenFeign集成Ribbon负载均衡-过滤和选择服务核心实现-阿里云开发者社区](https://developer.aliyun.com/article/1587717)

# Nacos
官网：

[Nacos 配置中心简介, Nacos 是什么](https://nacos.io/docs/v1/what-is-nacos/?spm=5238cd80.2ef5001f.0.0.3f613b7cIbSPbK)

nacos和SpringBoot和SpringCloud之间的版本对应关系：

[版本发布说明](https://sca.aliyun.com/docs/2021/overview/version-explain/?spm=7145af80.493a8c99.0.0.6ec42d5bMhz4m1)

## Nacos安装
**Window安装：（单机）**

+ 安装包地址：GitHub的Release下载页：[https://github.com/alibaba/nacos/releases](https://github.com/alibaba/nacos/releases)
+ 启动命令：startup.cmd -m standalone
+ 访问地址：localhost:8848/nacos

**Linux安装：**

+ 安装JDK，需要JDK的支持，上传解压jdk
+ 配置环境变量

```yaml
export JAVA_HOME=/usr/local/java			#jdk的位置，自定义
export PATH=$PATH:$JAVA_HOME/bin
```

+ 使配置生效：source /etc/profile
+ 安装Nacos，上传解压压缩包
+ 启动命令：sh startup.sh -m standalone
+ 安装数据库：运行sql在conf下

SpringBoot、SpringCloud、SpringCloudAlibaba各个版本和组件的对应：[版本说明 · alibaba/spring-cloud-alibaba Wiki · GitHub](https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E)

**Docker安装：**

[**https://blog.csdn.net/web2u/article/details/145107436**](https://blog.csdn.net/web2u/article/details/145107436)

## 服务注册到Nacos
**注意：特别注意SpringBoot、SpringCloud、SpringCloudAlibaba、Nacos各个依赖版本之间的关系和Nacos Clinet的版本关系**



配置Nacos地址：

```yaml
spring:
  cloud:
    nacos:
      discovery:
        server-addr: localhost:8848 # nacos服务地址
```

开启服务注册和发现的注解：@EnableDiscoveryClient



## 服务分级存储模型
一个服务可以有多个实例，比如：

127.0.0.1:8080、127.0.0.1:8081、127.0.0.1:8082......

这些实例分布于不同地方的机房里面，比如：

127.0.0.1:8080 在上海   127.0.0.1:8081  在北京   127.0.0.1:8082 在深圳

Nacos会将同一个机房内的实例划分为一个**集群**。

比如：

user-service是一个服务，服务下有多个集群，集群里面有多个实例，这样就形成了服务分级模型。

微服务互相访问时，应该尽可能访问同集群实例，因为本地访问速度更快。当本集群内不可用时，才访问其它集群。

给服务部署集群：

```yaml
spring:
  cloud:
    nacos:
      discovery:
        server-addr: localhost:8848 # nacos服务地址
        cluster-name: SH		## 集群名称
```

通过虚拟机选项配置多个服务和不同的集群名称：

```yaml
-Dserver.port=8083 -Dspring.cloud.nacos.discovery.cluster-name=HZ
```

**同集群优先的负载均衡：**  
默认的`ZoneAvoidanceRule`并不能实现根据同集群优先来实现负载均衡。

因此Nacos中提供了一个`NacosRule`的实现，可以优先从同集群中挑选实例。

```yaml
userservice:
  ribbon:
    NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule  # 负载均衡规则，优先选同集群的实例
```

**权限配置：**

上面配置的NacosRule是在同集群里面随机访问，可以通过配置权重，让性能更好的实例优先被访问，配置权重在nacos配置页面中。

**查看访问的是哪个服务实例的iP地址：**

+ LoadBalancerInterceptor类进来intercept()方法，进入execute()方法，跳转RibbonLoadBalancerClient类中execute()方法，语句Server server = this.getServer(loadBalancer, hint);获取ip地址。



## 环境隔离
Nacos提供namespace来进行环境隔离。不同的namespace中的服务互相不可见。

默认提供的namespace是public。

namespace又分为group，group下面又分service/data





## Nacos和Eureka的区别
Nacos和Eureka将服务实例分为两种：

+ 临时实例：宕机超过一段时间，自动别剔除服务
+ 非临时实例：宕机也不会自动剔除。

Nacos配置临时实例：

```yaml
spring:
  cloud:
    nacos:
      discovery:
        ephemeral: false # 设置为非临时实例
```

+ Nacos与eureka的共同点
    - 都支持服务注册和服务拉取
    - 都支持服务提供者心跳方式做健康检测
+ Nacos与Eureka的区别
    - Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式
    - 临时实例心跳不正常会被剔除，非临时实例则不会被剔除
    - Nacos支持服务列表变更的消息推送模式，服务列表更新更及时
    - Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式

## Nacos配置管理
当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。

Nacos一方面可以将配置集中管理，另一方可以在配置变更时，及时通知微服务，实现配置的热更新。

项目的核心配置，需要热更新的配置才有放到nacos管理的必要。基本不会变更的一些配置还是保存在微服务本地比较好。

规范配置文件的id：服务名称-profile.后缀名



微服务要拉取nacos中管理的配置，并且与本地的application.yml配置合并，才能完成项目启动。

但如果尚未读取application.yml，又如何得知nacos地址呢？

因此spring引入了一种新的配置文件：**bootstrap.yaml**文件，会在application.yml之前被读取，

根据`${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}`作为文件id，来读取配置。所以要在bootstrap.yaml中配置这些信息。



**热更新：不需要重启微服务，就可以看到配置修改**

1. 在@Value注入的变量所在类上添加注解@RefreshScope
2. 使用@ConfigurationProperties注解代替@Value注解。



**配置共享：**

其实微服务启动时，会去nacos读取多个配置文件，例如：

+ `[spring.application.name]-[spring.profiles.active].yaml`，例如：userservice-dev.yaml
+ `[spring.application.name].yaml`，例如：userservice.yaml

而`[spring.application.name].yaml`不包含环境，因此可以被多个环境共享。

配置共享的优先级（同名了会出现）：

![1725964516618-eb716202-2b5e-4e02-92e8-dd98839ee269.png](1725964516618-eb716202-2b5e-4e02-92e8-dd98839ee269-630407.png)



## Nacos集群配置
官方的Nacos集群图：

![1726018474755-41a67fd1-9484-492d-948d-f8cc4b91d5a0.png](1726018474755-41a67fd1-9484-492d-948d-f8cc4b91d5a0-325598.png)

计划搭建的集群图：

![1726018493764-35f31a01-8877-4165-b241-a6d91f5d2ec6.png](1726018493764-35f31a01-8877-4165-b241-a6d91f5d2ec6-704334.png)

搭建：

1. 初始化数据库

Nacos默认数据存储在内嵌数据库Derby中，不属于生产可用的数据库。

官方推荐的最佳实践是使用带有主从的高可用数据库集群，这里我们以单点的数据库为例来讲解。

创建nacos数据库，使用conf/nacos-mysql.sql初始化数据库。

2. 重命名cluster.conf.example文件为cluster.conf，向文件添加集群节点的地址，例如：

```java
127.0.0.1:8845
127.0.0.1.8846
127.0.0.1.8847
```

3. 修改application.properties文件，添加数据库配置

```properties
### If use MySQL as datasource:
spring.datasource.platform=mysql

### Count of DB:
db.num=1

### Connect URL of DB:
db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC
db.user.0=root
db.password.0=yangkai
```

4. 将nacos文件夹复制多份，并修改port，server.port=8845...，分别启动三个nacos节点startup.cmd
5. nginx配置集群，浏览器访问地址：http://localhost/nacos

```properties
upstream nacos-cluster {
    server 127.0.0.1:8845;
	server 127.0.0.1:8846;
	server 127.0.0.1:8847;
}

server {
    listen       80;
    server_name  localhost;

    location /nacos {
        proxy_pass http://nacos-cluster;
    }
}
```

6. 代码application.yml中配置：

```properties
spring:
  cloud:
    nacos:
      server-addr: localhost:80 # Nacos地址
```

注意nacos的版本，使用2.X

后续优化：

+ 实际部署时，需要给做反向代理的nginx服务器设置一个域名，这样后续如果有服务器迁移nacos的客户端也无需更改配置.
+ Nacos的各个节点应该部署到多个不同服务器，做好容灾和隔离





# Feign
可参考的文档：

[SpringCloud OpenFeign 全功能配置详解（一文吃透OpenFeign）-CSDN博客](https://blog.csdn.net/weixin_44606481/article/details/132499972)

[已解决集成feign报错：No Feign Client for loadBalancing defined. Did you forget to include-CSDN博客](https://blog.csdn.net/gongzi_9/article/details/123373981)

Feign是一个声明式的http客户端，官方地址：[https://github.com/OpenFeign/feign](https://github.com/OpenFeign/feign)

使用RestTemplate发起调用：

![1726021511405-1aa496a8-9085-4fc6-b626-a64864e91362.png](1726021511405-1aa496a8-9085-4fc6-b626-a64864e91362-218727.png)

存在的问题：

+ 代码可读性很差，不统一
+ 复杂参数的URL难以维护

## 使用Feign代替RestTemplate
1. 引入依赖：

```properties
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
```

2. 启动注解开启Feign功能：@EnableFeignClients
3. 使用注解@FeignClient("userservice")表明客户端，客户端就是服务接口。

```java
@FeignClient("userservice")
public interface UserClient {
    @GetMapping("/user/{id}")
    User queryById(@PathVariable("id") Long id);
}
```

4. 测试：

![1726021771095-0155a05e-7d9d-4826-9f9e-706ead6920dc.png](1726021771095-0155a05e-7d9d-4826-9f9e-706ead6920dc-252010.png)

## 自定义配置
| 类型 | 作用 | 说明 |
| --- | --- | --- |
| **feign.Logger.Level** | 修改日志级别 | 包含四种不同的级别：NONE、BASIC、HEADERS、FULL |
| feign.codec.Decoder | 响应结果的解析器 | http远程调用的结果做解析，例如解析json字符串为java对象 |
| feign.codec.Encoder | 请求参数编码 | 将请求参数编码，便于通过http请求发送 |
| feign. Contract | 支持的注解格式 | 默认是SpringMVC的注解 |
| feign. Retryer | 失败重试机制 | 请求失败的重试机制，默认是没有，不过会使用Ribbon的重试 |


一般默认值就可以满足，需要自定义可以使用@Bean覆盖默认的Bean

配置方式有Java代码方式和配置文件方式。

**全局生效：启动类上添加**

```java
@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration .class) 
```

**局部生效：被调用接口上添加**

```java
@FeignClient(value = "userservice", configuration = DefaultFeignConfiguration .class) 
```



## Feign优化
Feign底层发起http请求，依赖于其它的框架。其底层客户端实现包括：

•URLConnection：默认实现，不支持连接池

•Apache HttpClient ：支持连接池

•OKHttp：支持连接池

因此提高Feign的性能主要手段就是使用连接池代替默认的URLConnection。使用httpclient是为了替换底层的请求框架

1. 引入依赖

```xml
<!--httpClient的依赖 -->
<dependency>
  <groupId>io.github.openfeign</groupId>
  <artifactId>feign-httpclient</artifactId>
</dependency>
```

2. 配置连接池

```yaml
feign:
  httpclient:
    enabled: true # 开启feign对HttpClient的支持
    max-connections: 200 # 最大的连接数
    max-connections-per-route: 50 # 每个路径的最大连接数
```



## 实现基于抽取的最佳实践
将Feign的Client抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，提供给所有消费者使用。

1. 创建feign-api模块，引入feign的依赖
2. 放入接口、pojo、config信息
3. 使用服务调用的地方应引入模块

注意：接口和服务应该在一个包下，不在一个包下可以使用下面的方式结局：

+ 启动类指定要扫描的包：

```yaml
@EnableFeignClients(basePackages = "cn.itcast.feign.clients")
```

+ 启动类指定要扫描的接口

```yaml
@EnableFeignClients(clients = {UserClient.class})
```



# Gateway服务网关
[Gateway与SpringSecurity同时使用导致出现cannot access javax.servlet.Filter错误及包冲突问题解决-CSDN博客](https://blog.csdn.net/qq_26123545/article/details/125419271)

[springboot 项目启动报注册重复， A bean with that name has already been defined and overridin - 陈惟鲜的博客 - 博客园](https://www.cnblogs.com/a393060727/p/12759019.html)

Spring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。

## 为什么需要网关？
网关的**核心功能特性**：

+ 请求路由
+ 权限控制
+ 限流

![1726033587754-30bbf7b2-bf4a-49d2-bf66-2602a9b3b7c8.png](1726033587754-30bbf7b2-bf4a-49d2-bf66-2602a9b3b7c8-694929.png)

**权限控制**：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。

**路由和负载均衡**：一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。

**限流：**当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。

## 实现网关
1. 创建Gateway模块
2. 引入依赖

```xml
<!--网关-->
<dependency>
  <groupId>org.springframework.cloud</groupId>
  <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>
<!--nacos服务发现依赖-->
<dependency>
  <groupId>com.alibaba.cloud</groupId>
  <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
</dependency>
```

3. 配置规则

```yaml
server:
  port: 10010
logging:
  level:
    cn.itcast: debug
  pattern:
    dateformat: MM-dd HH:mm:ss:SSS
spring:
  application:
    name: gateway
  cloud:
    nacos:
      server-addr: nacos:8848 # nacos地址
    gateway:
      routes:
        - id: user-service # 路由标示，必须唯一
          uri: lb://userservice # 路由的目标地址
          predicates: # 路由断言，判断请求是否符合规则
            - Path=/user/** # 路径断言，判断路径是否是以/user开头，如果是则符合
        - id: order-service
          uri: lb://orderservice
          predicates:
            - Path=/order/**
      default-filters:4
        - AddRequestHeader=Truth,Itcast is freaking awesome!
```





## 断言工厂
我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件

例如Path=/user/**是按照路径匹配，这个规则是由`org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory`类来处理的，像这样的断言工厂在SpringCloudGateway还有十几个：

| **名称** | **说明** | **示例** |
| --- | --- | --- |
| After | 是某个时间点后的请求 | -  After=2037-01-20T17:42:47.789-07:00[America/Denver] |
| Before | 是某个时间点之前的请求 | -  Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai] |
| Between | 是某两个时间点之前的请求 | -  Between=2037-01-20T17:42:47.789-07:00[America/Denver],  2037-01-21T17:42:47.789-07:00[America/Denver] |
| Cookie | 请求必须包含某些cookie | - Cookie=chocolate, ch.p |
| Header | 请求必须包含某些header | - Header=X-Request-Id, \d+ |
| Host | 请求必须是访问某个host（域名） | -  Host=**.somehost.org,**.anotherhost.org |
| Method | 请求方式必须是指定方式 | - Method=GET,POST |
| Path | 请求路径必须符合指定规则 | - Path=/red/{segment},/blue/** |
| Query | 请求参数必须包含指定参数 | - Query=name, Jack或者-  Query=name |
| RemoteAddr | 请求者的ip必须是指定范围 | - RemoteAddr=192.168.1.1/24 |
| Weight | 权重处理 |  |


## 过滤器工厂
Spring提供了31种不同的路由过滤器工厂。

比如AddRequestHeader就是添加请求头过滤器。

如果要对所有的路由都生效，则可以将过滤器工厂写到default下。

```yaml
spring:
  cloud:
    gateway:
      routes:
      - id: user-service 
        uri: lb://userservice 
        predicates: 
        - Path=/user/**
      default-filters: # 默认过滤项
      - AddRequestHeader=Truth, Itcast is freaking awesome! 
```

## 全局过滤器
全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。

定义方式是实现GlobalFilter接口。

```java
@Component
public class AuthorizeFilter implements GlobalFilter, Ordered {
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        // 1.获取请求参数
        ServerHttpRequest request = exchange.getRequest();
        MultiValueMap<String, String> params = request.getQueryParams();
        // 2.获取参数中的 authorization 参数
        String auth = params.getFirst("authorization");
        // 3.判断参数值是否等于 admin
        if ("admin".equals(auth)) {
            // 4.是，放行
            return chain.filter(exchange);
        }
        // 5.否，拦截
        // 5.1.设置状态码
        exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);
        // 5.2.拦截请求
        return exchange.getResponse().setComplete();
    }

    @Override
    public int getOrder() {
        return -1;
    }
}
```

执行顺序：  
请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter

请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器：

![1726034600928-edce06bd-e728-4b64-a21c-60484dd5651e.png](1726034600928-edce06bd-e728-4b64-a21c-60484dd5651e-493340.png)

排序的规则是什么呢？

+ 每一个过滤器都必须指定一个int类型的order值，**order值越小，优先级越高，执行顺序越靠前**。
+ GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定
+ 路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。
+ 当过滤器的order值一样时，会按照 defaultFilter > 路由过滤器 > GlobalFilter的顺序执行。







## 跨域问题
跨域：服务ip或者端口不同

跨域问题：浏览器禁止请求的发起者想接受者发送Ajax跨域请求。



解决跨域请求的方式：通过CORS。 https://www.ruanyifeng.com/blog/2016/04/cors.html  



GateWay通过配置解决跨域请求：

```yaml
spring:
  cloud:
    gateway:
      # 。。。
      globalcors: # 全局的跨域处理
        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
        corsConfigurations:
          '[/**]':
            allowedOrigins: # 允许哪些网站的跨域请求 
              - "http://localhost:8090"
            allowedMethods: # 允许的跨域ajax的请求方式
              - "GET"
              - "POST"
              - "DELETE"
              - "PUT"
              - "OPTIONS"
            allowedHeaders: "*" # 允许在请求中携带的头信息
            allowCredentials: true # 是否允许携带cookie
            maxAge: 360000 # 这次跨域检测的有效期
```



gateway：

[从零开始的Spring Cloud Gateway指南：构建强大微服务架构_微服务网关技术-CSDN博客](https://blog.csdn.net/weixin_44863237/article/details/134728229)

Gateway和openfeign异常：

[【已解决 openFeign异步调用问题 block()/blockFirst()/blockLast()异常】_openfeign调用webflux block()-CSDN博客](https://blog.csdn.net/weixin_38376791/article/details/133130124)

[在 SpringBoot 中从 RestTemplate 过渡到 WebClient：详细指南-CSDN博客](https://blog.csdn.net/qq_42914528/article/details/134025056)

[【深入解析spring cloud gateway】13 Reactive Feign的使用_reactivefeignclient-CSDN博客](https://blog.csdn.net/suyuaidan/article/details/137674204)

[feign-reactive/feign-reactor-spring-cloud-starter/pom.xml at develop · PlaytikaOSS/feign-reactive](https://github.com/PlaytikaOSS/feign-reactive/blob/develop/feign-reactor-spring-cloud-starter/pom.xml)

[【深入解析spring cloud gateway】13 Reactive Feign的使用_reactivefeignclient-CSDN博客](https://blog.csdn.net/suyuaidan/article/details/137674204)

# Docker
## Docker介绍
微服务虽然具备各种各样的优势，但服务的拆分通用给部署带来了很大的麻烦。

+ 分布式系统中，依赖的组件非常多，不同组件之间部署时往往会产生一些冲突。
+ 在数百上千台服务中重复部署，环境不一定一致，会遇到各种问题

例如一个项目中，部署时需要依赖于node.js、Redis、RabbitMQ、MySQL等，这些服务部署时所需要的函数库、依赖项各不相同，甚至会有冲突。给部署带来了极大的困难。

**Docker解决兼容问题：**

Docker为了解决依赖的兼容问题的，采用了两个手段：

+ 将应用的Libs（函数库）、Deps（依赖）、配置与应用一起打包
+ 将每个应用放到一个隔离容器去运行，避免互相干扰

虽然解决了不同应用的兼容问题，但是开发、测试等环境会存在差异，操作系统版本也会有差异，怎么解决这些问题呢？

**Docker解决操作系统环境差异：**

+ Docker将用户程序与所需要调用的系统(比如Ubuntu)函数库一起打包
+ Docker运行到不同操作系统时，直接基于打包的函数库，借助于操作系统的Linux内核来运行

**Docker与虚拟机的区别：**

+ Docker是一个系统进程；虚拟机是在操作系统中的操作系统
+ docker体积小、启动速度快、性能好；虚拟机体积大、启动速度慢、性能一般

**镜像（Image）：**Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。

**容器（Container）：**镜像中的应用程序运行后形成的进程就是容器，只是Docker会给容器进程做隔离，对外不可见。

**DockerHub：**开源应用程序非常多，打包这些应用往往是重复的劳动。为了避免这些重复劳动，人们就会将自己打包的应用镜像，例如Redis、MySQL镜像放到网络上，共享使用，就像GitHub的代码共享一样。

+ DockerHub：DockerHub是一个官方的Docker镜像的托管平台。这样的平台称为Docker Registry。
+ 国内也有类似于DockerHub 的公开服务，比如 [网易云镜像服务](https://c.163yun.com/hub)、[阿里云镜像库](https://cr.console.aliyun.com/)等。

## CentOS安装Docker
这里介绍Docker CE在CentOS 7上的安装。

1. 卸载之前可能存在的旧版本Docker

```powershell
yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-selinux \
                  docker-engine-selinux \
                  docker-engine \
                  docker-ce
```

2. 安装yum

```powershell
yum install -y yum-utils \
           device-mapper-persistent-data \
           lvm2 --skip-broken
```

3. 更新yun配置

```powershell
# 设置docker镜像源
yum-config-manager \
    --add-repo \
    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
    
sed -i 's/download.docker.com/mirrors.aliyun.com\/docker-ce/g' /etc/yum.repos.d/docker-ce.repo

yum makecache fast
```

4. 安装docker-ce

```powershell
yum install -y docker-ce
```

5. 启动docker 

Docker应用需要用到各种端口，逐一去修改防火墙设置。非常麻烦，因此建议大家直接关闭防火墙！

启动docker前，一定要关闭防火墙后！！

启动docker前，一定要关闭防火墙后！！

启动docker前，一定要关闭防火墙后！！

```powershell
# 关闭
systemctl stop firewalld
# 禁止开机启动防火墙
systemctl disable firewalld
```

```powershell
systemctl start docker  # 启动docker服务

systemctl stop docker  # 停止docker服务

systemctl restart docker  # 重启docker服务
```

6. 配置镜像加速

docker官方镜像仓库网速较差，我们需要设置国内镜像服务：

参考阿里云的镜像加速文档：[https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors](https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors)

查看配置是否正确了：docker info

****

**安装Docker-compose**

1. linux下载：

```powershell
curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose
```

2. 修改权限：

```powershell
chmod +x /usr/local/bin/docker-compose
```

3. Base自动补全命令，启用自动补全：当你在终端中输入 `docker-compose` 并按 `Tab` 键时，Bash 会自动加载并执行这个脚本，帮助你补全 Docker Compose 命令及参数。  

```powershell
curl -L https://raw.githubusercontent.com/docker/compose/1.29.1/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose
```



**Docker镜像仓库：**

+ 简化版的镜像仓库：Docker官方的Docker Registry是一个基础版本的Docker镜像仓库，具备仓库管理的完整功能，但是没有图形化界面。

搭建命令：

```powershell
docker run -d \
    --restart=always \
    --name registry	\
    -p 5000:5000 \
    -v registry-data:/var/lib/registry \
    registry
```

命令中挂载了一个数据卷registry-data到容器内的/var/lib/registry 目录，这是私有镜像库存放数据的目录。

访问http://YourIp:5000/v2/_catalog 可以查看当前私有镜像服务中包含的镜像

+ 使用DockerCompose部署带有图象界面的DockerRegistry，命令如下：

```powershell
version: '3.0'
services:
  registry:
    image: registry
    volumes:
      - ./registry-data:/var/lib/registry
  ui:
    image: joxit/docker-registry-ui:static
    ports:
      - 8080:80
    environment:
      - REGISTRY_TITLE=私有仓库
      - REGISTRY_URL=http://registry:5000
    depends_on:
      - registry
```

docker up运行docekr-compose.yml文件

Docker Registry UI: 打开浏览器，访问 `http://localhost:8080`，你应该能够看到 Docker Registry 的 Web UI。

Registry: 可以通过 `http://localhost:5000` 访问 Docker 私有镜像仓库。

+ 我们的私服采用的是http协议，默认不被Docker信任，所以需要做一个配置：

```powershell
# 打开要修改的文件
vi /etc/docker/daemon.json
# 添加内容：
"insecure-registries":["http://192.168.150.101:8080"]
# 重加载
systemctl daemon-reload
# 重启docker
systemctl restart docker
```

## Docker的基本操作
### 镜像操作
镜像的命名是【respository】:【tag】

常见的镜像命令图：

![1726123096938-ee8b5ce4-0a04-45dd-8c8b-4923d50ff5a6.png](1726123096938-ee8b5ce4-0a04-45dd-8c8b-4923d50ff5a6-920910.png)

以为例nginx镜像：

1. 拉取nginx进行：docker pull nginx，这里默认拉取的是lastest
2. 保存镜像到本地：docker save -o nginx.tar nginx:lastest
3. 删除本地镜像：docker rmi nginx:lastest
4. 重新加载镜像到本地：docker load -i nginx.tar

### 容器操作
容器运行命令图：

![1726123790217-d5726887-6333-492c-a76f-7a94bb7b203a.png](1726123790217-d5726887-6333-492c-a76f-7a94bb7b203a-040977.png)

容器保护三个状态：

+ 运行：进程正常运行
+ 暂停：进程暂停，CPU不再运行，并不释放内存
+ 停止：进程终止，回收进程占用的内存、CPU等资源

以上面创建nginx镜像为例：

1. 创建容器并运行：docker run --name nginx -p 80:80 -d nginx:latest

-d 代表后台运行

-p 代表宿主机和容器的端口映射

--name 容器命名

2. 进入容器内部修改内容：docker exec -it nginx bash

-it : 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互

bash：标准的linux终端交互命令

3. 查看容器运行情况：docker ps和docker ps -a
4. 具体日志：docker logs -f ，-f持续的查看日志
5. 暂停容器：docker stop nginx:latest
6. 运行容器：docker start nginx:latest
7. 删除容器：docker rm nginx:latest

### 数据卷
进入nginx内部修改文件内容很麻烦，如果可以让nginx容器和宿主机上的文件进行挂载，同步修改，那么是不是很方便呢？数据卷的作用就是这个。

数据卷操作：

+ docker volume create：创建数据卷
+ docker volume ls：查看所有数据卷
+ docker volume inspect：查看数据卷详细信息，包括关联的宿主机目录位置
+ docker volume rm：删除指定数据卷
+ docker volume prune：删除所有未使用的数据卷

以nginx为例，挂载nginx的html目录到数据卷html：

1. 创建数据卷：docker volume html
2. 创建容器并挂载：-v html:/usr/share/nginx/html ，后面的目录是html在nginx的目录
3. 到html目录下面修改index.html文件

这里使用的是数据卷挂载目录方式，还可以：

-v 宿主机目录：容器目录

-v 宿主机文件：容器中文件

## Dockerfile自定义镜像
镜像就是在系统函数库、运行环境基础上，添加应用程序文件、配置文件、依赖文件等组合，然后编写好启动脚本打包在一起形成的文件。

我们只需要告诉Docker，我们的镜像的组成，需要哪些BaseImage、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来Docker会帮助我们构建镜像。描述这些信息的文件就是Dockerfile文件。

Dockerfile利用指令来构建镜像，每一个指令形成一个layer。

![1726125462490-88dc4d9c-f3a4-4681-9a3b-b9bd2f5698df.png](1726125462490-88dc4d9c-f3a4-4681-9a3b-b9bd2f5698df-431431.png)

构建镜像的命令：docker build -t 镜像名:版本 .  

.别掉了



## Docker Compose
Docker Compose可以基于Compose文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器！

拿cloud-demo项目进行部署：因为内存不足失败了，内存2g。

![1726129978028-110a91c4-b38d-4822-9346-36856d0068a6.png](1726129978028-110a91c4-b38d-4822-9346-36856d0068a6-823747.png)

1. 创建docker-compose文件

```yaml
version: "3.2"

services:
  nacos:
    image: nacos/nacos-server
    environment:
      MODE: standalone
    ports:
      - "8848:8848"
  mysql:
    image: mysql:5.7.25
    environment:
      MYSQL_ROOT_PASSWORD: 123
    volumes:
      - "$PWD/mysql/data:/var/lib/mysql"
      - "$PWD/mysql/conf:/etc/mysql/conf.d/"
  userservice:
    build: ./user-service
  orderservice:
    build: ./order-service
  gateway:
    build: ./gateway
    ports:
      - "10010:10010"
```

这里部署了五个服务，image代表镜像版本，environment环境变量，build代表userservice他们都是通过Dockerfile临时构建。

2. 服务目录就放了jar包和Dockerfile，其中Dockerfile内容：

```yaml
FROM openjdk:8-jdk-alpine
COPY ./app.jar /tmp/app.jar
ENTRYPOINT java -jar /tmp/app.jar
```

3. 修改微服务配置，因为容器之间进行互联是通过容器名，而不是ip地址，这里我们将order-service、user-service、gateway服务的mysql、nacos地址都修改为基于容器名的访问。

```yaml
spring:
  datasource:
    url: jdbc:mysql://mysql:3306/cloud_order?useSSL=false
    username: root
    password: 123
    driver-class-name: com.mysql.jdbc.Driver
  application:
    name: orderservice
  cloud:
    nacos:
      server-addr: nacos:8848 # nacos服务地址
```

4. 打jar包

```yaml
<build>
  <!-- 服务打包的最终名称 -->
  <finalName>app</finalName>
  <plugins>
    <plugin>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-maven-plugin</artifactId>
    </plugin>
  </plugins>
</build>
```

5. jar包放到对应的Dockerfile文件目录下。
6. 部署，将整个cloud-demo文件夹上传，进入目录，执行命令：docker-compose up -d

## Docker镜像仓库
Docker镜像仓库是自己存放镜像的地址，可以推送自己镜像上去，别人可以直接拉取下来。

注意：必须配置私服地址，上面安装Docker仓库有

使用：

1. 重新tag本地镜像，名称前缀为私有仓库的地址

```yaml
docker tag nginx:latest 139.9.45.47:8080/nginx:1.0 
```

2. 推送镜像

```yaml
docker push 139.9.45.47:8080/nginx:1.0 
```

3. 拉取镜像

```yaml
docker pull 139.9.45.47:8080/nginx:1.0 
```

4. 查看私人仓库有多少镜像：139.9.45.47:8080/v2/_catalog





# RabbitMQ
## 什么是MQ
+ 同步通讯：调用方发送请求，等待响应方返回。

优点： 时效性较强，可以立即得到结果

缺点：耦合度高、性能和吞吐量下降

+ 异步通讯：调用方通知服务提供者处理请求，不需要等待提供方返回。

缺点：架构复杂、依赖Broker的实现

优点：耦合度低、性能和吞吐量提高

发送方和接收方中间添加一个Broker（中间人），发送方只管发送，接收方只管从Broker中订阅消息。

![1726133846167-fd0b497c-f5d6-4ddd-8ec4-52c6be14fc4b.png](1726133846167-fd0b497c-f5d6-4ddd-8ec4-52c6be14fc4b-991077.png)

MQ是消息队列的简称，也就是上面的Broker。

常见的MQ实现有：ActiveMQ、RabbitMQ、RockerMQ、Kafka

|  | **RabbitMQ** | **ActiveMQ** | **RocketMQ** | **Kafka** |
| --- | --- | --- | --- | --- |
| 公司/社区 | Rabbit | Apache | 阿里 | Apache |
| 开发语言 | Erlang | Java | Java | Scala&Java |
| 协议支持 | AMQP，XMPP，SMTP，STOMP | OpenWire,STOMP，REST,XMPP,AMQP | 自定义协议 | 自定义协议 |
| 可用性 | 高 | 一般 | 高 | 高 |
| 单机吞吐量 | 一般 | 差 | 高 | 非常高 |
| 消息延迟 | 微秒级 | 毫秒级 | 毫秒级 | 毫秒以内 |
| 消息可靠性 | 高 | 一般 | 高 | 一般 |


追求可用性：Kafka、 RocketMQ 、RabbitMQ

追求可靠性：RabbitMQ、RocketMQ

追求吞吐能力：RocketMQ、Kafka

追求消息低延迟：RabbitMQ、Kafka

## RabbitMQ的架构
![1726134134523-ede5b452-f4ab-4e12-9309-adae202ff7cc.png](1726134134523-ede5b452-f4ab-4e12-9309-adae202ff7cc-242345.png)

RabbitMQ中的一些角色：

+ publisher：生产者
+ consumer：消费者
+ exchange个：交换机，负责消息路由
+ queue：队列，存储消息
+ virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离



## 安装RabbitMQ
**单机部署：**

1. 拉取镜像的方式：

```yaml
docker pull rabbitmq:3-management
```

2. 创建容器

```yaml
docker run \
 -e RABBITMQ_DEFAULT_USER=root \
 -e RABBITMQ_DEFAULT_PASS=123456 \
 # -v /var/lib/docker/volumes/mq-plugins/_data:/plugins \
 --name mq \
 --hostname mq1 \
 -p 15672:15672 \
 -p 5672:5672 \
 -d \
 rabbitmq:3-management
```

**集群部署：**

**MQ集群分类：**

在RabbitMQ的官方文档中，讲述了两种集群的配置方式：

+ 普通模式：普通模式集群不进行数据同步，每个MQ都有自己的队列、数据信息（其它元数据信息如交换机等会同步）。例如我们有2个MQ：mq1，和mq2，如果你的消息在mq1，而你连接到了mq2，那么mq2会去mq1拉取消息，然后返回给你。如果mq1宕机，消息就会丢失。
+ 镜像模式：与普通模式不同，队列会在各个mq的镜像节点之间同步，因此你连接到任何一个镜像节点，均可获取到消息。而且如果一个节点宕机，并不会导致数据丢失。不过，这种方式增加了数据同步的带宽消耗。

## RabbitMQ消息模型
![1726134765045-9099983a-2d55-48a9-83e0-37ba2ab405e0.png](1726134765045-9099983a-2d55-48a9-83e0-37ba2ab405e0-737899.png)



## Demo测试
基本消息队列的消息发送流程：

1. 建立connection
2. 创建channel
3. 利用channel声明队列
4. 利用channel向队列发送消息

基本消息队列的消息接收流程：

1. 建立connection
2. 创建channel
3. 利用channel声明队列
4. 定义consumer的消费行为handleDelivery()
5. 利用channel将消费者与队列绑定

发送方：

```java
public void testSendMessage() throws IOException, TimeoutException {
    // 1.建立连接
    ConnectionFactory factory = new ConnectionFactory();
    // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
    factory.setHost("192.168.150.101");
    factory.setPort(5672);
    factory.setVirtualHost("/");
    factory.setUsername("itcast");
    factory.setPassword("123321");
    // 1.2.建立连接
    Connection connection = factory.newConnection();

    // 2.创建通道Channel
    Channel channel = connection.createChannel();

    // 3.创建队列
    String queueName = "simple.queue";
    channel.queueDeclare(queueName, false, false, false, null);

    // 4.发送消息
    String message = "hello, rabbitmq!";
    channel.basicPublish("", queueName, null, message.getBytes());
    System.out.println("发送消息成功：【" + message + "】");

    // 5.关闭通道和连接
    channel.close();
    connection.close();

}
```

接收方：

```java
public static void main(String[] args) throws IOException, TimeoutException {
    // 1.建立连接
    ConnectionFactory factory = new ConnectionFactory();
    // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
    factory.setHost("192.168.150.101");
    factory.setPort(5672);
    factory.setVirtualHost("/");
    factory.setUsername("itcast");
    factory.setPassword("123321");
    // 1.2.建立连接
    Connection connection = factory.newConnection();

    // 2.创建通道Channel
    Channel channel = connection.createChannel();

    // 3.创建队列
    String queueName = "simple.queue";
    channel.queueDeclare(queueName, false, false, false, null);

    // 4.订阅消息
    channel.basicConsume(queueName, true, new DefaultConsumer(channel){
        @Override
        public void handleDelivery(String consumerTag, Envelope envelope,
                                   AMQP.BasicProperties properties, byte[] body) throws IOException {
            // 5.处理消息
            String message = new String(body);
            System.out.println("接收到消息：【" + message + "】");
        }
    });
    System.out.println("等待接收消息。。。。");
}
```

## 使用SpringAMQP
SpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配，使用起来非常方便。

SpringAmqp的官方地址：[https://spring.io/projects/spring-amqp](https://spring.io/projects/spring-amqp)

SpringAMQP提供了三个功能：

+ 自动声明队列、交换机及其绑定关系
+ 基于注解的监听器模式，异步接收消息
+ 封装了RabbitTemplate工具，用于发送消息



### 实现简单队列模型
1. 引入RabbitAMQP依赖

```java
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-amqp</artifactId>
        </dependency>
```

2. 提供者配置rabbitmq信息

```yaml
spring:
  rabbitmq:
    addresses: 139.9.45.47
    port: 5672
    virtual-host: /
    username: root
    password: 123456
```

3. 提供者通过注入的RabbitTemplate发送消息

```java
@Autowired
private RabbitTemplate rabbitTemplate;

@Test
public void testSimpleAMQP() {
    String queueName = "simple.queue";
    String message = "hello, testRabbitMQ";
    rabbitTemplate.convertAndSend(queueName, message);
}
```

4. 消费者通过@RabbitListener注解接收指定队列的消息：

```java
@Component
public class ConsumerAMQP {

    @RabbitListener(queues = "simple.queue")
    public void consumer(String msg) {
        System.out.println("接收消息： " + msg);
    }
}
```

### Work Queue
Work Queue工作队列，是多个消息消费者绑定一个Broker，只有一个消息提供者。

![1726213865032-36f39cae-adcb-424a-a0ae-1b8a5e23b8a9.png](1726213865032-36f39cae-adcb-424a-a0ae-1b8a5e23b8a9-741110.png)

实现：

1. 提供者模拟消息堆积：

```java
@Test
public void testSimpleAMQP() throws InterruptedException {
    String queueName = "simple.queue";
    String message = "hello, testRabbitMQ";
    
    //        rabbitTemplate.convertAndSend(queueName, message);
    for (int i = 0; i < 20; i++) {
        rabbitTemplate.convertAndSend(queueName, message);
        Thread.sleep(20);
    }
}
```

2. 多个消费者绑定Queue

```java
@Component
public class ConsumerAMQP {

    @RabbitListener(queues = "simple.queue")
    public void consumer(String msg) throws InterruptedException {
        System.out.println("1111接收消息： " + msg );
        Thread.sleep(20);
    }

    @RabbitListener(queues = "simple.queue")
    public void consumer2(String msg) throws InterruptedException {
        System.out.println("2222接收消息： " + msg);
        Thread.sleep(200);
    }
}
```

发现，消息是平均分配给消费者的，如果要按照处理能力划分的话，可以用下面的配置：

```java
    listener:
      simple:
        prefetch: 1 # 每次只能处理一条消息，处理完了才能获取下一条
```







## 发布订阅
模型图：

![1726214454157-a3e8277c-65da-4d1f-aa17-8ce22e9983d4.png](1726214454157-a3e8277c-65da-4d1f-aa17-8ce22e9983d4-527557.png)

可以看到，在订阅模型中，多了一个exchange角色，而且过程略有变化：

+ Publisher：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机）
+ Exchange：交换机，图中的X。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型：
    - Fanout：广播，将消息交给所有绑定到交换机的队列
    - Direct：定向，把消息交给符合指定routing key 的队列
    - Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列
+ Consumer：消费者，与以前一样，订阅队列，没有变化
+ Queue：消息队列也与以前一样，接收消息、缓存消息。

Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！

## Fanout交换机
Fanout翻译扇出，这里的意思就是广播类型的交换机。

![1726222495376-56bf950b-77a4-4647-bc25-83f408538f7b.png](1726222495376-56bf950b-77a4-4647-bc25-83f408538f7b-331924.png)

在广播模式下，消息发送流程是这样的：

+ 1）  可以有多个队列
+ 2）  每个队列都要绑定到Exchange（交换机）
+ 3）  生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定
+ 4）  交换机把消息发送给绑定过的所有队列
+ 5）  订阅队列的消费者都能拿到消息

案例：

+ 创建一个交换机 itcast.fanout，类型是Fanout
+ 创建两个队列fanout.queue1和fanout.queue2，绑定到交换机itcast.fanout

实现：

1. 消息提供者通知交换机发送消息

```java
@Test
public void testFanoutExchange() {
    // 队列名称
    String exchangeName = "itcast.exchange";
    // 消息
    String message = "hello, everyone!";
    rabbitTemplate.convertAndSend(exchangeName, "", message);
}
```

2. 消息消费者定义指定的交换机和队列，以及他们之间的绑定

```java
@Configuration
public class FanoutConfig {
    @Bean
    public FanoutExchange fanoutExchange() {
        return new FanoutExchange("itcast.exchange");
    }

    /**
     * 声明两个队列
     */
    @Bean
    public Queue queue1() {
        return new Queue("fanout.queue1");
    }

    @Bean
    public Queue queue2() {
        return new Queue("fanout.queue2");
    }

    /**
     * 绑定交换机和队列
     */
    @Bean
    public Binding binding1(Queue queue1, FanoutExchange fanoutExchange) {
        return BindingBuilder.bind(queue1).to(fanoutExchange);
    }

    @Bean
    public Binding binding2(Queue queue2, FanoutExchange fanoutExchange) {
        return BindingBuilder.bind(queue2).to(fanoutExchange);
    }
}
```

3. 消费者监听队列

```java
    @RabbitListener(queues = "fanout.queue1")
    public void fanoutConsumer(String msg) {
        System.out.println("queue1接收消息：" + msg);
    }

    @RabbitListener(queues = "fanout.queue2")
    public void fanoutConsumer2(String msg) {
        System.out.println("queue2接收消息：" + msg);
    }
```

交换机的作用是什么？

+ 接收publisher发送的消息
+ 将消息按照规则路由到与之绑定的队列
+ 不能缓存消息，路由失败，消息丢失
+ FanoutExchange的会将消息路由到每个绑定的队列

声明队列、交换机、绑定关系的Bean是什么？

+ Queue
+ FanoutExchange
+ Binding

## Direct交换机
在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。

![1726215866382-c49ff246-3186-4696-9d45-15462f442479.png](1726215866382-c49ff246-3186-4696-9d45-15462f442479-017061.png)

在Direct模型下：

+ 队列与交换机的绑定，不能是任意绑定了，而是要指定一个`RoutingKey`（路由key）
+ 消息的发送方在 向 Exchange发送消息时，也必须指定消息的 `RoutingKey`。
+ Exchange不再把消息交给每一个绑定的队列，而是根据消息的`Routing Key`进行判断，只有队列的`Routingkey`与消息的 `Routing key`完全一致，才会接收到消息

需求：

1. 通过注解方式声明交换机、队列，上面通过@Bean的方式注入交换机和队列显得很麻烦：

```java
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = "direct.queue2"),
    exchange = @Exchange(name = "itcast.direct", type = ExchangeTypes.DIRECT),
    key = {"red", "blue"}
))
public void directConsumer02(String msg) {
    System.out.println("queue2接收消息：" + msg);
}
```

2. 提供者发送指定Direct的消息

```java
@Test
public void testSendDirectExchange() {
    // 交换机名称
    String exchangeName = "itcast.direct";
    // 消息
    String message = "红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！";
    // 发送消息
    rabbitTemplate.convertAndSend(exchangeName, "yellow", message);
}
```

## Topic交换机
`Topic`类型的`Exchange`与`Direct`相比，都是可以根据`RoutingKey`把消息路由到不同的队列。只不过`Topic`类型`Exchange`可以让队列在绑定`Routing key` 的时候使用通配符！

`Routingkey` 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： `item.insert`

通配符规则：

`#`：匹配一个或多个词

`*`：匹配不多不少恰好1个词

举例：

`item.#`：能够匹配`item.spu.insert` 或者 `item.spu`

`item.*`：只能匹配`item.spu`

案例：

实现两个消费者绑定分别绑定各自的queue，提供者发送带有通配符的routeKey的消息。

![1726222248028-d0a4ad65-4b17-4b6a-9561-0dc78937d571.png](1726222248028-d0a4ad65-4b17-4b6a-9561-0dc78937d571-243906.png)

1. 消息消费者绑定queue：

```java
    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "topic.queue1"),
            exchange = @Exchange(name = "itcast.topic", type = ExchangeTypes.TOPIC),
            key = "china.news"
    ))
    public void listenTopicQueue3(String msg){
        System.out.println("消费者接收到topic.queue3的消息：【" + msg + "】");
    }
```

2. 提供者使用通配符发送：

```java
    @Test
    public void testSendTopicExchange() {
        // 交换机名称
        String exchangeName = "itcast.topic";
        // 消息
        String message = "喜报！孙悟空大战哥斯拉，胜!";
        // 发送消息
        rabbitTemplate.convertAndSend(exchangeName, "china.news", message);
    }
```

注意：如果相同key绑定queue，并不会重复接收到消息

## 消息转换器
Spring会把你发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。

默认情况下采用的是JDK序列化，所以发送给queue中就是JDK序列化后的字符序列：（可读性差、数据体积大、安全漏洞）

![1726240991352-1f82b870-c881-4564-b4f4-987ae17f53e2.png](1726240991352-1f82b870-c881-4564-b4f4-987ae17f53e2-120169.png)

所以我们采用JSON序列化：

1. 引入依赖：

```java
<dependency>
    <groupId>com.fasterxml.jackson.dataformat</groupId>
    <artifactId>jackson-dataformat-xml</artifactId>
    <version>2.9.10</version>
</dependency>
```

2. 启动类配置Bean

```java
@Bean
public MessageConverter jsonMessageConverter(){
    return new Jackson2JsonMessageConverter();
}
```











# ES
## ES基本概念
ElasticSearch是一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能

ELK是以elasticsearch为核心的技术栈，包括beats、Logstash、kibana、elasticsearch

ES的底层是Lucene，Lucene是Apache的开源搜索引擎类库，提供了搜索引擎的核心API

### 正向索引和倒排索引
MySQL等关系型数据库使用的就是正向索引，例如给字段id加上索引，我们就可以根据id索引获取数据。

倒排索引里面有两个重要概念：

+ 文档（document）：用来搜索数据，一条数据就是一个文档
+ 词条（Term）：对用户数据或者用户搜索的词按照某种算法进行划分

**创建倒排索引**是对正向索引的一种特殊处理，流程如下：

+ 将每一个文档的数据利用算法分词，得到一个个词条
+ 创建表，每行数据包括词条、词条所在文档id、位置等信息
+ 因为词条唯一性，可以给词条创建索引，例如hash表结构索引

![1726277757786-cc91bb9c-e0e3-4d60-9565-759f8b6b304c.png](1726277757786-cc91bb9c-e0e3-4d60-9565-759f8b6b304c-212494.png)

正向索引的优缺点

+ 可以给多个字段创建索引
+ 根据索引字段搜索、排序速度快
+ 但是根据非索引字段进行查看，要进行全表查找

倒排索引的优缺点：

+ 根据词条搜索、模糊搜索，速度非常快
+ 只能给词条创建索引，不能给字段
+ 不能给字段排序

### 文档、字段、索引、映射
一条数据对应一个文档。

文档中的一列对应一个字段。

索引是相同规则的文档集合。

映射是对索引中文档的约束信息。



### 部署单点ES
因为ES和Kibana要在一个网络，我们需要创建一个网络。

```java
docker network create es_net
```

1. 镜像拉取: docker pull elasticsearch:7.12.1
2. 创建容器：

```java
docker run -d \
	--name es \
    -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
    -e "discovery.type=single-node" \
    -v es-data:/usr/share/elasticsearch/data \
    -v es-plugins:/usr/share/elasticsearch/plugins \
    --privileged \
    --network es-net \
    -p 9200:9200 \
    -p 9300:9300 \
elasticsearch:7.12.1
```

### 部署kibana
kibana提供一个给es的可视化页面。

1. 镜像拉取
2. 创建容器：

```java
docker run -d \
--name kibana \
-e ELASTICSEARCH_HOSTS=http://es:9200 \
--network=es-net \
-p 5601:5601  \
kibana:7.12.1
```

### 安装ik分词器
在线安装：

```java
# 进入容器内部
docker exec -it elasticsearch /bin/bash

# 在线下载并安装
./bin/elasticsearch-plugin  install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip

#退出
exit
#重启容器
docker restart elasticsearch
```

离线安装：

1. 找到es-plugins的挂载目录：docker volume inspect es-plugins
2. 将ik整个文件夹放入到目录下面
3. 重启容器

IK分词器包含两种模式：

+ `ik_smart`：最少切分
+ `ik_max_word`：最细切分

**扩展词：**

1. 进入ik目录下面config文件夹，打开IKAnalyzer.cfg.xml
2. 配置

```java
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
        <comment>IK Analyzer 扩展配置</comment>
        <!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典-->
        <entry key="ext_dict">ext.dic</entry>
</properties>
```

3. 添加文件ext_dict，里面添加扩展词，一个词一行
4. 重启es

**停用词：**

1. 同样打开IKAnalyzer.cfg.xml

```java
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
        <comment>IK Analyzer 扩展配置</comment>
        <!--用户可以在这里配置自己的扩展字典-->
        <entry key="ext_dict">ext.dic</entry>
         <!--用户可以在这里配置自己的扩展停止词字典  *** 添加停用词词典-->
        <entry key="ext_stopwords">stopword.dic</entry>
</properties>
```

2. 在文件stopword.dic里面添加停用词
3. 重启服务

### 部署ES集群
部署es集群可以直接使用docker-compose来完成，不过要求你的Linux虚拟机至少有4G的内存空间

```java
version: '2.2'
services:
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    networks:
      - elastic
  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data02:/usr/share/elasticsearch/data
    networks:
      - elastic
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.12.1
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data03:/usr/share/elasticsearch/data
    networks:
      - elastic

volumes:
  data01:
    driver: local
  data02:
    driver: local
  data03:
    driver: local

networks:
  elastic:
    driver: bridge
```

启动：docker-compose up



## 索引库操作
索引对应着关系型数据库中的表，映射Mapping对应着表的约束。

Mapping属性有：

+ type：字段数据类型，常见的简单类型有：
    - 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）
    - 数值：long、integer、short、byte、double、float、
    - 布尔：boolean
    - 日期：date
    - 对象：object
+ index：是否创建索引，默认为true
+ analyzer：使用哪种分词器
+ properties：该字段的子字段

下面DSL分别对应的创建、获取、修改、删除。

注意：修改只能添加新的字段，而不能修改已经创建的映射。

```java
put /test
{
  "mappings": {
    "properties": {
      "age": {
        "type": "integer"
      }
    }
  }
}

get /test

put /test/_mapping 
{
  "properties": {
    "weight": {
      "type": "float"
    }
  }
}

delete /test
```

## 文档操作
文档创建、获取、全量修改（整个id对应的文档修改）、增量修改（针对id对应的文档部分字段修改）、删除文档

```java
post /test/_doc/1
{
  "age": "11",
  "weight": "200"
}

get /test/_doc/1


put /test/_doc/1
{
  "age": "100",
  "weight": "100"
}

post /test/_update/1
{
  "doc": {
    "weight": "200"
  }
}

delete /test/_doc/1
```

## RestAPI
ES官方提供了各种不同语言的客户端，用来操作ES。这些客户端的本质就是组装DSL语句，通过http请求发送给ES。官方文档地址：[https://www.elastic.co/guide/en/elasticsearch/client/index.html](https://www.elastic.co/guide/en/elasticsearch/client/index.html)

RestClient的依赖：

```java
<dependency>
    <groupId>org.elasticsearch.client</groupId>
    <artifactId>elasticsearch-rest-high-level-client</artifactId>
</dependency>
```

因为SpringBoot默认的ES版本是7.6.2，需要覆盖

```java
<properties>
    <java.version>1.8</java.version>
    <elasticsearch.version>7.12.1</elasticsearch.version>
</properties>
```

与ES交互的所有操作都在RestHighLevelClient，初始化：

```java
RestHighLevelClient client = new RestHighLevelClient(RestClient.builder(
        HttpHost.create("http://192.168.150.101:9200")
));
```

创建、删除、是否存在索引库的操作：

```java
@Test
void createHotelIndex() throws IOException {
    // 1.创建Request对象
    CreateIndexRequest request = new CreateIndexRequest("hotel");
    // 2.准备请求的参数：DSL语句，MAPPING_TEMPLATE是DSL语句字符串。
    request.source(MAPPING_TEMPLATE, XContentType.JSON);
    // 3.发送请求
    client.indices().create(request, RequestOptions.DEFAULT);
}

@Test
void testDeleteHotelIndex() throws IOException {
    // 1.创建Request对象
    DeleteIndexRequest request = new DeleteIndexRequest("hotel");
    // 2.发送请求
    client.indices().delete(request, RequestOptions.DEFAULT);
}

@Test
void testExistsHotelIndex() throws IOException {
    // 1.创建Request对象
    GetIndexRequest request = new GetIndexRequest("hotel");
    // 2.发送请求
    boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
    // 3.输出
    System.err.println(exists ? "索引库已经存在！" : "索引库不存在！");
}
```



### RestAPI操作文档
RestAPI添加文档、获取文档、修改文档、批量操作文档。

```java
@SpringBootTest
public class HotelDocumentTest {

    private RestHighLevelClient client;

    @Resource
    private IHotelService hotelService;

    @BeforeEach
    void setUp() {
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create("http://139.9.45.47:9200")
        ));
    }

    @AfterEach
    void tearDown() throws IOException {
        this.client.close();
    }

    @Test
    void testAddDocument() throws IOException {
        // 1.根据id查询酒店数据
        Hotel hotel = hotelService.getById(61083L);
        // 2.转换为文档类型
        HotelDoc hotelDoc = new HotelDoc(hotel);
        // 3.将HotelDoc转json
        String json = JSON.toJSONString(hotelDoc);

        // 1.准备Request对象
        IndexRequest request = new IndexRequest("hotel").id(hotelDoc.getId().toString());
        // 2.准备Json文档
        request.source(json, XContentType.JSON);
        // 3.发送请求
        client.index(request, RequestOptions.DEFAULT);
    }


    @Test
    void testGetDocumentById() throws IOException {
        // 1.准备Request
        GetRequest request = new GetRequest("hotel", "61083");
        // 2.发送请求，得到响应
        GetResponse response = client.get(request, RequestOptions.DEFAULT);
        // 3.解析响应结果
        String json = response.getSourceAsString();

        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
        System.out.println(hotelDoc);
    }

    @Test
    void testUpdateDocument() throws IOException {
        // 1.准备Request
        UpdateRequest request = new UpdateRequest("hotel", "61083");
        // 2.准备请求参数
        request.doc(
                "price", "952",
                "starName", "四钻"
        );
        // 3.发送请求
        client.update(request, RequestOptions.DEFAULT);
    }

    @Test
    void testBulkRequest() throws IOException {
        // 批量查询酒店数据
        List<Hotel> hotels = hotelService.list();

        // 1.创建Request
        BulkRequest request = new BulkRequest();
        // 2.准备参数，添加多个新增的Request
        for (Hotel hotel : hotels) {
            // 2.1.转换为文档类型HotelDoc
            HotelDoc hotelDoc = new HotelDoc(hotel);
            // 2.2.创建新增文档的Request对象
            request.add(new IndexRequest("hotel")
                    .id(hotelDoc.getId().toString())
                    .source(JSON.toJSONString(hotelDoc), XContentType.JSON));
        }
        // 3.发送请求
        client.bulk(request, RequestOptions.DEFAULT);
    }
}
```

## DSL查询文档
DSL查询分类：

+ 查询所有：查询出所有数据，一般测试用。例如：match_all
+ 全文检索（full text）查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：
    - match_query
    - multi_match_query
+ 精确查询：根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如：
    - ids
    - range
    - term
+ 地理（geo）查询：根据经纬度查询。例如：
    - geo_distance
    - geo_bounding_box
+ 复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：
    - bool
    - function_score

```java
格式：
GET /indexName/_search
{
  "query": {
    "查询类型": {
      "查询条件": "条件值"
    }
  }
}
```

查询所有：

```java
get /hotel/_search
{
  "query": {
    "match_all": {
      
    }
  }
}
```

全文检索：拿着词条去匹配文档，获取到文档的id，match一个字段查询，multi_match多个字段查询

```java
get /hotel/_search
{
  "query": {
    "match": {
      "all": "外滩如家"
    }
  }
}

get /hotel/_search
{
  "query": {
    "multi_match": {
      "query": "",
      "fields": ["brand", "name", "business"]
    }
  }
}
```

精确检索：term代表精确检索，range范围检索。

```java
get /hotel/_search
{
  "query": {
    "term": {
      "city": {
        "value": "上海"
      }
    }
  }
}

get /hotel/_search
{
  "query": {
    "range": {
      "price": {
        "gte": 1000,
        "lte": 2000
      }
    }
  }
}
```

坐标查询：包括矩形范围的查询、附近查询

```java
GET /hotel/_search
{
  "query": {
    "geo_bounding_box": {
      "location": {
        "top_left": { 
          "lat": 31.1,
          "lon": 121.5
        },
        "bottom_right": { 
          "lat": 30.9,
          "lon": 121.7
        }
      }
    }
  }
}

get /hotel/_search
{
  "query": {
    "geo_distance": {
      "distance": "3km",
      "location": "31.21, 121.5"
    }
  }
}
```

算分函数查询：按照查询的条件得出的文档的原始分，再累计函数分按照指定的模式计算总分，分数越高越靠前

```java
get /hotel/_search
{
  "query": {
    "function_score": {
      "query": {
        "match": {
          "all": "外滩"
        }
      },
      "functions": [
        {
          "filter": {
            "term": {
              "brand": "如家"
            }
          },
          "weight": 10
        }
      ],
      "boost_mode": "sum"
    }
  }
}
```

![1726306206880-721e4514-4742-4ecd-916b-aea8ab510f35.png](1726306206880-721e4514-4742-4ecd-916b-aea8ab510f35-823202.png)

布尔查询：布尔查询是一个或多个查询子句的组合，每一个子句就是一个**子查询**。子查询的组合方式有：

+ must：必须匹配每个子查询，类似“与”
+ should：选择性匹配子查询，类似“或”
+ must_not：必须不匹配，**不参与算分**，类似“非”
+ filter：必须匹配，不参与算分

```java
get /hotel/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": 
          {
            "name": "如家"
          }
        }
        
      ],
      "must_not": [
        {
          "range":
          {
            "price": {
              "gt": "400"
            }
          }
        }
      ],
      "filter": [
        {
          "geo_distance": {
            "distance": "10km",
            "location": {
              "lat": 31.21,
              "lon": 121.5
            }
          }
        }
      ]
    }
  }
}
```

## 搜索结果处理
### 排序
分为根据普通字段排序（keyword、数值、日期类型排序）、根据地理坐标排序：

```java
get /hotel/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "score": "desc"
    },
    {
      "price": "asc"
    }
  ]
}

get /hotel/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "_geo_distance": {
        "location": {
          "lat": 34.263161,
          "lon": 108.945277
        },
        "order": "asc",
        "unit": "km"
      }
    }
  ]
}
```

### 分页
ES中通过from和size控制分页：

```java
GET /hotel/_search
{
  "query": {
    "match_all": {}
  },
  "from": 0, // 分页开始的位置，默认为0
  "size": 10, // 期望获取的文档总数
  "sort": [
    {"price": "asc"}
  ]
}
```

深度分页问题：如果是ES集群，我们要从集群中查询top1000，那么要从每个节点中拉取1000条数据，然后总的再排名，从中获取top1000的数据。当查询分页深度较大时，汇总数据过多，对内存和CPU会产生非常大的压力，因此elasticsearch会禁止from+ size 超过10000的请求。

针对深度分页，ES提供了两种解决方案，[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html)：

+ search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。
+ scroll：原理将排序后的文档id形成快照，保存在内存。官方已经不推荐使用。

### 高亮
+ 高亮是对关键字高亮，因此**搜索条件必须带有关键字**，而不能是范围这样的查询。
+ 默认情况下，**高亮的字段，必须与搜索指定的字段一致**，否则无法高亮
+ 如果要对非搜索字段高亮，则需要添加一个属性：required_field_match=false

```java
get /hotel/_search
{
  "query": {
    "match": {
      "all": "上海"
    }
  },
  "highlight": {
    "fields": {
      "city": {
        "pre_tags": "<em>",
        "post_tags": "</em>"
      },
      "name": {
        "require_field_match": "false"
      }
    }
  }
}
```

## RestClient操作文档（DSL的实现）
**MatchAll使用Java代码实现，并且解析返回结果：**

```java
@Test
void testMatchAll() throws IOException {
    SearchRequest searchRequest = new SearchRequest("hotel");
    searchRequest.source().query(QueryBuilders.matchAllQuery());
    SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
    System.out.println("搜索结果：" + response);
    //解析结果：
    SearchHits searchHits = response.getHits();
    long total = searchHits.getTotalHits().value;
    System.out.println("总条数: " + total);
    SearchHit[] hits = searchHits.getHits();
    for (SearchHit hit : hits) {
        String sourceAsString = hit.getSourceAsString();
        System.out.println("单条数据结果" + sourceAsString);
    }
}
```

match-query单个条件查找：

```java
    @Test
    void testMatchQuery() throws IOException {
        SearchRequest searchRequest = new SearchRequest("hotel");
        searchRequest.source().query(QueryBuilders.matchQuery("all", "如家"));
        SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
        SearchHits searchHits = response.getHits();
        for (SearchHit hit : searchHits) {
            String json = hit.getSourceAsString();
            System.out.println("单挑数据结果：" + json);
        }
    }
```

match-all多个条件查找：

```java
    @Test
    void testMulMatch() throws IOException {
        SearchRequest searchRequest = new SearchRequest("hotel");
        searchRequest.source().query(QueryBuilders.multiMatchQuery("如家", "name", "business"));
        SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
        SearchHits hites = response.getHits();
        for (SearchHit hit : hites){
            String json = hit.getSourceAsString();
            System.out.println("单挑数据结果：" + json);
        }
    }
```

term精确查找：

```java
    @Test
    void testTerm() throws IOException {
        SearchRequest searchRequest = new SearchRequest("hotel");
        searchRequest.source().query(QueryBuilders.termQuery("city", "上海"));
        SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
        SearchHits hits = response.getHits();
        for (SearchHit hit : hits) {
            String json = hit.getSourceAsString();
            System.out.println("单挑数据结果：" + json);
        }
    }
```

range范围查找：

```java
    @Test
    void testRange() throws IOException {
        SearchRequest searchRequest = new SearchRequest("hotel");
        searchRequest.source().query(QueryBuilders.rangeQuery("price").gte(100).lte(400));
        SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
        SearchHits hits = response.getHits();
        for (SearchHit hit : hits) {
            String json = hit.getSourceAsString();
            System.out.println("数据结果：" + json);
        }
    }
```

bool+filter联合查找：  


```java
    @Test
    void testBoolAndFilter() throws IOException {
        SearchRequest searchRequest = new SearchRequest("hotel");
        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
        boolQueryBuilder.must(QueryBuilders.termQuery("city", "上海"));
        boolQueryBuilder.filter(QueryBuilders.rangeQuery("price").lte("250"));
        searchRequest.source().query(boolQueryBuilder);
        SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
        SearchHits hits = response.getHits();
        for (SearchHit hit: hits) {
            System.out.println("结果：" + hit.getSourceAsString());
        }
    }
```

排序加分页：

```java
    @Test
    void testSortAndPage() throws Exception{
        SearchRequest searchRequest = new SearchRequest("hotel");
        searchRequest.source().query(QueryBuilders.matchAllQuery());
        searchRequest.source().sort("price", SortOrder.ASC);
        searchRequest.source().from(1).size(2);
        SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
        SearchHits hits = response.getHits();
        for (SearchHit hit : hits) {
            System.out.println("结果：" + hit.getSourceAsString());
        }
    }
```

高亮，注意高亮的解析也不一样：  


```java
    @Test
    void testHighLight() throws  Exception {
        SearchRequest searchRequest = new SearchRequest("hotel");
        searchRequest.source().query(QueryBuilders.matchAllQuery());
        searchRequest.source().highlighter(new HighlightBuilder().field("name").requireFieldMatch(false));
        SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);
        SearchHits hits = response.getHits();
        for (SearchHit hit : hits) {
            HotelDoc hotelDoc = JSON.parseObject(hit.getSourceAsString(), HotelDoc.class);
            Map<String, HighlightField> highlightFields = hit.getHighlightFields();
            if (!CollectionUtils.isEmpty(highlightFields)) {
                HighlightField highlightField = highlightFields.get("name");
                if (highlightField != null) {
                    String name = highlightField.getFragments()[0].string();
                    hotelDoc.setName(name);
                }
            }
            System.out.println("结果：" + hotelDoc);
        }
    }
```

## 黑马旅游
### 酒店的搜索与分页
根据搜索框的查询条件，定义查询条件对象，返回指定内容的封装  


```java
    public PageResult listByOptions(RequestParam requestParam) throws IOException {
        SearchRequest search = new SearchRequest("hotel");
        String key = requestParam.getKey();
        if (key == null || "".equals(key)) {
            search.source().query(QueryBuilders.matchAllQuery());
        } else {
            search.source().query(QueryBuilders.matchQuery("all", key));
        }
        search.source()
                .from((requestParam.getPage() - 1) * requestParam.getSize())
                .size(requestParam.getSize());


        SearchResponse response = client.search(search, RequestOptions.DEFAULT);

        List<HotelDoc> hotelDocs = new ArrayList<>();
        SearchHits hits = response.getHits();
        long value = hits.getTotalHits().value;
        for (SearchHit hit : hits) {
            String json = hit.getSourceAsString();
            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
            hotelDocs.add(hotelDoc);
        }



        return new PageResult(value, hotelDocs);
    }
```

### 酒店结果过滤
添加过滤条件。

```java
    @Override
    public PageResult listByOptions(RequestParam requestParam) throws IOException {
        SearchRequest search = new SearchRequest("hotel");
        String key = requestParam.getKey();

        BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
        if (key == null || "".equals(key)) {
//            search.source().query(QueryBuilders.matchAllQuery());
            boolQuery.must(QueryBuilders.matchAllQuery());
        } else {
//            search.source().query(QueryBuilders.matchQuery("all", key));
            boolQuery.must(QueryBuilders.matchQuery("all", key));
        }

        if (requestParam.getBrand() != null && !"".equals(requestParam.getBrand())) {
            boolQuery.filter(QueryBuilders.termQuery("brand", requestParam.getBrand()));
        }
        if (requestParam.getStarName() != null && !"".equals(requestParam.getStarName())) {
            boolQuery.filter(QueryBuilders.termQuery("starName", requestParam.getStarName()));
        }

        if (requestParam.getCity() != null && !"".equals(requestParam.getCity())) {
            boolQuery.filter(QueryBuilders.termQuery("city",requestParam.getCity()));
        }

        if (requestParam.getMaxPrice() != null && requestParam.getMaxPrice() != null) {
            boolQuery.filter(QueryBuilders
                    .rangeQuery("price")
                    .lte(requestParam.getMaxPrice())
                    .gte(requestParam.getMinPrice()));
        }
        search.source()
                .query(boolQuery)
                .from((requestParam.getPage() - 1) * requestParam.getSize())
                .size(requestParam.getSize());

        SearchResponse response = client.search(search, RequestOptions.DEFAULT);

        List<HotelDoc> hotelDocs = new ArrayList<>();
        SearchHits hits = response.getHits();
        long value = hits.getTotalHits().value;
        for (SearchHit hit : hits) {
            String json = hit.getSourceAsString();
            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
            hotelDocs.add(hotelDoc);
        }



        return new PageResult(value, hotelDocs);
    }
```

### 我周围最近的酒店
```java
@Override
    public PageResult listByOptions(RequestParam requestParam) throws IOException {
        SearchRequest search = new SearchRequest("hotel");
        String key = requestParam.getKey();

        BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
        if (key == null || "".equals(key)) {
//            search.source().query(QueryBuilders.matchAllQuery());
            boolQuery.must(QueryBuilders.matchAllQuery());
        } else {
//            search.source().query(QueryBuilders.matchQuery("all", key));
            boolQuery.must(QueryBuilders.matchQuery("all", key));
        }

        if (requestParam.getBrand() != null && !"".equals(requestParam.getBrand())) {
            boolQuery.filter(QueryBuilders.termQuery("brand", requestParam.getBrand()));
        }
        if (requestParam.getStarName() != null && !"".equals(requestParam.getStarName())) {
            boolQuery.filter(QueryBuilders.termQuery("starName", requestParam.getStarName()));
        }

        if (requestParam.getCity() != null && !"".equals(requestParam.getCity())) {
            boolQuery.filter(QueryBuilders.termQuery("city",requestParam.getCity()));
        }

        if (requestParam.getMaxPrice() != null && requestParam.getMaxPrice() != null) {
            boolQuery.filter(QueryBuilders
                    .rangeQuery("price")
                    .lte(requestParam.getMaxPrice())
                    .gte(requestParam.getMinPrice()));
        }
        search.source()
                .query(boolQuery)
                .from((requestParam.getPage() - 1) * requestParam.getSize())
                .size(requestParam.getSize());
        if (requestParam.getLocation() != null && !requestParam.getLocation().equals("")) {
            search.source()
                    .sort(SortBuilders
                            .geoDistanceSort("location", new GeoPoint(requestParam.getLocation()))
                            .order(SortOrder.ASC)
                            .unit(DistanceUnit.KILOMETERS));
        }

        SearchResponse response = client.search(search, RequestOptions.DEFAULT);

        List<HotelDoc> hotelDocs = new ArrayList<>();
        SearchHits hits = response.getHits();
        long value = hits.getTotalHits().value;
        for (SearchHit hit : hits) {
            String json = hit.getSourceAsString();
            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
            Object[] sortValues = hit.getSortValues();
            if (sortValues.length > 0) {
                Object sortValue = sortValues[0];
                hotelDoc.setDistance(sortValue);
            }
            hotelDocs.add(hotelDoc);
        }




        return new PageResult(value, hotelDocs);
    }
```

### 酒店竞价排名
让给了广告费的酒店优先显示。

```java
 @Override
public PageResult listByOptions(RequestParam requestParam) throws IOException {
    SearchRequest search = new SearchRequest("hotel");
    String key = requestParam.getKey();

    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
    if (key == null || "".equals(key)) {
//            search.source().query(QueryBuilders.matchAllQuery());
        boolQuery.must(QueryBuilders.matchAllQuery());
    } else {
//            search.source().query(QueryBuilders.matchQuery("all", key));
        boolQuery.must(QueryBuilders.matchQuery("all", key));
    }

    if (requestParam.getBrand() != null && !"".equals(requestParam.getBrand())) {
        boolQuery.filter(QueryBuilders.termQuery("brand", requestParam.getBrand()));
    }
    if (requestParam.getStarName() != null && !"".equals(requestParam.getStarName())) {
        boolQuery.filter(QueryBuilders.termQuery("starName", requestParam.getStarName()));
    }

    if (requestParam.getCity() != null && !"".equals(requestParam.getCity())) {
        boolQuery.filter(QueryBuilders.termQuery("city",requestParam.getCity()));
    }

    if (requestParam.getMaxPrice() != null && requestParam.getMaxPrice() != null) {
        boolQuery.filter(QueryBuilders
                .rangeQuery("price")
                .lte(requestParam.getMaxPrice())
                .gte(requestParam.getMinPrice()));
    }

    FunctionScoreQueryBuilder functionScoreQueryBuilder = QueryBuilders.functionScoreQuery(
            boolQuery,
            new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
                    new FunctionScoreQueryBuilder.FilterFunctionBuilder(
                            QueryBuilders.termQuery("isAD", true),
                            ScoreFunctionBuilders.weightFactorFunction(10)
                    )
            });

    search.source()
            .query(functionScoreQueryBuilder)
            .from((requestParam.getPage() - 1) * requestParam.getSize())
            .size(requestParam.getSize());
    if (requestParam.getLocation() != null && !requestParam.getLocation().equals("")) {
        search.source()
                .sort(SortBuilders
                        .geoDistanceSort("location", new GeoPoint(requestParam.getLocation()))
                        .order(SortOrder.ASC)
                        .unit(DistanceUnit.KILOMETERS));
    }



    SearchResponse response = client.search(search, RequestOptions.DEFAULT);

    List<HotelDoc> hotelDocs = new ArrayList<>();
    SearchHits hits = response.getHits();
    long value = hits.getTotalHits().value;
    for (SearchHit hit : hits) {
        String json = hit.getSourceAsString();
        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
        Object[] sortValues = hit.getSortValues();
        if (sortValues.length > 0) {
            Object sortValue = sortValues[0];
            hotelDoc.setDistance(sortValue);
        }
        hotelDocs.add(hotelDoc);
    }

    return new PageResult(value, hotelDocs);
}
```



## 数据聚合
### DSL实现数据聚合
聚合（aggregations）可以让我们极其方便的进行数据的统计、分析、计算。

聚合的类型：

+ 桶聚合：按照某个字段值对文档进行分组
+ 度量（Metric）聚合：计算值
+ 管道聚合：其他基础上进行聚合

参加聚合的字段类型有：keyword、日期、数值、布尔类型。

DSL语句实现聚合的例子：

```java
get /hotel/_search
{
  "query": {		//定义查询条件
    "range": {
      "price": {
        "gte": 100,
        "lte": 200
      }
    }
  },
  "size": 0,		//表示不获取文档，只获取聚合结果
  "aggs": {				//聚合定义
    "brandAgg": {			//聚合名称
      "terms": {				//什么字段进行聚合字段
        "field": "brand",		
        "size": 10,				//聚合显示条数
        "order": {				//排序
          "score_stats.avg": "desc"
        }
      },
      "aggs": {					//聚合子聚合，分组后对每组进行运算
        "score_stats": {			//聚合名称
          "stats": {			//聚合类型
            "field": "score"		//聚合字段，运算统计的字段
          }
        }
      }
    }
  }
}
```

```java
//Java代码实现：
@Test
void testAgg() throws IOException {
    SearchRequest request = new SearchRequest("hotel");
    request.source().size(0);
    request.source().aggregation(AggregationBuilders
            .terms("brand_agg")
            .field("brand").size(20));
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    Aggregations agg = response.getAggregations();
    Terms brandAgg = agg.get("brand_agg");
    List<? extends Terms.Bucket> buckets = brandAgg.getBuckets();
    for (Terms.Bucket bucket : buckets) {
        System.out.println("品牌名称：" + bucket.getKeyAsString());
    }
}
//对应的DSL
get /hotel/_search
{
  "size": 0,
  "aggs": {
    "brand_agg": {
      "terms": {
        "field": "brand",
        "size": 10
      }
    }
  }
}
```

### 业务应用数据聚合
使用聚合功能，利用Bucket聚合，对搜索结果中的文档基于品牌分组、基于城市分组，就能得知包含哪些品牌、哪些城市了。

这里实现根据搜索的不同，动态的显示（品牌、城市、星级）过滤条件

代码实现：

```java
 @Override
    public Map<String, List<String>> filter(RequestParam requestParam) throws IOException {
        SearchRequest request = new SearchRequest("hotel");
        buildBasicQuery(requestParam, request);
        request.source().size(0);
        buildAggregation(request);
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        Map<String, List<String>> result = new HashMap<>();
        Aggregations aggregations = response.getAggregations();
        //解析结果
        List<String> brandList = getResultByAggregations(aggregations, "brandAgg");
        result.put("品牌", brandList);
        List<String> cityList = getResultByAggregations(aggregations, "cityAgg");
        result.put("城市", cityList);
        List<String> starList = getResultByAggregations(aggregations, "starAgg");
        result.put("星级", starList);

        return result;
    }

    private static List<String> getResultByAggregations(Aggregations aggregations, String name) {
        List<String> brandList = new ArrayList<>();
        Terms brandAgg = aggregations.get(name);
        List<? extends Terms.Bucket> buckets = brandAgg.getBuckets();
        for (Terms.Bucket bucket : buckets) {
            String key = bucket.getKeyAsString();
            brandList.add(key);
        }
        return brandList;
    }

    private void buildAggregation(SearchRequest request) {
        request.source().aggregation(AggregationBuilders
                .terms("brandAgg")
                .field("brand")
                .size(100));
        request.source().aggregation(AggregationBuilders
                .terms("cityAgg")
                .field("city")
                .size(100));
        request.source().aggregation(AggregationBuilders
                .terms("starAgg")
                .field("starName")
                .size(100));
    }
```

## 自动补全
### DSL实现自动补全
要想根据拼音联想自动补全，必须给es安装插件，安装方式和ik一样，安装包地址：[https://github.com/medcl/elasticsearch-analysis-pinyin](https://github.com/medcl/elasticsearch-analysis-pinyin)

默认的拼音分词器会将汉字单个的分为拼音，所以我们需要自定义分词器。

```java
post /_analyze
{
  "text": "如家酒店真不错",
  "analyzer": "pinyin"
}
```

自定义分词器分为三步：字符过滤、切割词条、对词条进行处理

![1726564056007-035dfc82-e106-47af-918a-98676951d66d.png](1726564056007-035dfc82-e106-47af-918a-98676951d66d-221877.png)

```java
PUT /test
{
  "settings":{
    "analysis":{
      "analyzer":{
        "my_analyzer":{
          "tokenizer":"ik_max_word",
          "filter":"py"
          }
        },
      "filter":{
          "py": {
          "type":"pinyin",
          "keep_full_pinyin":false,
          "keep_joined_full_pinyin":true,
          "keep_original":true,
          "limit_first_letter_length":16,
          "remove_duplicated_term":true,
          "none_chinese_pinyin_tokenize":false
          }
        }
      }
  },
  "mappings":{
    "properties":{
      "name":{
      "type":"text",
      "analyzer":"my_analyzer",
      "search_analyzer":"ik_smart"
      }
    }
  }
}
post /test/_analyze
{
  "text": ["如家酒店还不错"],
  "analyzer": "my_analyzer"
}
```

自动补全：查询会匹配用户输入内容的词条并返回，为了提高查询的效率。这了对补全查询的字段有一定的约束：

+ 字段类型必须是Completion
+ 字段的内容一般是用来补全多个词条形成的数组

```java
put test
{
  "mappings": {
    "properties": {
      "title": {
        "type": "completion"
      }
    }
  }
}

post /test/_doc
{
  "title": ["SK-II", "switch"] 
}

get /test/_search
{
  "suggest": {
    "title_suggest": {
      "text": "s",
      "completion": {
        "field": "title",
        "skip_duplicates": true,
        "size": 10
      }
    }
  }
}

```

### RestAPI业务实现
测试使用RestAPI实现自动补全：

![1726566117211-0b07e92a-3684-4628-96f6-5fe350d8569a.png](1726566117211-0b07e92a-3684-4628-96f6-5fe350d8569a-895514.png)

![1726566122360-11d0d930-2431-416c-9da2-91425b1a372c.png](1726566122360-11d0d930-2431-416c-9da2-91425b1a372c-151979.png)

```java
    @Test
    void testSuggest() throws IOException {
        SearchRequest request = new SearchRequest("hotel");
        request.source().suggest(new SuggestBuilder()
                .addSuggestion("mySuggestion", SuggestBuilders
                        .completionSuggestion("suggestion")
                        .prefix("h")
                        .skipDuplicates(true)
                        .size(10)));
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        Suggest suggest = response.getSuggest();
        CompletionSuggestion suggestion = suggest.getSuggestion("mySuggestion");
        for (CompletionSuggestion.Entry.Option option : suggestion.getOptions()) {
            String text = option.getText().string();
            System.out.println("提示：" + text);
        }
    }
```

业务实现：

```java
    @Override
    public List<String> suggestion(String prefix) throws IOException {
        SearchRequest request = new SearchRequest("hotel");
        request.source().suggest(new SuggestBuilder()
                .addSuggestion("suggestion",
                        SuggestBuilders.completionSuggestion("suggestion")
                                .prefix(prefix)
                                .skipDuplicates(true)
                                .size(10)));
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        Suggest suggest = response.getSuggest();
        CompletionSuggestion suggestions = suggest.getSuggestion("suggestion");
        List<CompletionSuggestion.Entry.Option> options = suggestions.getOptions();
        List<String> list = new ArrayList<>();
        for (CompletionSuggestion.Entry.Option option : options) {
            String text = option.getText().toString();
            list.add(text);
        }


        return list;
    }
```

## 数据同步
elasticsearch中的酒店数据来自于mysql数据库，因此mysql数据发生改变时，elasticsearch也必须跟着改变，这个就是elasticsearch与mysql之间的数据同步。

数据同步实现的三种方式：

1. 同步通知，数据库新增完调用更新es索引的接口

![1726566362135-bc0e27d4-8ebd-4c2c-9958-d46204129388.png](1726566362135-bc0e27d4-8ebd-4c2c-9958-d46204129388-234227.png)

2. 异步通知，数据库新增完，调用mq通知调用es的更新索引库接口来处理，不需要等待接口返回

![1726566400333-b7e977ba-25eb-4d86-b979-f5d01742f252.png](1726566400333-b7e977ba-25eb-4d86-b979-f5d01742f252-819890.png)

3. 监听binlog，binlog记载mysql的增、删、改的操作

![1726566437684-15ecddad-d65f-42e3-9133-e5f92e88df2f.png](1726566437684-15ecddad-d65f-42e3-9133-e5f92e88df2f-057110.png)



实现通过rabbitmq通知es同步修改索引：（以删除为例）

```java
@PostMapping
public void saveHotel(@RequestBody Hotel hotel){
    hotelService.save(hotel);
    //删除完发送mq消息通知
    //hotel.topic	
    //hotel.insert
    rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE, MqConstants.HOTEL_INSERT_KEY, hotel.getId());
}

//监听器实时监听队列
@RabbitListener(queues = MqConstants.HOTEL_INSERT_QUEUE)
public void listenHotelInsertOrUpdate(Long id){
    hotelService.insertById(id);
}
@Override
public void insertById(Long id) {
    System.out.println("正在新增/修改.......");
    try {
        // 0.根据id查询酒店数据
        Hotel hotel = getById(id);
        // 转换为文档类型
        HotelDoc hotelDoc = new HotelDoc(hotel);

        // 1.准备Request对象
        IndexRequest request = new IndexRequest("hotel").id(hotel.getId().toString());
        // 2.准备Json文档
        request.source(JSON.toJSONString(hotelDoc), XContentType.JSON);
        // 3.发送请求
        client.index(request, RequestOptions.DEFAULT);
    } catch (IOException e) {
        throw new RuntimeException(e);
    }
}
```

## 集群
复杂后续再说







# Sentinel
## 雪崩问题和解决方案
一个微服务的调用可能涉及很多个微服务。如果一个微服务异常了，那么会导致调用这个微服务的所有微服务阻塞， 久而久之，就会造成这个服务器的瘫痪。由此就产生了雪崩。

解决雪崩的常见的四种方式：

+ 超时处理：设定超时时间，超过一定时间没有响应返回错误信息，不会无休止的等待
+ 仓壁模式：类似于船舱的设计，分离多个独立空间，船体破损，只允许部分空间进入，将故障控制在一定的空间中，避免整个淹没。凭借这个思想，可以控制每个业务的线程数，避免耗尽整个线程资源，这也叫做线程隔离。
+ 断路器：统计某个服务的请求数量，异常数量，统计异常比，超过一定的阀值断开该业务
+ 限流（流量控制）：限制业务访问的QPS（每秒访问次数），避免因为访问的突增而古筝。

可以认为：

限流是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种预防措施。

超时处理、线程隔离、降级熔断是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种补救措施。







## 服务保护技术对比
主流的服务保护技术Hystrix和Sentinel对比：

|  | **Sentinel** | **Hystrix** |
| --- | --- | --- |
| 隔离策略 | 信号量隔离 | 线程池隔离/信号量隔离 |
| 熔断降级策略 | 基于慢调用比例或异常比例 | 基于失败比率 |
| 实时指标实现 | 滑动窗口 | 滑动窗口（基于 RxJava） |
| 规则配置 | 支持多种数据源 | 支持多种数据源 |
| 扩展性 | 多个扩展点 | 插件的形式 |
| 基于注解的支持 | 支持 | 支持 |
| 限流 | 基于 QPS，支持基于调用关系的限流 | 有限的支持 |
| 流量整形 | 支持慢启动、匀速排队模式 | 不支持 |
| 系统自适应保护 | 支持 | 不支持 |
| 控制台 | 开箱即用，可配置规则、查看秒级监控、机器发现等 | 不完善 |
| 常见框架的适配 | Servlet、Spring Cloud、Dubbo、gRPC  等 | Servlet、Spring Cloud Netflix |


早期比较流行的是Hystrix框架，但目前国内实用最广泛的还是阿里巴巴的Sentinel框架

## Sentinel安装
Docker安装：

[docker运行sentinel、Docker打包Sentinel 镜像、控制台环境搭建及使用介绍_docker sentinel-CSDN博客](https://blog.csdn.net/create_bj/article/details/126968352)

Sentinel是阿里巴巴开源的一款微服务流量控制组件。官网地址：[https://sentinelguard.io/zh-cn/index.html](https://sentinelguard.io/zh-cn/index.html)

启动命令：

```java
java --add-opens java.base/java.lang=ALL-UNNAMED   -Dserver.port=8090 -jar sentinel-dashboard-1.8.1.jar
```

升级 JDK：如果你使用的是 JDK 9 或以上版本，可以尝试在启动时添加以下 JVM 参数，来开放模块访问：

 --add-opens java.base/java.lang=ALL-UNNAMED  

访问地址：localhost:8090

账号密码默认：sentinel

## 微服务整合Sentinel
1. 引入依赖

```java
<!--sentinel-->
<dependency>
    <groupId>com.alibaba.cloud</groupId> 
    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>
</dependency>
```

2. 配置

```java
server:
  port: 8088
spring:
  cloud: 
    sentinel:
      transport:
        dashboard: localhost:8080
```

3. 访问启动服务的任意接口，观察sentinel控制台

## 流量控制
当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、Mapper，这样的一个调用链就叫做簇点链路。簇点链路中被监控的每一个接口就是一个资源。

Sentinel会监控簇点链路中的每一个资源，我们可以通过控制台提供的功能设置资源的流量。

这里使用Jmeter帮助我们测试。

![1726627229684-74deb55d-bc3b-4c4f-ac07-80a512f9d479.png](1726627229684-74deb55d-bc3b-4c4f-ac07-80a512f9d479-519067.png)

Sentinel提供的三种流控模式：

+ 直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式
+ 关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流
+ 链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流

直接模式：表示该资源QPS（每秒调用的次数）的阀值为2，超过的直接断掉

![1726627304248-18cd7706-73a6-42db-a9be-67f360949d52.png](1726627304248-18cd7706-73a6-42db-a9be-67f360949d52-746596.png)

关联模式：当/write超过阀值时，对/read进行资源限流

![1726627371005-c1783402-c97d-439b-927a-68b1db6da6b6.png](1726627371005-c1783402-c97d-439b-927a-68b1db6da6b6-864677.png)

链路模式：只有从/order/query进行的业务请求访问到goods会被限流，这里goods是个方法，被@SentinelResource("goods")注解修饰

![1726627434550-93105853-4108-40b6-ad7a-4542d60f1469.png](1726627434550-93105853-4108-40b6-ad7a-4542d60f1469-910227.png)

注意：但是sentinel默认会给进入SpringMVC的所有请求设置同一个root资源，会导致链路模式失效。

关闭SpringMVC的资源聚合：

```java
spring:
  cloud:
    sentinel:
      web-context-unify: false # 关闭context整合
```

流控效果：

+ 快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。是默认的处理方式。
+ warm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。请求阈值初始值是 maxThreshold / coldFactor，持续指定时长后，逐渐提高到maxThreshold值。而coldFactor的默认值是3.
+ 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长

热点参数限流：

分别统计参数值相同的请求，判断是否超过QPS阈值。

需要通过@SentinelResource注解标记接口![1726629540112-a654f588-65f5-4094-837b-6e311b4e1aa2.png](1726629540112-a654f588-65f5-4094-837b-6e311b4e1aa2-038141.png)



## 线程隔离和熔断降级
线程隔离：调用者在调用服务提供者时，给每个调用的请求分配独立线程池，出现故障时，最多消耗这个线程池内资源，避免把调用者的所有资源耗尽。

熔断降级：是在调用方这边加入断路器，统计对服务提供者的调用，如果调用的失败比例过高，则熔断该业务，不允许访问该服务的提供者了。

可以看到，不管是线程隔离还是熔断降级，都是对客户端（调用方）的保护。需要在调用方 发起远程调用时做线程隔离、或者服务熔断。而我们的微服务远程调用都是基于Feign来完成的，因此我们需要将Feign与Sentinel整合，在Feign里面实现线程隔离和服务熔断。

### Feign整合Sentinel
1. 开启feign支持Sentinel

```java
feign:
  sentinel:
    enabled: true # 开启feign对sentinel的支持
```

2. 编写失败降级逻辑：

给FeignClient编写失败后的降级逻辑

①方式一：FallbackClass，无法对远程调用的异常做处理

②方式二：FallbackFactory，可以对远程调用的异常做处理，我们选择这种

定义类实现FallbackFactory接口

```java
@Slf4j
public class UserClientFallbackFactory implements FallbackFactory<UserClient> {
    @Override
    public UserClient create(Throwable throwable) {
        return new UserClient() {
            @Override
            public User findById(Long id) {
                log.error("查询用户异常", throwable);
                return new User();
            }
        };
    }
}
```

注册bean:

```java
@Bean
public UserClientFallbackFactory userClientFallbackFactory(){
    return new UserClientFallbackFactory();
}
```

注解@FeignClient加入fallbackFactory:

```java
@FeignClient(value = "userservice", fallbackFactory = UserClientFallbackFactory.class)
public interface UserClient {

    @GetMapping("/user/{id}")
    User findById(@PathVariable("id") Long id);
}
```

3. Sentinel控制台可以看到：

![1726630498101-f619646c-db52-4953-95a3-8b1262188941.png](1726630498101-f619646c-db52-4953-95a3-8b1262188941-112575.png)



### 线程隔离
线程隔离的方式有

+ 信号量隔离（Sentinel默认）：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求。
+ 线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果

![1726642396828-40ae7e05-18a2-4051-aae6-fb4dfc53dd5f.png](1726642396828-40ae7e05-18a2-4051-aae6-fb4dfc53dd5f-377909.png)

该资源能使用用的tomcat线程数的最大值为2。

### 熔断降级
熔断降级是解决雪崩问题的重要手段。其思路是由断路器统计服务调用的异常比例、慢请求比例，如果超出阈值则会熔断该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。

断路器是通过状态机来完成熔断和放行的：

![1726643024868-03ff4a44-65bd-40f1-9978-54cc303e2f8d.png](1726643024868-03ff4a44-65bd-40f1-9978-54cc303e2f8d-224878.png)

状态机包括三个状态：

+ closed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态
+ open：打开状态，服务调用被**熔断**，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态
+ half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。
    - 请求成功：则切换到closed状态
    - 请求失败：则切换到open状态

断路器熔断策略有三种：慢调用、异常比例、异常数

+ 慢调用：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断。

![1726643058902-56cd63d1-c0b6-488a-9887-7fe8c1cdaa2c.png](1726643058902-56cd63d1-c0b6-488a-9887-7fe8c1cdaa2c-345529.png)

+ 异常比例或异常数：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现异常的比例达到设定的比例阈值（或超过指定异常数），则触发熔断。

![1726643082575-516411dc-ee84-4ac8-9c81-d289ab565a4a.png](1726643082575-516411dc-ee84-4ac8-9c81-d289ab565a4a-090157.png)

## 授权规则
通过授权规则配置进出请求在origin的黑白名单。

![1726645135665-3089f590-e1c0-4407-b02d-7695cfbb38a7.png](1726645135665-3089f590-e1c0-4407-b02d-7695cfbb38a7-577978.png)

如何获取origin？

Sentinel是通过RequestOriginParser这个接口的parseOrigin来获取请求的来源的。默认情况下，sentinel不管请求者从哪里来，返回值永远是default，也就是说一切请求的来源都被认为是一样的值default。

```java
@Component
public class HeaderOriginParser implements RequestOriginParser {
    @Override
    public String parseOrigin(HttpServletRequest request) {
        // 1.获取请求头
        String origin = request.getHeader("origin");
        // 2.非空判断
        if (StringUtils.isEmpty(origin)) {
            origin = "blank";
        }
        return origin;
    }
}
```

给网关添加请求头：

```java
spring:
  cloud:
    gateway:
      default-filters:
        - AddRequestHeader=origin,gateway
```

sentinel控制台配置规则。

测试发现只有通过网关发送的请求能够正确处理，直接通过接口访问的请求被拒绝。



## 自定义异常结果
现在被拒绝的异常结果都是：

![1726645325985-fd50cd2a-b935-4ba4-bd71-1b8c3820c659.png](1726645325985-fd50cd2a-b935-4ba4-bd71-1b8c3820c659-368068.png)

无法得知是限流还是降级还是授权拦截。

自定义异常时的返回结果，需要实现BlockExceptionHandler接口：  
 这个方法有三个参数：

+ HttpServletRequest request：request对象
+ HttpServletResponse response：response对象
+ BlockException e：被sentinel拦截时抛出的异常

```java
@Component
public class SentinelExceptionHandler implements BlockExceptionHandler {
    @Override
    public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception {
        String msg = "未知异常";
        int status = 429;

        if (e instanceof FlowException) {
            msg = "请求被限流了";
        } else if (e instanceof ParamFlowException) {
            msg = "请求被热点参数限流";
        } else if (e instanceof DegradeException) {
            msg = "请求被降级了";
        } else if (e instanceof AuthorityException) {
            msg = "没有权限访问";
            status = 401;
        }

        response.setContentType("application/json;charset=utf-8");
        response.setStatus(status);
        response.getWriter().println("{\"msg\": " + msg + ", \"status\": " + status + "}");
    }
}
```

## 规则持久化
Sentinel有三种规则持久化模式：

+ 默认模式（放在内存中，重启后消失）
+ pull，sentinel推送消息，可以保存在本地文件中
+ push，sentinel监听nacos等远程配置中心，获取配置变更的推送消息，完成本地配置更新
1. 修改order-server（调用者）,添加依赖

```java
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-datasource-nacos</artifactId>
</dependency>
```

2. 添加规则：监控Nacos中的sentinel规则

```java
spring:
  cloud:
    sentinel:
      datasource:
        flow:
          nacos:
            server-addr: localhost:8848 # nacos地址
            dataId: orderservice-flow-rules
            groupId: SENTINEL_GROUP
            rule-type: flow # 还可以是：degrade、authority、param-flow
```

3. 修改Sentinel的源码
4. 去掉sentinel-dashboard中pom文件的依赖中的test范围：

```java
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-datasource-nacos</artifactId>
</dependency>
```

5. 添加nacos支持：在sentinel-dashboard的test包下，已经编写了对nacos的支持，我们需要将其拷贝到main下。

![1727058219758-8c86d72a-26a9-4beb-8eb7-b7b0057ec642.png](1727058219758-8c86d72a-26a9-4beb-8eb7-b7b0057ec642-601524.png)

6. 修改Nacos地址，修改nacos包下的NacosConfig类：

![1727058248427-5220c281-b5fc-4445-8b2c-4db6b8a31088.png](1727058248427-5220c281-b5fc-4445-8b2c-4db6b8a31088-109927.png)

7. 在sentinel-dashboard的application.properties中添加nacos地址配置：nacos.addr=localhost:8848
8. 配置数据源：修改com.alibaba.csp.sentinel.dashboard.controller.v2包下的FlowControllerV2类

![1727058300817-e24b3168-8cc6-4b9b-b944-2973e76edb73.png](1727058300817-e24b3168-8cc6-4b9b-b944-2973e76edb73-834456.png)

9. 修改前端：修改src/main/webapp/resources/app/scripts/directives/sidebar/目录下的sidebar.html文件：

![1727058338623-c182279f-0e7b-4c7f-b164-b85391a9c0aa.png](1727058338623-c182279f-0e7b-4c7f-b164-b85391a9c0aa-745792.png)

10. 重新编译打包：

![1727058362475-a442f47b-4390-40f3-93df-6011f3132b1c.png](1727058362475-a442f47b-4390-40f3-93df-6011f3132b1c-217439.png)

11. 启动Sentinel：java  --add-opens java.base/java.lang=ALL-UNNAMED -jar sentinel-dashboard.jar  
如果要修改nacos地址，需要添加参数：

```java
java -jar -Dnacos.addr=localhost:8848 sentinel-dashboard.jar
```

12. 效果：nacos默认会创建order-service配置的文件保存Sentinel中的配置：重启后的Sentinel也会自动读取

![1727058468976-8980444a-0018-4702-82f6-3bb7946dd533.png](1727058468976-8980444a-0018-4702-82f6-3bb7946dd533-437650.png)





## 网关整合sentinel
[https://segmentfault.com/a/1190000044009720#item-1](https://segmentfault.com/a/1190000044009720#item-1)



# 链路追踪
[SpringBoot2整合链路追踪Zipkin监控mysql和redis（跟我学SpringCloud系列）_zipkin 追踪redis-CSDN博客](https://blog.csdn.net/ron03129596/article/details/109063339)

[微服务—链路追踪（Sleuth+Zipkin）_链路追踪使用什么技术-CSDN博客](https://blog.csdn.net/qq_40587263/article/details/117338097)

# 分布式事务
## 本地事务
本地事务是指单个服务所开启的事务，满足ACID四个原则：

+ 原子性：所有的操作要么全部完成，要么全部失败
+ 一致性：保证数据库内部完整性约束、声明性约束
+ 隔离性：对同一资源的事务不能同时发生
+ 持久性：对数据库所做的所有修改永久保存，不管是否发生异常

## 分布式事务
分布式事务就不是单个服务下产生的事务，例如：

+ 跨数据源的分布式事务
+ 跨事务的分布式事务
+ 综合情况

订单的创建、库存的扣减、账户扣款在每一个服务和数据库内是一个本地事务，可以保证ACID原则。

但是当我们把三件事情看做一个"业务"，要满足保证“业务”的原子性，要么所有操作全部成功，要么全部失败，不允许出现部分成功部分失败的现象，这就是分布式系统下的事务了。

此时ACID难以满足，这是分布式事务要解决的问题



## CAP定理
1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。

+ Consistency（一致性）：用户访问分布式的任意结点，得到的数据应该完全一致
+ Available（可用性）：用户访问任意一个节点，应该能够响应用户的请求，而不是超时或者拒绝
+ Partition tolerance（分区容错性）：分区指由于网络原因或者其他故障导致节点与其他结点失去连接，形成的独立分区。容错指当出现分区时，应该系统能够持续对外服务。

在分布式系统中，系统间的网络不能100%保证健康，一定会有故障的时候，而服务有必须对外保证服务。因此Partition Tolerance不可避免。

如果n3和n1、n2断开连接了，此时当节点接收到新的数据变更时，就会出现问题了：

+ 如果此时要保证一致性，就必须等待网络恢复，完成数据同步后，整个集群才对外提供服务，服务处于阻塞状态，不可用。
+ 如果此时要保证可用性，就不能等待网络恢复，那node01、node02与node03之间就会出现数据不一致。

所以在P一定会出现的情况下，A和C只能选择一个。

## BASE理论
BASE理论是对CAP定理的一种解决方法：

+ **Basically Available** **（基本可用）**：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。
+ ** Soft State（软状态）：**在一定时间内，允许出现中间状态，比如临时的不一致状态。
+ **Eventually Consistent（最终一致性）**：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。

两种解决方法：

+ AP模式：各子事务分别执行和提交，允许出现结果不一致，然后采用弥补措施恢复数据即可，实现最终一致。
+ CP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致。但事务等待过程中，处于弱可用状态。

但不管是哪一种模式，都需要在子系统事务之间互相通讯，协调事务状态，也就是需要一个事务协调者(TC)：

![1727079155124-ef3952b8-b9ee-4a1d-8d31-bc34b1da86b9.png](1727079155124-ef3952b8-b9ee-4a1d-8d31-bc34b1da86b9-944937.png)

这里的子系统事务，称为**分支事务**；有关联的各个分支事务在一起称为**全局事务**。

## Seata
Seata是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。

官网地址：[http://seata.io/](http://seata.io/)，其中的文档、播客中提供了大量的使用说明、源码分析。

Seata事务管理的三个角色：

+ **TC (Transaction Coordinator) -** **事务协调者：**维护全局和分支事务的状态，协调全局事务提交或回滚。
+ **TM (Transaction Manager) -** **事务管理器：**定义全局事务的范围、开始全局事务、提交或回滚全局事务。
+ **RM (Resource Manager) -** **资源管理器：**管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。

架构图：

![1727079431928-f52ff4f1-3d28-4fdf-a793-fa8799828ef6.png](1727079431928-f52ff4f1-3d28-4fdf-a793-fa8799828ef6-940418.png)

Seata基于上面的架构，提供了四种不同的解决方案：

+ XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入
+ TCC模式：最终一致的分阶段事务模式，有业务侵入
+ AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式
+ SAGA模式：长事务模式，有业务侵入

### 部署TC服务
不管哪一种模式，都需要TC的协调。

1. 下载Seata-server：[http](http://seata.io/zh-cn/blog/download.html)[://seata.io/zh-cn/blog/download](http://seata.io/zh-cn/blog/download.html)[.](http://seata.io/zh-cn/blog/download.html)[html](http://seata.io/zh-cn/blog/download.html)
2. 修改conf/registry.conf:

```java
registry {
  # tc服务的注册中心类，这里选择nacos，也可以是eureka、zookeeper等
  type = "nacos"

  nacos {
    # seata tc 服务注册到 nacos的服务名称，可以自定义
    application = "seata-tc-server"
    serverAddr = "127.0.0.1:8848"
    group = "DEFAULT_GROUP"
    namespace = ""
    cluster = "SH"
    username = "nacos"
    password = "nacos"
  }
}

config {
  # 读取tc服务端的配置文件的方式，这里是从nacos配置中心读取，这样如果tc是集群，可以共享配置
  type = "nacos"
  # 配置nacos地址等信息
  nacos {
    serverAddr = "127.0.0.1:8848"
    namespace = ""
    group = "SEATA_GROUP"
    username = "nacos"
    password = "nacos"
    dataId = "seataServer.properties"
  }
}
```

3. nacos添加配置，根据配置信息创建上面写的文件，并且输入内容：

```java
# 数据存储方式，db代表数据库
store.mode=db
store.db.datasource=druid
store.db.dbType=mysql
store.db.driverClassName=com.mysql.jdbc.Driver
store.db.url=jdbc:mysql://127.0.0.1:3306/seata?useUnicode=true&rewriteBatchedStatements=true
store.db.user=root
store.db.password=123
store.db.minConn=5
store.db.maxConn=30
store.db.globalTable=global_table
store.db.branchTable=branch_table
store.db.queryLimit=100
store.db.lockTable=lock_table
store.db.maxWait=5000
# 事务、日志等配置
server.recovery.committingRetryPeriod=1000
server.recovery.asynCommittingRetryPeriod=1000
server.recovery.rollbackingRetryPeriod=1000
server.recovery.timeoutRetryPeriod=1000
server.maxCommitRetryTimeout=-1
server.maxRollbackRetryTimeout=-1
server.rollbackRetryTimeoutUnlockEnable=false
server.undo.logSaveDays=7
server.undo.logDeletePeriod=86400000

# 客户端与服务端传输方式
transport.serialization=seata
transport.compressor=none
# 关闭metrics功能，提高性能
metrics.enabled=false
metrics.registryType=compact
metrics.exporterList=prometheus
metrics.exporterPrometheusPort=9898
```

4. 创建数据库表：tc服务在管理分布式事务时，需要记录事务相关数据到数据库中，你需要提前创建好这些表。

```java

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- 分支事务表
-- ----------------------------
DROP TABLE IF EXISTS `branch_table`;
CREATE TABLE `branch_table`  (
  `branch_id` bigint(20) NOT NULL,
  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `transaction_id` bigint(20) NULL DEFAULT NULL,
  `resource_group_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `resource_id` varchar(256) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `branch_type` varchar(8) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `status` tinyint(4) NULL DEFAULT NULL,
  `client_id` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `gmt_create` datetime(6) NULL DEFAULT NULL,
  `gmt_modified` datetime(6) NULL DEFAULT NULL,
  PRIMARY KEY (`branch_id`) USING BTREE,
  INDEX `idx_xid`(`xid`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

-- ----------------------------
-- 全局事务表
-- ----------------------------
DROP TABLE IF EXISTS `global_table`;
CREATE TABLE `global_table`  (
  `xid` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `transaction_id` bigint(20) NULL DEFAULT NULL,
  `status` tinyint(4) NOT NULL,
  `application_id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `transaction_service_group` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `transaction_name` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `timeout` int(11) NULL DEFAULT NULL,
  `begin_time` bigint(20) NULL DEFAULT NULL,
  `application_data` varchar(2000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `gmt_create` datetime NULL DEFAULT NULL,
  `gmt_modified` datetime NULL DEFAULT NULL,
  PRIMARY KEY (`xid`) USING BTREE,
  INDEX `idx_gmt_modified_status`(`gmt_modified`, `status`) USING BTREE,
  INDEX `idx_transaction_id`(`transaction_id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;

SET FOREIGN_KEY_CHECKS = 1;
```

5. 启动服务：bin目录下的seata-server.bat

解决jdk不匹配问题：去掉下面的参数：

```java
-XX:+CMSParallelRemarkEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=75
```

### 服务集成Seata
1. 引入依赖：

```java
<!--seata-->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-seata</artifactId>
    <exclusions>
        <!--版本较低，1.3.0，因此排除--> 
        <exclusion>
            <artifactId>seata-spring-boot-starter</artifactId>
            <groupId>io.seata</groupId>
        </exclusion>
    </exclusions>
</dependency>
<dependency>
    <groupId>io.seata</groupId>
    <artifactId>seata-spring-boot-starter</artifactId>
    <!--seata starter 采用1.4.2版本-->
    <version>${seata.version}</version>
</dependency>
```

2. 配置信息：

```java
seata:
  registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址
    type: nacos # 注册中心类型 nacos
    nacos:
      server-addr: 127.0.0.1:8848 # nacos地址
      namespace: "" # namespace，默认为空
      group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP
      application: seata-tc-server # seata服务名称
      username: nacos
      password: nacos
  tx-service-group: seata-demo # 事务组名称
  service:
    vgroup-mapping: # 事务组与cluster的映射关系
      seata-demo: SH
```

### 实现XA模式
强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入

XA的实现原理是基于两阶段提交。

XA模型图：

![1727080451526-c0b8b81d-4c7f-491f-b683-acfb72f9fde4.png](1727080451526-c0b8b81d-4c7f-491f-b683-acfb72f9fde4-226175.png)



XA模式的优点是什么？

+ 事务的强一致性，满足ACID原则。
+ 常用数据库都支持，实现简单，并且没有代码侵入

XA模式的缺点是什么？

+ 因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差
+ 依赖关系型数据库实现事务

**实现XA模式：**

1. 配置文件开启XA模式：

```java
seata:
  data-source-proxy-mode: XA
```

2. 入口方法添加@GlobalTransactional注解

### 实现AT模式
AT模式同样是分阶段提交的事务模型，不过缺弥补了XA模型中资源锁定周期过长的缺陷。Seata的默认模式。

AT模型：

![1727082010923-56808f7c-8f71-4ad9-b477-789a2c630a55.png](1727082010923-56808f7c-8f71-4ad9-b477-789a2c630a55-989462.png)

简述AT模式与XA模式最大的区别是什么？

+ XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。
+ XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。
+ XA模式强一致；AT模式最终一致

**脏写问题：如果有多个服务去访问AT模式的服务，就会出现脏写问题。因为AT模式提交后释放了锁，其他业务可以读取修改后的值，但是此时没有回滚。**

解决思路就是引入了全局锁的概念。在释放DB锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。

AT模式的优点：

+ 一阶段完成直接提交事务，释放数据库资源，性能比较好
+ 利用全局锁实现读写隔离
+ 没有代码侵入，框架自动完成回滚和提交

AT模式的缺点：

+ 两阶段之间属于软状态，属于最终一致
+ 框架的快照功能会影响性能，但比XA模式要好很多

实现：

1. AT模式需要一个全局锁表记录全局锁，另一张表记录数据快照undo_log
2. 修改配置

```java
seata:
  data-source-proxy-mode: AT # 默认就是AT
```

### 实现TCC模式
TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码来实现数据恢复。需要实现三个方法：

+ Try：资源的检测和预留； 
+ Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。
+ Cancel：预留资源释放，可以理解为try的反向操作。

TCC模型图：

![1727082588188-c782d72f-76c7-4fc2-8825-7a4f006a1a52.png](1727082588188-c782d72f-76c7-4fc2-8825-7a4f006a1a52-883737.png)

TCC的优点是什么？

+ 一阶段完成直接提交事务，释放数据库资源，性能好
+ 相比AT模型，无需生成快照，无需使用全局锁，性能最强
+ 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库

TCC的缺点是什么？

+ 有代码侵入，需要人为编写try、Confirm和Cancel接口，太麻烦
+ 软状态，事务是最终一致
+ 需要考虑Confirm和Cancel的失败情况，做好幂等处理

**空回滚：**如果业务在try的时候发生阻塞，可能导致全局事务超时而触发cancel，在未执行try时先执行了cancel，这是不能做回滚，也叫空回滚。

**业务悬挂：**上面空回滚的业务恢复了try，由于cancel已经执行过了，那么try的执行永远不会回滚或者提交。

**实现：**

1. 创建业务表存储冻结资源，事务状态: 

```java
CREATE TABLE `account_freeze_tbl` (
  `xid` varchar(128) NOT NULL,
  `user_id` varchar(255) DEFAULT NULL COMMENT '用户id',
  `freeze_money` int(11) unsigned DEFAULT '0' COMMENT '冻结金额',
  `state` int(1) DEFAULT NULL COMMENT '事务状态，0:try，1:confirm，2:cancel',
  PRIMARY KEY (`xid`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT;
```

2. 声明TCC的三个接口

```java
@LocalTCC
public interface AccountTCCService {

    @TwoPhaseBusinessAction(name = "deduct", commitMethod = "confirm", rollbackMethod = "cancel")
    void deduct(@BusinessActionContextParameter(paramName = "userId") String userId,
                @BusinessActionContextParameter(paramName = "money")int money);

    boolean confirm(BusinessActionContext ctx);

    boolean cancel(BusinessActionContext ctx);
}
```

3. 实现接口

```java
@Service
@Slf4j
public class AccountTCCServiceImpl implements AccountTCCService {

    @Autowired
    private AccountMapper accountMapper;
    @Autowired
    private AccountFreezeMapper freezeMapper;

    @Override
    @Transactional
    public void deduct(String userId, int money) {
        // 0.获取事务id
        String xid = RootContext.getXID();
        // 1.扣减可用余额
        accountMapper.deduct(userId, money);
        // 2.记录冻结金额，事务状态
        AccountFreeze freeze = new AccountFreeze();
        freeze.setUserId(userId);
        freeze.setFreezeMoney(money);
        freeze.setState(AccountFreeze.State.TRY);
        freeze.setXid(xid);
        freezeMapper.insert(freeze);
    }

    @Override
    public boolean confirm(BusinessActionContext ctx) {
        // 1.获取事务id
        String xid = ctx.getXid();
        // 2.根据id删除冻结记录
        int count = freezeMapper.deleteById(xid);
        return count == 1;
    }

    @Override
    public boolean cancel(BusinessActionContext ctx) {
        // 0.查询冻结记录
        String xid = ctx.getXid();
        AccountFreeze freeze = freezeMapper.selectById(xid);

        // 1.恢复可用余额
        accountMapper.refund(freeze.getUserId(), freeze.getFreezeMoney());
        // 2.将冻结金额清零，状态改为CANCEL
        freeze.setFreezeMoney(0);
        freeze.setState(AccountFreeze.State.CANCEL);
        int count = freezeMapper.updateById(freeze);
        return count == 1;
    }
}
```

### SAGA模式
Saga 模式是 Seata 即将开源的长事务解决方案，将由蚂蚁金服主要贡献。

Seata官网对于Saga的指南：[https://seata.io/zh-cn/docs/user/saga.html](https://seata.io/zh-cn/docs/user/saga.html)

原理：分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。

优点：

+ 事务参与者可以基于事件驱动实现异步调用，吞吐高
+ 一阶段直接提交事务，无锁，性能好
+ 不用编写TCC中的三个阶段，实现简单

缺点：

+ 软状态持续时间不确定，时效性差
+ 没有锁，没有事务隔离，会有脏写

### 四种模式的对比
![1727083193880-dcf7a945-771d-4561-9966-551fc898489a.png](1727083193880-dcf7a945-771d-4561-9966-551fc898489a-690234.png)

### Seata高可用架构模型
Seata的TC作为核心，应该部署集群来保证服务的可用性，但集群并不能确保100%安全，万一集群所在机房故障怎么办？所以如果要求较高，一般都会做异地多机房容灾。

微服务基于事务组（tx-service-group)与TC集群的映射关系，来查找当前应该使用哪个TC集群。当SH集群故障时，只需要将vgroup-mapping中的映射关系改成HZ。则所有微服务就会切换到HZ的TC集群了。



### 实现高可用
特别复杂，需要各种集群一致

1. 复制一份目录，修改配置文件的集群名称，启动加上参数-p 8092改端口
2. 将事务组和集群的映射关系放到nacos配置文件中，名称和分组根据上面配置文件填写
3. 新建配置文件，服务的事务组关系映射：

```java
# 事务组映射关系
service.vgroupMapping.seata-demo=SH

service.enableDegrade=false
service.disableGlobalTransaction=false
# 与TC服务的通信配置
transport.type=TCP
transport.server=NIO
transport.heartbeat=true
transport.enableClientBatchSendRequest=false
transport.threadFactory.bossThreadPrefix=NettyBoss
transport.threadFactory.workerThreadPrefix=NettyServerNIOWorker
transport.threadFactory.serverExecutorThreadPrefix=NettyServerBizHandler
transport.threadFactory.shareBossWorker=false
transport.threadFactory.clientSelectorThreadPrefix=NettyClientSelector
transport.threadFactory.clientSelectorThreadSize=1
transport.threadFactory.clientWorkerThreadPrefix=NettyClientWorkerThread
transport.threadFactory.bossThreadSize=1
transport.threadFactory.workerThreadSize=default
transport.shutdown.wait=3
# RM配置
client.rm.asyncCommitBufferLimit=10000
client.rm.lock.retryInterval=10
client.rm.lock.retryTimes=30
client.rm.lock.retryPolicyBranchRollbackOnConflict=true
client.rm.reportRetryCount=5
client.rm.tableMetaCheckEnable=false
client.rm.tableMetaCheckerInterval=60000
client.rm.sqlParserType=druid
client.rm.reportSuccessEnable=false
client.rm.sagaBranchRegisterEnable=false
# TM配置
client.tm.commitRetryCount=5
client.tm.rollbackRetryCount=5
client.tm.defaultGlobalTransactionTimeout=60000
client.tm.degradeCheck=false
client.tm.degradeCheckAllowTimes=10
client.tm.degradeCheckPeriod=2000

# undo日志配置
client.undo.dataValidation=true
client.undo.logSerialization=jackson
client.undo.onlyCareUpdateColumns=true
client.undo.logTable=undo_log
client.undo.compress.enable=true
client.undo.compress.type=zip
client.undo.compress.threshold=64k
client.log.exceptionRate=100
```

3. 修改微服务的配置：将上面配置文件配置进来

```java
seata:
  config:
    type: nacos
    nacos:
      server-addr: 127.0.0.1:8848
      username: nacos
      password: nacos
      group: SEATA_GROUP
      data-id: client.properties
```



# 分布式缓存
## Redis持久化
Redis有两种持久化方案：

+ RDB（Redis Database Backup file）
+ AOF（Append Only File）

RDB也叫数据快照备份，简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。

RDB的四种执行时机：

+ save命令，会导致主进程执行save命令，其他进程会造成阻塞，只会在数据迁移的时候用到。
+ bgsave命令，异步备份，开启独立的线程
+ 停机时候，会执行一次RDB操作
+ Redis配置的条件，比如：

```java
# 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save "" 则表示禁用RDB
save 900 1  
save 300 10  
save 60 10000 
```

其他配置：

```java
# 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱
rdbcompression yes

# RDB文件名称
dbfilename dump.rdb  

# 文件保存的路径目录
dir ./ 
```

**RDB原理：**

bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。

fork采用的是copy-on-write技术：

+ 当主进程执行读操作时，访问共享内存；
+ 当主进程执行写操作时，则会拷贝一份数据，执行写操作。

RDB的缺点？

+ RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险
+ fork子进程、压缩、写出RDB文件都比较耗时

**AOF原理：**

AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。

AOF默认是关闭的，需要在redis.conf中配置开启：

```java
# 是否开启AOF功能，默认是no
appendonly yes
# AOF文件的名称
appendfilename "appendonly.aof"
```

AOF记录命令的频率：

```java
# 表示每执行一次写命令，立即记录到AOF文件
appendfsync always 
# 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案
appendfsync everysec 
# 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
appendfsync no
```

AOF重写文件的阀值设置：

```java
# AOF文件比上次文件 增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写 
auto-aof-rewrite-min-size 64mb 
```



**RDB和AOF的对比：**

![1727148185126-b936c17c-0e8d-4e94-8bc9-e9be6e94973b.png](1727148185126-b936c17c-0e8d-4e94-8bc9-e9be6e94973b-798133.png)



## 搭建Redis主从集群
单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。

**搭建单个Redis：**

1. 安装redis所需要的依赖：yum install -y gcc tcl
2. 解压redis安装包
3. 编译：make && make install
4. 修改配置

```java
# 绑定地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问
bind 0.0.0.0
# 数据库数量，设置为1
databases 1
```

5. 启动命令：redis-server redis.conf
6. 关闭命令：redis-cli shutdown

**搭建主从模式：**

例如要搭建如下的Redis主从模式：

![1727160157760-b51da930-d293-4c90-b5c8-74a9d1ff7877.png](1727160157760-b51da930-d293-4c90-b5c8-74a9d1ff7877-245245.png)

1. 创建三个目录，自定义名称，这里定义7001、7002、7003
2. 将redis.conf的配置恢复成原始的RDB：

```java
# 开启RDB
# save ""
save 3600 1
save 300 100
save 60 10000

# 关闭AOF
appendonly no
```

3. 分别拷贝配置文件到三个目录的下面，使用cp命令
4. 修改每个配置文件里面的端口号和RDB存储目录（默认是dir ./）
5. 修改每个配置文件中的实例声明ip（ip定义为服务器的ip）：

```java
replica-announce-ip 192.168.150.101
```

6. 分别启动：redis-server 7001/redis.conf

现在三个实例还没有任何关系，要配置主从可以使用replicaof 或者slaveof（5.0以前）命令。

有临时和永久两种模式：

+ 永久：修改redis.conf文件，添加一行配置：slaveof \<masterip\> \<masterport\>
+ 临时：登入redis-cli，执行命令slaveof \<masterip\> \<masterport\>，5.0之后新增replicaof，效果一致
7. 配置完之后，登入7001查看集群：info replication

## 主从数据同步原理
主从节点第一次连接，会执行全量同步，将主节点的数据全部同步给子节点。如图：

![1727160733551-780ab392-888e-44be-afe3-7bbb6740010e.png](1727160733551-780ab392-888e-44be-afe3-7bbb6740010e-654984.png)

重要的标志：

+ replicationId：每个master有唯一的id，子节点继承父节点的，两者相一致代表是同一个数据集，两个不一致就代表是第一次请求，就执行全量同步
+ offset：偏移量，表示repl_baklog的位置，slaver的offset如果小于master的offset，那么需要更新，也就是增量同步
+ repl_baklog文件：固定大小的环形数组，记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset

全量同步：将master的全部数据拷贝给slave节点

增量同步：将master的更新数据拷贝给slave节点



可以从以下几个方面来优化Redis主从就集群：

+ 在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。
+ Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO
+ 适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步
+ 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力

## Redis哨兵
Redis提供Sentinel机制实现主从集群的自动故障与恢复。

哨兵的作用：

+ **监控**：Sentinel 会不断检查您的master和slave是否按预期工作
+ **自动故障恢复**：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主
+ **通知**：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端

结构图：

![1727337102304-2f328bb2-7f53-4199-b4e7-1a076c9ac1ac.png](1727337102304-2f328bb2-7f53-4199-b4e7-1a076c9ac1ac-241859.png)

监控原理： 

基于心跳检测机制，每隔一秒向集群的每个实例发送ping命令，

+ 如果一个Sentinel节点发现实例未在规定时间响应，则认为主观下线
+ 如果发现主观下线的Sentinel节点超过了指定数量（quorum），则认为客观下线，quorum最好设置为sentinel数量的一半

集群故障故障恢复原理：一旦发现master故障，sentinel需要在salve中选择一个作为新的master

+ 首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点
+ 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举
+ 如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高
+ 最后是判断slave节点的运行id大小，越小优先级越高。

选出master节点之后，需要发送命令指定：

+ sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master
+ sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。
+ 最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点

## 搭建Redis哨兵
准备搭建三个Sentinel监控Redis集群：

![1727337426737-430902d9-57ba-465c-84e7-64c1fe9d3c7f.png](1727337426737-430902d9-57ba-465c-84e7-64c1fe9d3c7f-948411.png)

1. /tmp创建三个目录s1、s2、s3
2. s1目录下新建sentinel.conf，输出内容：

```java
port 27001
sentinel announce-ip 192.168.150.101
sentinel monitor mymaster 192.168.150.101 7001 2
sentinel down-after-milliseconds mymaster 5000
sentinel failover-timeout mymaster 60000
dir "/tmp/s1"
```

3. 复制这个文件到s2、s3，修改文件中的端口和目录地址
4. 启动：redis-sentinel /tmp/s1/sentinel.conf
5. 测试断开master结点，看看会不会重新选择master

## Lettuce
在Sentinel集群监管下的Redis主从集群，其节点会因为自动故障转移而发生变化，Redis的客户端必须感知这种变化，及时更新连接信息。Spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换。

实现：

1. 导入依赖：

```java
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```

2. 配置哨兵集群

```java
spring:
  redis:
    sentinel:
      master: mymaster
      nodes:
        - 192.168.150.101:27001
        - 192.168.150.101:27002
        - 192.168.150.101:27003
```

3. 配置读写分离

```java
@Bean
public LettuceClientConfigurationBuilderCustomizer clientConfigurationBuilderCustomizer(){
    return clientConfigurationBuilder -> clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
}
```

读写策略有四种：

+ MASTER：从主节点读取
+ MASTER_PREFERRED：优先从master节点读取，master不可用才读取replica
+ REPLICA：从slave（replica）节点读取
+ REPLICA _PREFERRED：优先从slave（replica）节点读取，所有的slave都不可用才读取master

## 搭建Redis分片集群
主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：

+ 海量数据存储问题
+ 高并发写的问题

使用分片集群可以解决上述问题。

![1727403339096-7c2da03e-f4a7-4e10-9be6-b9add21c2983.png](1727403339096-7c2da03e-f4a7-4e10-9be6-b9add21c2983-291520.png)

分片集群特征：

+ 集群有多个master，每个master保存不同的数据
+ 每个master可以有多个slave节点
+ master之间通过ping监测彼此健康状态
+ 客户端可以请求访问集群的任意节点，最终都会被正确转发到正确节点

**搭建最小的一个分片集群：**

![1727403458243-bffe3d94-a795-4baa-8dc9-a8b53058fe6d.png](1727403458243-bffe3d94-a795-4baa-8dc9-a8b53058fe6d-447364.png)

1. 创建6个目录：7001、7002、7003、8001、8002、8003
2. 准备redis.conf文件，输出内容：

```java
port 6379
# 开启集群功能
cluster-enabled yes
# 集群的配置文件名称，不需要我们创建，由redis自己维护
cluster-config-file /tmp/6379/nodes.conf
# 节点心跳失败的超时时间
cluster-node-timeout 5000
# 持久化文件存放目录
dir /tmp/6379
# 绑定地址
bind 0.0.0.0
# 让redis后台运行
daemonize yes
# 注册的实例ip
replica-announce-ip 192.168.150.101
# 保护模式
protected-mode no
# 数据库数量
databases 1
# 日志
logfile /tmp/6379/run.log
```

3. 改文件拷贝到每个目录下面：

```java
echo 7001 7002 7003 8001 8002 8003 | xargs -t -n 1 cp redis.conf
```

4. 修改每个配置文件中的内容

```java
printf '%s\n' 7001 7002 7003 8001 8002 8003 | xargs -I{} -t sed -i 's/6379/{}/g' {}/redis.conf
```

5. 一键启动服务

```java
# 一键启动所有服务
printf '%s\n' 7001 7002 7003 8001 8002 8003 | xargs -I{} -t redis-server {}/redis.conf
```

6. 查看服务是否启动成功

```java
ps -ef | grep redis
//一次关闭所有服务
printf '%s\n' 7001 7002 7003 8001 8002 8003 | xargs -I{} -t redis-cli -p {} shutdown
```

7. redis5.0之前创建集群：通过redis安装包下的src/redis-trib.rb来实现

```java
//安装ruby环境
# 安装依赖
yum -y install zlib ruby rubygems
gem install redis
//命令
# 进入redis的src目录
cd /tmp/redis-6.2.4/src
# 创建集群
./redis-trib.rb create --replicas 1 192.168.150.101:7001 192.168.150.101:7002 192.168.150.101:7003 192.168.150.101:8001 192.168.150.101:8002 192.168.150.101:8003
```

8. redis5.0之后创建集群：通过redis-cli命令

```java
redis-cli --cluster create --cluster-replicas 1 192.168.150.101:7001 192.168.150.101:7002 192.168.150.101:7003 192.168.150.101:8001 192.168.150.101:8002 192.168.150.101:8003
- `redis-cli --cluster`或者`./redis-trib.rb`：代表集群操作命令
- `create`：代表是创建集群
- `--replicas 1`或者`--cluster-replicas 1` ：指定集群中每个master的副本个数为1，此时`节点总数 ÷ (replicas + 1)` 得到的就是master的数量。因此节点列表中的前n个就是master，其它节点都是slave节点，随机分配到不同master
```

9. 开启端口，不光服务端口，还有集群总线接口（服务端口+10000）
10. 查看集群状态：

```java
redis-cli -p 7001 cluster nodes
```

11. 集群操作要加上-c

```java
redis-cli -c -p 7001
```

## Redis分片集群原理
### 散列插槽
Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到：

redis会根据key的有效部分计算插槽值，分两种情况：

- key中包含"{}"，且“{}”中至少包含1个字符，“{}”中的部分是有效部分

- key中不包含“{}”，整个key都是有效部分

### 集群伸缩
redis-cli --cluster提供了很多操作集群的命令，可以通过下面方式查看：

+ 添加新节点到集群中：

```java
redis-cli --cluster add-node  139.9.45.47:7004 139.9.45.47:7001
139.9.45.47:7004要添加的节点
139.9.45.47:7001已经存在的主机：端口
```

+ 转移插槽

```java
redis-cli --cluster reshard 139.9.45.47:7001
```

一步一步的进行询问，过程填写节点的id。

+ 自动故障转移：节点宕机，自动选slaver为master
+ 手动故障转移：redis-cli连接服务端口，执行命令cluster failover

![1727404383912-40a57199-49b8-4d64-9a81-60227b9383f1.png](1727404383912-40a57199-49b8-4d64-9a81-60227b9383f1-383210.png)

这种failover命令可以指定三种模式：

+ 缺省：默认的流程，如图1~6歩
+ force：省略了对offset的一致性校验
+ takeover：直接执行第5歩，忽略数据一致性、忽略master状态和其它master的意见

### Lettuce访问分片集群
1）引入redis的starter依赖

2）配置分片集群地址

3）配置读写分离

与哨兵模式相比，其中只有分片集群的配置方式略有差异，如下：

```java
spring:
  redis:
    cluster:
      nodes:
        - 192.168.150.101:7001
        - 192.168.150.101:7002
        - 192.168.150.101:7003
        - 192.168.150.101:8001
        - 192.168.150.101:8002
        - 192.168.150.101:8003
```



# 多级缓存
目标：建立多级缓存来提升程序的效率。

## 什么是多级缓存？
一般请求处理的逻辑：先查询Redis缓存，Redis中没有就查询数据库。

这里存在的问题：

+ 只要Redis不存在就会对数据库访问，如果大量的key不存在，则会造成数据库的压力。
+ 请求都会经过Tomcat处理，Tomcat的性能成为了瓶颈

多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：

+ 浏览器访问静态资源时，优先读取浏览器本地缓存
+ 访问非静态资源（ajax查询数据）时，访问服务端
+ 请求到达Nginx后，优先读取Nginx本地缓存
+ 如果Nginx本地缓存未命中，则去直接查询Redis（不经过Tomcat）
+ 如果Redis查询未命中，则查询Tomcat
+ 请求进入Tomcat后，优先查询JVM进程缓存
+ 如果JVM进程缓存未命中，则查询数据库

![1728464668950-9409f22c-41f7-4c01-bffb-708b00d28ed8.png](1728464668950-9409f22c-41f7-4c01-bffb-708b00d28ed8-453320.png)

在多级缓存架构中，Nginx内部需要编写本地缓存查询、Redis查询、Tomcat查询的业务逻辑，因此这样的nginx服务不再是一个反向代理服务器，而是**一个编写业务的Web服务器**了。

多级缓存的关键：

1. Tomcat中实现JVM进程缓存
2. nginx中编写业务，实现Nginx本地缓存、Redis缓存，JVM进程缓存的查询

nginx编写业务需要使用到OpenResty框架结合Lua来实现。

## JVM进程缓存实现
根据上面的图来搭建整个多级缓存模型，启动项目后，配置nginx，nginx的配置文件nginx.conf内容如下：

```java

#user  nobody;
worker_processes  1;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;
    #tcp_nopush     on;
    keepalive_timeout  65;

    upstream nginx-cluster{
        server 139.9.45.47:8081;
    }
    server {
        listen       80;
        server_name  localhost;

	location /api {
            proxy_pass http://nginx-cluster;
        }

        location / {
            root   html;
            index  index.html index.htm;
        }

        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
```

### 使用Caffeine实现进程缓存
Caffeine是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：[https://github.com/ben-manes/caffeine](https://github.com/ben-manes/caffeine)

基本使用的API方法：

```java
@Test
void testBasicOps() {
    // 构建cache对象
    Cache<String, String> cache = Caffeine.newBuilder().build();

    // 存数据
    cache.put("gf", "迪丽热巴");

    // 取数据
    String gf = cache.getIfPresent("gf");
    System.out.println("gf = " + gf);

    // 取数据，包含两个参数：
    // 参数一：缓存的key
    // 参数二：Lambda表达式，表达式参数就是缓存的key，方法体是查询数据库的逻辑
    // 优先根据key查询JVM缓存，如果未命中，则执行参数二的Lambda表达式
    String defaultGF = cache.get("defaultGF", key -> {
        // 根据key去数据库查询数据
        return "柳岩";
    });
    System.out.println("defaultGF = " + defaultGF);
}
```



Caffeine提供的缓存清楚策略：

1. 基于容量：

```java
// 创建缓存对象
Cache<String, String> cache = Caffeine.newBuilder()
    .maximumSize(1) // 设置缓存大小上限为 1
    .build();
```

2. 基于时间

```java
// 创建缓存对象
Cache<String, String> cache = Caffeine.newBuilder()
    // 设置缓存有效期为 10 秒，从最后一次写入开始计时 
    .expireAfterWrite(Duration.ofSeconds(10)) 
    .build();

```

3. 基于引用：设置缓存为弱引用或者软引用，利用GC进行回收缓存数据，性能较差，不建议使用

## Lua语法
Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。官网：[https://www.lua.org/](https://www.lua.org/)

Lua经常嵌入到C语言开发的程序中，例如游戏开发、游戏插件等。

Nginx本身也是C语言开发，因此也允许基于Lua做拓展。

1. Lua支持的变量：

![1728465555374-c733e003-5af7-4820-a633-f8a1270161f4.png](1728465555374-c733e003-5af7-4820-a633-f8a1270161f4-622242.png)

Lua变量：

```java
-- 声明字符串，可以用单引号或双引号，
local str = 'hello'
-- 字符串拼接可以使用 ..
local str2 = 'hello' .. 'world'
-- 声明数字
local num = 21
-- 声明布尔类型
local flag = true
-- 声明数组 ，key为角标的 table
local arr = {'java', 'python', 'lua'}
-- 声明table，类似java的map
local map =  {name='Jack', age=21}
```

2. 条件控制：

```java
if(布尔表达式)
then
   --[ 布尔表达式为 true 时执行该语句块 --]
else
   --[ 布尔表达式为 false 时执行该语句块 --]
end

```

3. 逻辑操作符：and、or、not
4. 函数：

```java
function 函数名( argument1, argument2..., argumentn)
    -- 函数体
    return 返回值
end
```

## OpenResty
OpenResty® 是一个基于 Nginx的高性能 Web 平台，用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。具备下列特点：

+ 具备Nginx的完整功能
+ 基于Lua语言进行扩展，集成了大量精良的 Lua 库、第三方模块
+ 允许使用Lua**自定义业务逻辑**、**自定义库**

官方网站： [https://openresty.org/cn/](https://openresty.org/cn/)

### 安装OpenResty
服务器记得联网

1. 安装OpenResty依赖的开发库

```java
yum install -y pcre-devel openssl-devel gcc --skip-broken
```

2. 添加仓库：

```java
yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo
命令不存在先执行下面命令：
yum install -y yum-utils 
```

3. 安装OpenResty

```java
yum install -y openresty
```

4. 安装opm工具，opm是帮助我们安装一个第三方的lua模块：

```java
yum install -y openresty-opm
```

5. 默认安装路径：/usr/local/openresty
6. 配置nginx环境变量：

```java
vi /etc/profile

添加：
export NGINX_HOME=/usr/local/openresty/nginx
export PATH=${NGINX_HOME}/sbin:$PATH

使配置生效
source /etc/profile
```

7. 启动：

```java
# 启动nginx
nginx
# 重新加载配置
nginx -s reload
# 停止
nginx -s stop
```

### 入门
1. nginx编写业务逻辑需要使用lua库，需要在nginx配置文件中引入，写在http下面：

```java
#lua 模块
lua_package_path "/usr/local/openresty/lualib/?.lua;;";
#c模块     
lua_package_cpath "/usr/local/openresty/lualib/?.so;;";  
```

2. 对路径进行监听，监听的路径对应lua脚本的执行：

```java
location  /api/item {
    # 默认的响应类型
    default_type application/json;
    # 响应结果由lua/item.lua文件来决定
    content_by_lua_file lua/item.lua;
}
```

3. 创建lua/item.lua内容：输出模拟数据

```java
ngx.say('{"id":10001,"name":"SALSA AIR","title":"RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4","price":17900,"image":"https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp","category":"拉杆箱","brand":"RIMOWA","spec":"","status":1,"createTime":"2019-04-30T16:00:00.000+00:00","updateTime":"2019-04-30T16:00:00.000+00:00","stock":2999,"sold":31290}')
```

上面的是模拟数据，如果我要获取监听到的路径的参数：

![1728466678488-9ec74a15-1505-4b32-bbf7-12e4da3ecc34.png](1728466678488-9ec74a15-1505-4b32-bbf7-12e4da3ecc34-918901.png)

比如参数是/api/item/10010，上面配置修改：

```java
location ~ /api/item/(\d+) {
    # 默认的响应类型
    default_type application/json;
    # 响应结果由lua/item.lua文件来决定
    content_by_lua_file lua/item.lua;
}
```

lua文件修改：

```java
-- 获取商品id
local id = ngx.var[1]
-- 拼接并返回
ngx.say('{"id":' .. id .. ',"name":"SALSA AIR","title":"RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4","price":17900,"image":"https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp","category":"拉杆箱","brand":"RIMOWA","spec":"","status":1,"createTime":"2019-04-30T16:00:00.000+00:00","updateTime":"2019-04-30T16:00:00.000+00:00","stock":2999,"sold":31290}')
```

## OpenResty实现请求到Tomcat缓存
![1728467155991-019bf7ac-bd30-4b0d-a461-86e02ec9b1d5.png](1728467155991-019bf7ac-bd30-4b0d-a461-86e02ec9b1d5-634896.png)

### http工具
openresty提供了api发送http请求，例如：

```java
local resp = ngx.location.capture("/path",{
    method = ngx.HTTP_GET,   -- 请求方式
    args = {a=1,b=2},  -- get方式传参数
})

- resp.status：响应状态码
- resp.header：响应头，是一个table
- resp.body：响应体，就是响应数据
```

**注意：这里的path是路径，不包含ip和端口，会被nginx内部的server监听，所以server需要配置！！！**

![1728467774178-4e8eaa5d-4dfb-4bb9-9659-4795584146cd.png](1728467774178-4e8eaa5d-4dfb-4bb9-9659-4795584146cd-808395.png)

### 封装工具类
openresty启动会优先加载这两个模块，所以我们自定义得工具类也需要放到lualib目录下面

![1728468032613-db0c2ee5-8652-48d2-925b-c3e5a2f689b0.png](1728468032613-db0c2ee5-8652-48d2-925b-c3e5a2f689b0-237875.png)

封装的内容：

```java
-- 封装函数，发送http请求，并解析响应
local function read_http(path, params)
    local resp = ngx.location.capture(path,{
        method = ngx.HTTP_GET,
        args = params,
    })
    if not resp then
        -- 记录错误信息，返回404
        ngx.log(ngx.ERR, "http请求查询失败, path: ", path , ", args: ", args)
        ngx.exit(404)
    end
    return resp.body
end
-- 将方法导出
local _M = {  
    read_http = read_http
}  
return _M
```

使用：利用require("common")导入，common是这个自定义工具类的文件名

### CJSON组合数据
CJSON是用来序列化和反序列化JSON的。修改lua文件：

```java
-- 导入common函数库
local common = require('common')
local read_http = common.read_http
-- 导入cjson库
local cjson = require('cjson')

-- 获取路径参数
local id = ngx.var[1]
-- 根据id查询商品
local itemJSON = read_http("/item/".. id, nil)
-- 根据id查询商品库存
local itemStockJSON = read_http("/item/stock/".. id, nil)

-- JSON转化为lua的table
local item = cjson.decode(itemJSON)
local stock = cjson.decode(stockJSON)

-- 组合数据
item.stock = stock.stock
item.sold = stock.sold

-- 把item序列化为json 返回结果
ngx.say(cjson.encode(item))
```

### 基于ID的负载均衡
默认的负载均衡策略是轮询，如果一个请求到第一个Tomcat之后，第一个Tomcat是有缓存了，之后如果轮询的话，那又请求第二个Tomcat，又重新走一遍数据库，很影响。

解决方法：nginx根据请求路径做hash运算，把得到的数值对tomcat服务的数量取余，余数是几，就访问第几个服务，实现负载均衡。

```java
upstream tomcat-cluster {
    hash $request_uri;
    server 139.9.45.47:8081;
    server 139.9.45.47:8082;
}

...

location /item {
    proxy_pass http://tomcat-cluster;
}
```

## OpenResty实现请求到Redis
### 缓存预热
缓存预热：第一次启动时将缓存都存好，避免第一次都请求到数据库。

利用InitializingBean接口来实现，因为InitializingBean可以在对象被Spring创建并且成员变量全部注入后执行。

```java
@Component
public class RedisHandler implements InitializingBean {

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private IItemService itemService;
    @Autowired
    private IItemStockService stockService;

    private static final ObjectMapper MAPPER = new ObjectMapper();

    @Override
    public void afterPropertiesSet() throws Exception {
        // 初始化缓存
        // 1.查询商品信息
        List<Item> itemList = itemService.list();
        // 2.放入缓存
        for (Item item : itemList) {
            // 2.1.item序列化为JSON
            String json = MAPPER.writeValueAsString(item);
            // 2.2.存入redis
            redisTemplate.opsForValue().set("item:id:" + item.getId(), json);
        }

        // 3.查询商品库存信息
        List<ItemStock> stockList = stockService.list();
        // 4.放入缓存
        for (ItemStock stock : stockList) {
            // 2.1.item序列化为JSON
            String json = MAPPER.writeValueAsString(stock);
            // 2.2.存入redis
            redisTemplate.opsForValue().set("item:stock:id:" + stock.getId(), json);
        }
    }
}
```

### 封装http工具
openresty提供了操作redis的模块，可以在自定义中直接使用api操作：

```java
-- 导入redis
local redis = require('resty.redis')
-- 初始化redis
local red = redis:new()
red:set_timeouts(1000, 1000, 1000)

-- 关闭redis连接的工具方法，其实是放入连接池
local function close_redis(red)
    local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒
    local pool_size = 100 --连接池大小
    local ok, err = red:set_keepalive(pool_max_idle_time, pool_size)
    if not ok then
        ngx.log(ngx.ERR, "放入redis连接池失败: ", err)
    end
end

-- 查询redis的方法 ip和port是redis地址，key是查询的key
local function read_redis(ip, port, key)
    local ok, err = red:connect(ip, port)
    if not ok then
        ngx.log(ngx.ERR, "连接redis失败 : ", err)
        return nil
    end
    local resp, err = red:get(key)
    if not resp then
        ngx.log(ngx.ERR, "查询Redis失败: ", err, ", key = " , key)
    end
    if resp == ngx.null then
        resp = nil
        ngx.log(ngx.ERR, "查询Redis数据为空, key = ", key)
    end
    close_redis(red)
    return resp
end

-- 将方法导出
local _M = {  
    read_http = read_http,
    read_redis = read_redis
}  
return _M
```



### lua脚本修改
```java
-- 导入common函数库
local common = require('common')
local read_http = common.read_http
local read_redis = common.read_redis
-- 封装查询函数
function read_data(key, path, params)
    
    local val = read_redis("127.0.0.1", 6379, key)
    
    if not val then
        ngx.log(ngx.ERR, "redis查询失败，尝试查询http， key: ", key)
        
        val = read_http(path, params)
    end
   
    return val
end
```



## OpenResty实现请求到Nginx缓存
OpenResty为Nginx提供了shard dict的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。

1. 开启共享字典：

```java
 # 共享字典，也就是本地缓存，名称叫做：item_cache，大小150m
 lua_shared_dict item_cache 150m; 
```

2. 操作

```java
-- 获取本地缓存对象
local item_cache = ngx.shared.item_cache
-- 存储, 指定key、value、过期时间，单位s，默认为0代表永不过期
item_cache:set('key', 'value', 1000)
-- 读取
local val = item_cache:get('key')
```

lua脚本修改，集成了nginx本地缓存、redis缓存、Tomcat进程缓存：

```java
-- 导入common函数库
local common = require('common')
local read_http = common.read_http
local read_redis = common.read_redis
-- 导入cjson库
local cjson = require('cjson')
-- 导入共享词典，本地缓存
local item_cache = ngx.shared.item_cache

-- 封装查询函数
function read_data(key, expire, path, params)
    -- 查询本地缓存
    local val = item_cache:get(key)
    if not val then
        ngx.log(ngx.ERR, "本地缓存查询失败，尝试查询Redis， key: ", key)
        -- 查询redis
        val = read_redis("127.0.0.1", 6379, key)
        -- 判断查询结果
        if not val then
            ngx.log(ngx.ERR, "redis查询失败，尝试查询http， key: ", key)
            -- redis查询失败，去查询http
            val = read_http(path, params)
        end
    end
    -- 查询成功，把数据写入本地缓存
    item_cache:set(key, val, expire)
    -- 返回数据
    return val
end

-- 获取路径参数
local id = ngx.var[1]

-- 查询商品信息
local itemJSON = read_data("item:id:" .. id, 1800,  "/item/" .. id, nil)
-- 查询库存信息
local stockJSON = read_data("item:stock:id:" .. id, 60, "/item/stock/" .. id, nil)

-- JSON转化为lua的table
local item = cjson.decode(itemJSON)
local stock = cjson.decode(stockJSON)
-- 组合数据
item.stock = stock.stock
item.sold = stock.sold

-- 把item序列化为json 返回结果
ngx.say(cjson.encode(item))
```



## 缓存同步
目的实现缓存数据和数据库数据一致性。

三种方法：

**设置有效期**：给缓存设置有效期，到期后自动删除。再次查询时更新

+ 优势：简单、方便
+ 缺点：时效性差，缓存过期之前可能不一致
+ 场景：更新频率较低，时效性要求低的业务

**同步双写**：在修改数据库的同时，直接修改缓存

+ 优势：时效性强，缓存与数据库强一致
+ 缺点：有代码侵入，耦合度高；
+ 场景：对一致性、时效性要求较高的缓存数据

**异步通知：**修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据

+ 优势：低耦合，可以同时通知多个缓存服务
+ 缺点：时效性一般，可能存在中间不一致状态
+ 场景：时效性要求一般，有多个服务需要同步

### MQ异步通知实现缓存一致
![1728469397670-cdb94f30-978a-4f29-ba0b-9cd9b5d584c6.png](1728469397670-cdb94f30-978a-4f29-ba0b-9cd9b5d584c6-066167.png)

实体服务对数据进行修改之后需要发送一条消息给MQ，缓存服务监听MQ，去更新缓存。

需要代码植入。

### Canal异步通知缓存一致
![1728469530357-6f3cb3ad-5db0-4f01-9ebc-015e8dcb4725.png](1728469530357-6f3cb3ad-5db0-4f01-9ebc-015e8dcb4725-401469.png)

实体服务更新完数据库直接结束，然后Canal监听mysql，发生变化后通知缓存服务区更新缓存。

这里没有代码植入。

### 安装Canal
Canal [kə'næl]，译意为水道/管道/沟渠，canal是阿里巴巴旗下的一款开源项目，基于Java开发。基于数据库增量日志解析，提供增量数据订阅&消费。GitHub的地址：[https://github.com/alibaba/canal](https://github.com/alibaba/canal)

Canal是基于mysql的主从同步来实现的，MySQL主从同步的原理如下：

![1728469672643-79cad0f2-dc2f-4528-99c5-87faa4872252.png](1728469672643-79cad0f2-dc2f-4528-99c5-87faa4872252-982001.png)

而Canal就是把自己伪装成MySQL的一个slave节点，从而监听master的binary log变化。再把得到的变化信息通知给Canal的客户端，进而完成对其它数据库的同步。

1. 必须开启mysql的主从一致功能：配置文件添加内容

```java
log-bin=/var/lib/mysql/mysql-bin
binlog-do-db=heima

第一行是binlog的存放位置
第二行是binlog指定哪个数据库记录binlog
```

2. （可以忽略）这里为了安全，添加了一个仅用于数据同步的账户：

```java
create user canal@'%' IDENTIFIED by 'canal';
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT,SUPER ON *.* TO 'canal'@'%' identified by 'canal';
FLUSH PRIVILEGES;	
```

3. 查看是否成功：show master status;
4. 创建网络，将mq、mysql、canal都放到一个网络中：

```java
docker network create heima
docker network connect heima mysql  # mysql加入网络
```

5. 启动canal：

```java
docker run -p 11111:11111 --name canal \
-e canal.destinations=heima \
-e canal.instance.master.address=mysql:3306  \
-e canal.instance.dbUsername=canal  \
-e canal.instance.dbPassword=canal  \
-e canal.instance.connectionCharset=UTF-8 \
-e canal.instance.tsdb.enable=true \
-e canal.instance.gtidon=false  \
-e canal.instance.filter.regex=heima\\..* \
--network heima \
-d canal/canal-server:v1.1.5
```



### 监听Canal
我们可以利用Canal提供的Java客户端，监听Canal通知消息。当收到变化的消息时，完成对缓存的更新。

这里使用GitHub上的第三方开源的canal-starter客户端。地址：https://github.com/NormanGyllenhaal/canal-client

1. 引入依赖：

```java
<dependency>
    <groupId>top.javatool</groupId>
    <artifactId>canal-spring-boot-starter</artifactId>
    <version>1.2.1-RELEASE</version>
</dependency>
```

2. 配置：

```java
canal:
  destination: heima # canal的集群名字，要与安装canal时设置的名称一致
  server: 192.168.150.101:11111 # canal服务地址
```

3. 修改实体类：利用@ID、@Column、等注解完成Item与数据库表字段的映射：

```java
@Data
@TableName("tb_item")
public class Item {
    @TableId(type = IdType.AUTO)
    @Id
    private Long id;//商品id
    @Column(name = "name")
    private String name;//商品名称
    private String title;//商品标题
    private Long price;//价格（分）
    private String image;//商品图片
    private String category;//分类名称
    private String brand;//品牌名称
    private String spec;//规格
    private Integer status;//商品状态 1-正常，2-下架
    private Date createTime;//创建时间
    private Date updateTime;//更新时间
    @TableField(exist = false)
    @Transient
    private Integer stock;
    @TableField(exist = false)
    @Transient
    private Integer sold;
}
```

4. 编写监听器，通过实现EntryHandler\<T\>接口编写监听器，监听Canal消息：

注意两点：使用@CanalTable("表名")指定监听表的信息；EntryHandler的泛型是与表对应的实体类

```java
@CanalTable("tb_item")
@Component
public class ItemHandler implements EntryHandler<Item> {

    @Autowired
    private RedisHandler redisHandler;
    @Autowired
    private Cache<Long, Item> itemCache;

    @Override
    public void insert(Item item) {
        // 写数据到JVM进程缓存
        itemCache.put(item.getId(), item);
        // 写数据到redis
        redisHandler.saveItem(item);
    }

    @Override
    public void update(Item before, Item after) {
        // 写数据到JVM进程缓存
        itemCache.put(after.getId(), after);
        // 写数据到redis
        redisHandler.saveItem(after);
    }

    @Override
    public void delete(Item item) {
        // 删除数据到JVM进程缓存
        itemCache.invalidate(item.getId());
        // 删除数据到redis
        redisHandler.deleteItemById(item.getId());
    }
}
```

对Redis操作的类RedisHandler封装：

```java
@Component
public class RedisHandler implements InitializingBean {

    @Autowired
    private StringRedisTemplate redisTemplate;

    @Autowired
    private IItemService itemService;
    @Autowired
    private IItemStockService stockService;

    private static final ObjectMapper MAPPER = new ObjectMapper();

    @Override
    public void afterPropertiesSet() throws Exception {
        // 初始化缓存
        // 1.查询商品信息
        List<Item> itemList = itemService.list();
        // 2.放入缓存
        for (Item item : itemList) {
            // 2.1.item序列化为JSON
            String json = MAPPER.writeValueAsString(item);
            // 2.2.存入redis
            redisTemplate.opsForValue().set("item:id:" + item.getId(), json);
        }

        // 3.查询商品库存信息
        List<ItemStock> stockList = stockService.list();
        // 4.放入缓存
        for (ItemStock stock : stockList) {
            // 2.1.item序列化为JSON
            String json = MAPPER.writeValueAsString(stock);
            // 2.2.存入redis
            redisTemplate.opsForValue().set("item:stock:id:" + stock.getId(), json);
        }
    }

    public void saveItem(Item item) {
        try {
            String json = MAPPER.writeValueAsString(item);
            redisTemplate.opsForValue().set("item:id:" + item.getId(), json);
        } catch (JsonProcessingException e) {
            throw new RuntimeException(e);
        }
    }

    public void deleteItemById(Long id) {
        redisTemplate.delete("item:id:" + id);
    }
}
```

# 深入MQ-Rabbitmq
MQ中消息在发送的过程中会发生很多的问题：

![1728632680632-5c9daf04-d559-4ea0-aa52-1588394cdd9c.png](1728632680632-5c9daf04-d559-4ea0-aa52-1588394cdd9c-151413.png)

可以使用下面的方法来保证消息的发送

## 保证消息的可靠性
### 生产者消息确认机制
RabbitMQ提供了publisher confirm机制来避免消息发送到MQ过程中丢失。这种机制必须给每个消息**指定一个唯一ID**。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否处理成功。

返回结果有两种方式：

+ publisher-confirm，发送者确认
    - 消息成功投递到交换机，返回ack
    - 消息未投递到交换机，返回nack
+ publisher-return，发送者回执
    - 消息投递到交换机了，但是没有路由到队列。返回ACK，及路由失败原因。

实现：

1. publish开启confirm机制：

```yaml
spring:
  rabbitmq:
        publisher-confirm-type: correlated
        publisher-returns: true
        template:
          mandatory: true

- `publish-confirm-type`：开启publisher-confirm，这里支持两种类型：
  - `simple`：同步等待confirm结果，直到超时
  - `correlated`：异步回调，定义ConfirmCallback，MQ返回结果时会回调这个ConfirmCallback
- `publish-returns`：开启publish-return功能，同样是基于callback机制，不过是定义ReturnCallback
- `template.mandatory`：定义消息路由失败时的策略。true，则调用ReturnCallback；false：则直接丢弃消息
```

2. 配置ReturnCallback回调，这个回调会在消息到了交换机，但是没有到路由时候失败的回调，只有一个，项目加载时配置

```java
@Slf4j
@Configuration
public class CommonConfig implements ApplicationContextAware {
    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
        // 获取RabbitTemplate
        RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class);
        // 设置ReturnCallback
        rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -> {
            // 投递失败，记录日志
            log.info("消息发送失败，应答码{}，原因{}，交换机{}，路由键{},消息{}",
                     replyCode, replyText, exchange, routingKey, message.toString());
            // 如果有业务需要，可以重发消息
        });
    }
}
```

3. 配置confirm回调，判断消息是否到交换机？：

```java
@Test
public void testSendMessage3SimpleQueue() throws InterruptedException {
// 1.消息体
//        String message = "hello, spring amqp!";
Message message = MessageBuilder
.withBody("hello, spring mq!".getBytes(StandardCharsets.UTF_8))
.setDeliveryMode(MessageDeliveryMode.PERSISTENT)
.build();
// 2.全局唯一的消息ID，需要封装到CorrelationData中
CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());
// 3.添加callback
correlationData.getFuture().addCallback(
    result -> {
        if(result.isAck()){
            // 3.1.ack，消息成功
            log.debug("消息发送成功, ID:{}", correlationData.getId());
        }else{
            // 3.2.nack，消息失败
            log.error("消息发送失败, ID:{}, 原因{}",correlationData.getId(), result.getReason());
        }
    },
    ex -> log.error("消息发送异常, ID:{}, 原因{}",correlationData.getId(),ex.getMessage())
);
// 4.发送消息，在此之前，创建队列和交换机，绑定之间的关系
DirectExchange directExchange = new DirectExchange("task.direct");
Queue queue1 = new Queue("task.queue1");
Queue queue2 = new Queue("task.queue2");
RabbitAdmin rabbitAdmin = new RabbitAdmin(rabbitTemplate.getConnectionFactory());
rabbitAdmin.declareExchange(directExchange);
rabbitAdmin.declareQueue(queue1);
rabbitAdmin.declareQueue(queue2);
rabbitAdmin.declareBinding(BindingBuilder.bind(queue1).to(directExchange).with("task"));
rabbitAdmin.declareBinding(BindingBuilder.bind(queue2).to(directExchange).with("task2"));
//        rabbitTemplate.convertAndSend("task.direct3", "task3", message, correlationData);
rabbitTemplate.convertAndSend("task.direct", "task", message, correlationData);

// 休眠一会儿，等待ack回执
Thread.sleep(2000);
}
```

4. 消费者监听：

```java
@Component
public class SpringRabbitListener {

    @RabbitListener(bindings = @QueueBinding(
        value = @Queue(name = "task.queue1"),
        exchange = @Exchange(name = "task.direct", type = ExchangeTypes.DIRECT),
        key = {"task"}
    ))
    public void listenSimpleQueue(String msg) {
        System.out.println("消费者接收到task.direct的消息：【" + msg + "】");
        //模拟异常
        System.out.println(1 / 0);
        log.debug("消息处理完成");
    }

    @RabbitListener(bindings = @QueueBinding(
        value = @Queue(name = "task.queue2"),
        exchange = @Exchange(name = "task.direct", type = ExchangeTypes.DIRECT),
        key = {"task2"}
    ))
    public void listenSimpleQueue2(String msg) {
        System.out.println("消费者接收到task.direct的消息：【" + msg + "】");
    }
}

```

### 消息持久化
生产者确认可以确保消息投递到RabbitMQ的队列中，但是消息发送到RabbitMQ以后，如果突然宕机，也可能导致消息丢失。

要想确保消息在RabbitMQ中安全保存，必须开启消息持久化机制。

+ 交换机持久化
+ 队列持久化
+ 消息持久化
1. RabbitMQ默认交换机不是持久化的，mq重启后丢失，事实上，默认SpringAMQP声明的交换机是持久化的，也可以通过代码持久化：

```java
@Bean
public DirectExchange simpleExchange(){
    // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除
    return new DirectExchange("simple.direct", true, false);
}
```

2. 队列和交换机一样，可以通过代码持久化：

```java
@Bean
public Queue simpleQueue(){
    // 使用QueueBuilder构建队列，durable就是持久化的
    return QueueBuilder.durable("simple.queue").build();
}
```

3. 消息也是一样，可以通过代码指定是否需要持久化：

```java
Message message = MessageBuilder
                .withBody("hello, spring mq!".getBytes(StandardCharsets.UTF_8))
                .setDeliveryMode(MessageDeliveryMode.PERSISTENT)
                .build();
```

### 消费者消息确认
RabbitMQ是阅后即焚机制，RabbitMQ确认消息被消费者消费后会立刻删除。

而RabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。

消息消费之后返回ack的时机很重要，有三种：

+ manual：手动ack，需要在业务代码结束后，调用api发送ack。
+ auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack
+ none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除

一般情况下使用auto。实现auto：

1. 开启auto

```java
spring:
  rabbitmq:
    listener:
      simple:
        acknowledge-mode: auto 
```

2. 模拟异常

```java
@RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "task.queue1"),
            exchange = @Exchange(name = "task.direct", type = ExchangeTypes.DIRECT),
            key = {"task"}
    ))
    public void listenSimpleQueue(String msg) {
        System.out.println("消费者接收到task.direct的消息：【" + msg + "】");
        //模拟异常
        System.out.println(1 / 0);
        log.debug("消息处理完成");
    }
```

在这里可以发现，队列消费消息失败之后，会重新将消息入队，重新消费，然后还是进入这个监听方法，一直失败，一直循环。

解决方法下面。

### 消费失败重试机制
针对上面的问题，这里使用本地重试进行解决：

1. 开启消费者失败重试机制，配置重试的最大次数和相关配置

```java
spring:
  rabbitmq:
    listener:
      simple:
        retry:
          enabled: true # 开启消费者失败重试
          initial-interval: 1000 # 初识的失败等待时长为1秒
          multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval
          max-attempts: 3 # 最大重试次数
          stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false
```

达到最大的次数过后，默认是将消息丢弃，返回ack

2. 重试失败过后的策略有三种：
+ RejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式
+ ImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队
+ RepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机，交由人工处理

优雅实现RepublishMessageRecoverer：创建交换机和队列，绑定它们的关系，通过RepublishMessageRecoverer声明其为存放失败消息的交换机。

这里只要利用RepublishMessageRecoverer()绑定了存放失败消息的队列，就会将失败的消息存放到该交换机中。

```java
@Bean
public DirectExchange errorMessageExchange(){
    return new DirectExchange("error.direct");
}
@Bean
public Queue errorQueue(){
    return new Queue("error.queue", true);
}
@Bean
public Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange){
    return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with("error");
}

@Bean
public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){
    return new RepublishMessageRecoverer(rabbitTemplate, "error.direct", "error");
}
```



## 死信交换机
### 死信交换机是什么？
什么是死信？

当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）：

+ 消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false
+ 消息是一个过期消息，超时无人消费
+ 要投递的队列消息满了，无法投递

如果这个包含死信的队列配置了`dead-letter-exchange`属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机（Dead Letter Exchange，检查DLX）。

另外，队列将死信投递给死信交换机时，必须知道两个信息：

+ 死信交换机名称
+ 死信交换机与死信队列绑定的RoutingKey

这样才能确保投递的消息能到达死信交换机，并且正确的路由到死信队列。

![1728641656759-1a9d4d5c-c517-4d93-af60-fc539c1232eb.png](1728641656759-1a9d4d5c-c517-4d93-af60-fc539c1232eb-672840.png)

实现：

1. 在失败重试策略中，默认的RejectAndDontRequeueRecoverer会在本地重试次数耗尽后，发送reject给RabbitMQ，消息变成死信，被丢弃。我们可以定义死信交换机关联该队列，获取死信信息。（正常监听队列的代码逻辑需要更改，在发生异常的时候，应该拒绝消息）
2. 代码实现：正常队列和死信交换机的绑定、死信交换机和死信队列的绑定

```java
@Bean
public Queue taskQueue1(){
    return QueueBuilder.durable("task.queue1") // 指定队列名称，并持久化
    .deadLetterExchange("dl.direct") // 指定死信交换机
    .deadLetterRoutingKey("simple")
    .build();
}
@Bean
public DirectExchange taskDirect(){
    return new DirectExchange("task.direct");
}
@Bean
public Binding ttlBinding(){
    return BindingBuilder.bind(taskQueue1()).to(taskDirect()).with("task");
}

// 声明死信交换机 dl.direct
@Bean
public DirectExchange dlExchange(){
    return new DirectExchange("dl.direct", true, false);
}
// 声明存储死信的队列 dl.queue
@Bean
public Queue dlQueue(){
    return new Queue("dl.queue", true);
}
// 将死信队列 与 死信交换机绑定
@Bean
public Binding dlBinding(){
    return BindingBuilder.bind(dlQueue()).to(dlExchange()).with("simple");
}
```

3. 监听：死信队列的监听

```java
@RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "dl.queue", durable = "true"),
            exchange = @Exchange(name = "dl.direct"),
            key = "simple"
    ))
    public void listenDlQueue(String msg){
        log.info("接收到 dl.ttl.queue的延迟消息：{}", msg);
    }
```

4. 发送者：正常发送消息

```java
// 4.发送消息，在此之前，创建队列和交换机，绑定之间的关系
        DirectExchange directExchange = new DirectExchange("task.direct");
//        Queue queue1 = new Queue("task.queue1");
        Queue queue1 = QueueBuilder.durable("task.queue1") // 指定队列名称，并持久化
                .deadLetterExchange("dl.direct") // 指定死信交换机
                .deadLetterRoutingKey("simple")
                .build();
        Queue queue2 = new Queue("task.queue2");
        DirectExchange directExchange1 = new DirectExchange("dl.direct");
        Queue queue = new Queue("dl.queue");


        RabbitAdmin rabbitAdmin = new RabbitAdmin(rabbitTemplate.getConnectionFactory());
        rabbitAdmin.declareExchange(directExchange);
        rabbitAdmin.declareQueue(queue1);
        rabbitAdmin.declareQueue(queue2);
        rabbitAdmin.declareBinding(BindingBuilder.bind(queue1).to(directExchange).with("task"));
        rabbitAdmin.declareBinding(BindingBuilder.bind(queue2).to(directExchange).with("task2"));
        rabbitAdmin.declareExchange(directExchange1);
        rabbitAdmin.declareQueue(queue);
        rabbitAdmin.declareBinding(BindingBuilder.bind(queue).to(directExchange1).with("simple"));
        //        rabbitTemplate.convertAndSend("task.direct3", "task3", message, correlationData);
        rabbitTemplate.convertAndSend("task.direct", "task", message, correlationData);


        // 休眠一会儿，等待ack回执
        Thread.sleep(2000);
```

5. 队列的监听：模拟异常，拒绝消息成为死信

```java
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = "task.queue1"),
    exchange = @Exchange(name = "task.direct", type = ExchangeTypes.DIRECT),
    key = {"task"}
))
public void listenSimpleQueue(String msg, Channel channel, Message amqpMessage) throws Exception {
    try {
        System.out.println("消费者接收到task.direct的消息：【" + msg + "】");
        // 模拟异常
        System.out.println(1 / 0);
        log.debug("消息处理完成");

        // 如果成功处理消息，手动确认消息
        channel.basicAck(amqpMessage.getMessageProperties().getDeliveryTag(), false);
    } catch (Exception e) {
        log.error("处理消息时发生异常", e);

        // 消息处理失败，拒绝消息，且不重新入队
        channel.basicReject(amqpMessage.getMessageProperties().getDeliveryTag(), false);
    }
}
```

死信交换机的使用场景是什么？

+ 如果队列绑定了死信交换机，死信会投递到死信交换机；
+ 可以利用死信交换机收集所有消费者处理失败的消息（死信），交由人工处理，进一步提高消息队列的可靠性。

### TTL
一个队列中的消息如果超时未消费，则会变为死信，超时分为两种情况：

+ 消息所在的队列设置了超时时间
+ 消息本身设置了超时时间

**创建设置了超时时间的消息队列：**

```java
Queue queue1 = QueueBuilder.durable("task.queue1") // 指定队列名称，并持久化
.deadLetterExchange("dl.direct") // 指定死信交换机
.deadLetterRoutingKey("simple")
.ttl(10000)
.build();
//注意在消费者和发送者都要这样创建
//测试模拟发送消息，等待11秒过期
```

**创建带有超时时间的消息：**

```java
Message message = MessageBuilder
.withBody("hello, ttl message".getBytes(StandardCharsets.UTF_8))
.setExpiration("5000")
.build();
```

消息超时的两种方式是？

+ 给队列设置ttl属性，进入队列后超过ttl时间的消息变为死信
+ 给消息设置ttl属性，队列接收到消息超过ttl时间后变为死信

如何实现发送一个消息20秒后消费者才收到消息？

+ 给消息的目标队列指定死信交换机
+ 将消费者监听的队列绑定到死信交换机
+ 发送消息时给消息设置超时时间为20秒

利用这两种方式都可以实现延迟发送消息。



### 延迟队列
因为延迟队列的需求非常多，所以RabbitMQ的官方也推出了一个插件，原生支持延迟队列效果。

这个插件就是DelayExchange插件。参考RabbitMQ的插件列表页面：[https://www.rabbitmq.com/community-plugins.html](https://www.rabbitmq.com/community-plugins.html)

使用方式可以参考官网地址：[https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq](https://blog.rabbitmq.com/posts/2015/04/scheduling-messages-with-rabbitmq)

安装插件：

1. 下载好的插件挂载到rabbitmq的plugins目录下面
2. 进入容器内部执行命令开启插件

```java
rabbitmq-plugins enable rabbitmq_delayed_message_exchange
```

3. 出现下面结果表示成功

![1728700305161-050b1808-802d-4606-9f43-d6a9c587c42a.png](1728700305161-050b1808-802d-4606-9f43-d6a9c587c42a-212328.png)

**DelayExchange原理：**

DelayExchange需要将一个交换机声明为delayed类型。当我们发送消息到delayExchange时，流程如下：

+ **接收消息**
+ **判断消息是否具备x-delay属性**
+ **如果有x-delay属性，说明是延迟消息，持久化到硬盘，读取x-delay值，作为延迟时间**
+ **返回routing not found结果给消息发送者**
+ **x-delay时间到期后，重新投递消息到指定队列**

**实现：**

1. 给交换机加上delayed属性，有监听器注解方式和@Bean的方式

![1728700465732-7b2e4711-daf0-415e-b9fd-8ff701bc6ba2.png](1728700465732-7b2e4711-daf0-415e-b9fd-8ff701bc6ba2-438577.png)

![1728700473552-509f3a54-6d03-49be-861a-faf59e9345dd.png](1728700473552-509f3a54-6d03-49be-861a-faf59e9345dd-332358.png)

2. 发送消息携带x-delay

![1728700568764-fe0e88c1-3347-4102-b0fc-b011999bb800.png](1728700568764-fe0e88c1-3347-4102-b0fc-b011999bb800-784943.png)

## 惰性队列
### 消息堆积问题
当生产者发送消息的速度超过了消费者处理消息的速度，就会导致队列中的消息堆积，直到队列存储消息达到上限。之后发送的消息就会成为死信，可能会被丢弃，这就是消息堆积问题。

![1728723227823-a1c2e5cf-9830-41ce-9371-268ff0fbf261.png](1728723227823-a1c2e5cf-9830-41ce-9371-268ff0fbf261-947599.png)

解决消息堆积有两种思路：

+ 增加更多消费者，提高消费速度。也就是我们之前说的work queue模式
+ 扩大队列容积，提高堆积上限

### 惰性队列的实现
从RabbitMQ的3.6.0版本开始，就增加了Lazy Queues的概念，也就是惰性队列。惰性队列的特征如下：

+ 接收到消息后直接存入磁盘而非内存
+ 消费者要消费消息时才会从磁盘中读取并加载到内存
+ 支持数百万条的消息存储

三种方式实现：

1. 使用命令行的方式：

```yaml
rabbitmqctl set_policy Lazy "^lazy-queue$" '{"queue-mode":"lazy"}' --apply-to queues  
- `rabbitmqctl` ：RabbitMQ的命令行工具
- `set_policy` ：添加一个策略
- `Lazy` ：策略名称，可以自定义
- `"^lazy-queue$"` ：用正则表达式匹配队列的名字
- `'{"queue-mode":"lazy"}'` ：设置队列模式为lazy模式
- `--apply-to queues  `：策略的作用对象，是所有的队列
```

2. 基于@Bean声明的方式

```java
@Bean
public Queue taskQueue1(){
    return QueueBuilder.durable("task.queue1") // 指定队列名称，并持久化
    .deadLetterExchange("dl.direct") // 指定死信交换机
    .deadLetterRoutingKey("simple")
    .lazy()
    .build();
}
```

3. 基于@RabbitListener声明LazyQueue

```java
@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = "task.queue1"),
    exchange = @Exchange(name = "task.direct", type = ExchangeTypes.DIRECT),
    key = {"task"},
    arguments = @Argument(name = "x-queue-mode", value = "lazy")
))
```

惰性队列的优点有哪些？

+ 基于磁盘存储，消息上限高
+ 没有间歇性的page-out，性能比较稳定

惰性队列的缺点有哪些？

+ 基于磁盘存储，消息时效性会降低
+ 性能受限于磁盘的IO

## MQ集群
RabbitMQ的是基于Erlang语言编写，而Erlang又是一个面向并发的语言，天然支持集群模式。RabbitMQ的集群有两种模式：

•普通集群：是一种分布式集群，将队列分散到集群的各个节点，从而提高整个集群的并发能力。

•镜像集群：是一种主从集群，普通集群的基础上，添加了主从备份功能，提高集群的数据可用性。

镜像集群虽然支持主从，但主从同步并不是强一致的，某些情况下可能有数据丢失的风险。因此在RabbitMQ的3.8版本以后，推出了新的功能：仲裁队列来代替镜像集群，底层采用Raft协议确保主从的数据一致性。

### 普通集群
普通集群，或者叫标准集群（classic cluster），具备下列特征：

+ 会在集群的各个节点间共享部分数据，包括：交换机、队列元信息。不包含队列中的消息。
+ 当访问集群某节点时，如果队列不在该节点，会从数据所在节点传递到当前节点并返回
+ 队列所在节点宕机，队列中的消息就会丢失

实现：

1. 获取Cookie。要使两个节点能够通信，它们必须具有相同的共享秘密，称为**Erlang cookie**。cookie 只是一串最多 255 个字符的字母数字字符。

```java
docker exec -it mq cat /var/lib/rabbitmq/.erlang.cookie
记录这个值，这里以FXZMCVGLBIXZCDEMMVZQ为例
```

2. 在/tmp目录新建一个配置文件 rabbitmq.conf：

```java
loopback_users.guest = false
listeners.tcp.default = 5672
cluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_config
cluster_formation.classic_config.nodes.1 = rabbit@mq1
cluster_formation.classic_config.nodes.2 = rabbit@mq2
cluster_formation.classic_config.nodes.3 = rabbit@mq3
```

3. 创建.erlang.cookie，写入内容

```java
FXZMCVGLBIXZCDEMMVZQ
```

4. 赋予权限：

```java
chmod 600 .erlang.cookie	
```

5. 创建目录并拷贝

```java
# 创建目录
mkdir mq1 mq2 mq3
# 拷贝
cp rabbitmq.conf mq1
cp rabbitmq.conf mq2
cp rabbitmq.conf mq3
cp .erlang.cookie mq1
cp .erlang.cookie mq2
cp .erlang.cookie mq3
```

6. 创建一个网络

```java
docker network create mq-net
```

7. 启动集群

```java
docker run -d --net mq-net \
-v ${PWD}/mq1/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \
-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \
-e RABBITMQ_DEFAULT_USER=itcast \
-e RABBITMQ_DEFAULT_PASS=123321 \
--name mq1 \
--hostname mq1 \
-p 8071:5672 \
-p 8081:15672 \
rabbitmq:3-management

docker run -d --net mq-net \
-v ${PWD}/mq2/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \
-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \
-e RABBITMQ_DEFAULT_USER=itcast \
-e RABBITMQ_DEFAULT_PASS=123321 \
--name mq2 \
--hostname mq2 \
-p 8072:5672 \
-p 8082:15672 \
rabbitmq:3-management

docker run -d --net mq-net \
-v ${PWD}/mq3/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf \
-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \
-e RABBITMQ_DEFAULT_USER=itcast \
-e RABBITMQ_DEFAULT_PASS=123321 \
--name mq3 \
--hostname mq3 \
-p 8073:5672 \
-p 8083:15672 \
rabbitmq:3-management
```

8. 测试创建队列，其他结点能否看到队列
9. 测试队列发送消息，其他结点能否接收消息
10. 测试队列所在结点宕机，其他结点还能看到队列吗



### 镜像集群
镜像集群：本质是主从模式，具备下面的特征：

+ 交换机、队列、队列中的消息会在各个mq的镜像节点之间同步备份。
+ 创建队列的节点被称为该队列的**主节点，****备份到的其它节点叫做该队列的****镜像**节点。
+ 一个队列的主节点可能是另一个队列的镜像节点
+ 所有操作都是主节点完成，然后同步给镜像节点
+ 主宕机后，镜像节点会替代成新的主

镜像模式的配置有3种模式：

| ha-mode | ha-params | 效果 |
| :--- | :--- | :--- |
| 准确模式exactly | 队列的副本量count | 集群中队列副本（主服务器和镜像服务器之和）的数量。count如果为1意味着单个副本：即队列主节点。count值为2表示2个副本：1个队列主和1个队列镜像。换句话说：count = 镜像数量 + 1。如果群集中的节点数少于count，则该队列将镜像到所有节点。如果有集群总数大于count+1，并且包含镜像的节点出现故障，则将在另一个节点上创建一个新的镜像。 |
| all | (none) | 队列在群集中的所有节点之间进行镜像。队列将镜像到任何新加入的节点。镜像到所有节点将对所有群集节点施加额外的压力，包括网络I / O，磁盘I / O和磁盘空间使用情况。推荐使用exactly，设置副本数为（N / 2 +1）。 |
| nodes | _node names_ | 指定队列创建到哪些节点，如果指定的节点全部不存在，则会出现异常。如果指定的节点在集群中存在，但是暂时不可用，会创建节点到当前客户端连接到的节点。 |


1. exactly模式

```java
rabbitmqctl set_policy ha-two "^two\." '{"ha-mode":"exactly","ha-params":2,"ha-sync-mode":"automatic"}'

- `rabbitmqctl set_policy`：固定写法
- `ha-two`：策略名称，自定义
- `"^two\."`：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以`two.`开头的队列名称
- `'{"ha-mode":"exactly","ha-params":2,"ha-sync-mode":"automatic"}'`: 策略内容
  - `"ha-mode":"exactly"`：策略模式，此处是exactly模式，指定副本数量
  - `"ha-params":2`：策略参数，这里是2，就是副本数量为2，1主1镜像
  - `"ha-sync-mode":"automatic"`：同步策略，默认是manual，即新加入的镜像节点不会同步旧的消息。如果设置为automatic，则新加入的镜像节点会把主节点中所有消息都同步，会带来额外的网络开销
```

2. all模式

```java
rabbitmqctl set_policy ha-all "^all\." '{"ha-mode":"all"}'

- `ha-all`：策略名称，自定义
- `"^all\."`：匹配所有以`all.`开头的队列名
- `'{"ha-mode":"all"}'`：策略内容
  - `"ha-mode":"all"`：策略模式，此处是all模式，即所有节点都会称为镜像节点
```

3. nodes模式

```java
rabbitmqctl set_policy ha-nodes "^nodes\." '{"ha-mode":"nodes","ha-params":["rabbit@nodeA", "rabbit@nodeB"]}'

- `rabbitmqctl set_policy`：固定写法
- `ha-nodes`：策略名称，自定义
- `"^nodes\."`：匹配队列的正则表达式，符合命名规则的队列才生效，这里是任何以`nodes.`开头的队列名称
- `'{"ha-mode":"nodes","ha-params":["rabbit@nodeA", "rabbit@nodeB"]}'`: 策略内容
  - `"ha-mode":"nodes"`：策略模式，此处是nodes模式
  - `"ha-params":["rabbit@mq1", "rabbit@mq2"]`：策略参数，这里指定副本所在节点名称
```

**注意：这些命令要进入容器内部执行。**

****

### 仲裁队列
仲裁队列：仲裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征：

+ 与镜像队列一样，都是主从模式，支持主从数据同步
+ 使用非常简单，没有复杂的配置
+ 主从同步基于Raft协议，强一致

实现：

1. 添加仲裁队列，可以通过控制台的创建队列，指定类型quorum就行了
2. Java代码创建仲裁队列：

```java
@Bean
public Queue quorumQueue() {
    return QueueBuilder
        .durable("quorum.queue") // 持久化
        .quorum() // 仲裁队列
        .build();
}
```

如果需要加入结点到集群中：

1. 创建新容器：

```java
docker run -d --net mq-net \
-v ${PWD}/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie \
-e RABBITMQ_DEFAULT_USER=itcast \
-e RABBITMQ_DEFAULT_PASS=123321 \
--name mq4 \
--hostname mq5 \
-p 8074:5672 \
-p 8084:15672 \
rabbitmq:3-management
```

2. 执行命令：

```java
//进入控制台
docker exec -it mq4 bash
//停止mq进程
rabbitmqctl stop_app
//重置MQ中的数据
rabbitmqctl reset
//加入到mq1中
rabbitmqctl join_cluster rabbit@mq1
//再次启动
rabbitmqctl start_app
```

3. 可以看到mq4加入到了集群中

如果需要增加仲裁副本：

1. 进入容器内部，查看当前副本

```java
docker exec -it mq1 bash
rabbitmq-queues quorum_status "quorum.queue"
```

2. 让mq4也加入进来

```java
rabbitmq-queues add_member "quorum.queue" "rabbit@mq4"
```

### Java代码连接MQ集群
```java
注意，这里用address来代替host、port方式
spring:
  rabbitmq:
    addresses: 192.168.150.105:8071, 192.168.150.105:8072, 192.168.150.105:8073
    username: itcast
    password: 123321
    virtual-host: /
```




# 八股文
八股文整合黑马、B站等

## 微服务？分布式？

微服务是一种架构风格，将应用程序按照业务拆分一组独立的服务，服务可以独立开发测试、部署、运维。不同的微服务还可以使用不同的技术栈。服务之间通过规定的接口进行通信。
微服务的出现是为了解决传统单体项目的局限性，适用于规模大且复杂的项目，维护和开发难度都会提升。

分布式是指将独立工作的计算机通过网络连接等方式进行协作，共同向外提供服务，共同完成任务，用户角度来看是一个单一的系统，提供高可用性和高性能，适用于高并发高可用环境。
分布式的出现是为了解决单机系统的性能瓶颈和可靠性问题。

微服务是一种架构，强调根据业务特点划分系统，分布式是系统设计方案，旨在提高系统的可用性可靠性。
微服务通常运行在分布式系统上，每个微服务可能部署在不同节点，依赖分布式系统的特性

## 旧服务改造
旧服务（通常是单体架构或遗留系统）改造为微服务架构需要系统性规划，以下是关键步骤和注意事项：
评估：
- 分析现有系统的架构、代码结构、依赖关系和技术栈。
- 识别业务功能模块，确定哪些部分适合拆分为微服务。
- 评估当前系统的性能瓶颈、耦合度、维护成本等。

逐步拆分策略：
- **“绞杀者模式”（Strangler Pattern）**：逐步将单体系统的功能替换为微服务，逐步“绞杀”旧系统。
    - 选择低风险、独立的模块开始拆分（如报表、通知服务）。
    - 通过API网关或代理将新服务与旧系统集成，确保功能逐步迁移。
- **并行运行**：新微服务与旧系统并行运行，逐步切换流量到新服务。
- **数据分离**：将数据库按业务领域拆分，避免共享数据库导致耦合。

## 服务划分
服务划分是微服务设计的核心，直接影响系统的可维护性、可扩展性和性能。
划分原则：
- **单一职责原则（SRP）**：每个微服务应只负责一个明确的业务功能。
- **领域驱动设计（DDD）**：基于业务领域划分服务，识别“界限上下文”（Bounded Context），每个上下文对应一个微服务。
- **高内聚、低耦合**：服务内部功能高度相关，对外依赖最小化。
- **数据独立性**：每个服务拥有自己的数据库，避免跨服务共享数据库。
- **业务价值导向**：优先划分对业务价值高、变更频繁的模块。

划分方法：
- **按业务能力划分**：根据业务功能（如订单、支付、库存）拆分服务。
- **按用例划分**：根据用户场景（如用户注册、商品浏览）划分。
- **按变更频率划分**：将经常变更的功能独立为服务，减少频繁部署对其他模块的影响。
- **按团队组织划分**：根据康威定律（Conway's Law），按团队职责划分服务，减少跨团队协作成本。

## 服务分层与治理
微服务架构通常采用分层设计，便于管理和扩展：
1. 接入层：提供统一的入口，处理请求路由、认证授权、限流、负载均衡等。
2. 业务服务层：核心微服务，按业务领域划分，处理具体业务逻辑。
3. 基础服务层：提供通用功能，如配置中心（Apollo、Nacos）、服务注册与发现（Eureka、Consul）、日志收集、监控等。
4. 数据层：每个服务拥有独立的数据库，支持多样的存储方案（SQL、NoSQL）。
5. 基础设施层：包括容器化（Docker）、编排（Kubernetes）、CI/CD管道等。

服务治理确保微服务系统的高可用性、可观测性和可维护性：服务注册与发现、负载均衡、服务监控与可观测性、容错与降级、配置管理、安全性、自动化运维

## CAP理论？
CAP理论是分布式系统设计的基础理论，包含一致性(Consistency)、可用性(Availability)和分区容错性(Partition tolerance)。在网络分区发生时，系统只能在一致性和可用性之间选择其一

**AP 模式**和 **CP 模式**是分布式系统设计中基于 **CAP 定理** 的两种一致性模型。CAP 定理指出，一个分布式系统无法同时完全满足以下三个属性：
- **C（Consistency，一致性）**：所有节点在同一时间看到的数据是一致的。
- **A（Availability，可用性）**：系统始终能够响应客户端请求，即使部分节点故障。
- **P（Partition Tolerance，分区容忍性）**：系统能够在网络分区（节点间通信中断）的情况下继续运行。
由于网络分区（P）在分布式系统中几乎不可避免，系统设计通常需要在 **一致性（C）** 和 **可用性（A）** 之间做出权衡，从而衍生出 **AP 模式**和 **CP 模式**。
AP：在网络分区发生时，优先保证系统的 **可用性**，即系统能够继续响应请求，即使数据可能不完全一致。
CP：在网络分区发生时，优先保证数据的 **一致性**，即所有节点的数据必须保持一致，即使这可能导致系统暂时不可用。

## 为什么分布式系统中无法同时保证可用性和一致性？
在分布式系统中，分区容错性是不可避免的要发生的，我们通常需要在一致性和可用性之间做出选择。如果系统优先保证一致性，可能需要牺牲可用性，反之亦然。
保证一致性可能要阻塞请求确保服务数据一致，保证可用性允许临时的不一致快速返回，两者是相反的。

## Base理论？
BASE理论是分布式系统设计中对CAP理论中AP方案的延伸，强调通过基本可用、软状态和最终一致性来实现系统设计。
基本可用指系统即使出现部分故障，但是系统仍然是能够提供服务的。
软状态指系统的状态间存在短暂的不一致
最终一致性指系统在一定时间后一定会达到一致状态，但是不保证实时一致

## 微服务组件
微服务组件一般包含：API网关、服务注册发现、服务间通信、负载均衡、服务熔断保护

在早期，Spring Cloud的五大组件通常指的是：
- **Eureka**：服务注册中心
- **Ribbon**：客户端负载均衡器
- **Feign**：声明式的服务调用
- **Hystrix**：服务熔断器
- **Zuul/Gateway**：API网关

随着Spring Cloud Alibaba的兴起，我们项目中也融入了一些阿里巴巴的技术组件：
- 服务注册与配置中心：Nacos
- 负载均衡：Ribbon
- 服务调用：Feign
- 服务保护：Sentinel
- API网关：Gateway

## 服务注册和发现是什么意思？SpringCloud如何实现服务注册发现？
服务注册与发现主要包含三个核心功能：服务注册、服务发现和服务状态监控。

服务注册与发现可以使用Eureka/nacos
- **服务注册**：服务提供者将自己的信息（如服务名称、IP、端口等）注册到Eureka/nacos。
- **服务发现**：消费者从Eureka/nacos获取服务列表信息，并利用负载均衡算法选择一个服务进行调用。
- **服务监控**：服务提供者定期向Eureka/nacos发送心跳以报告健康状态；如果Eureka/nacos在一定时间内未接收到心跳，将服务实例从注册中心剔除。

## Eureka
Eureka 是 Netflix 开源的服务注册与发现组件，基于REST，常用于微服务架构中。
核心功能：
- 服务注册：微服务启动后向Eureka 服务端发送自己的注册信息（ip、端口等）
- 服务发现：客户端通过Eureka服务端获取服务可用的实例列表
- 负载均衡：与Ribbon等负载均衡组件结合，选择合适的实例
Eureka架构分为两个部分：
- 注册中心，也就是Eureka服务，负责提供注册和发现功能
- 客户端，又服务提供方和服务消费方
通过 AP 模型（最终一致性）保证高可用性
## Nacos
Nacos 是阿里巴巴开源的一款动态服务注册与发现、配置管理和服务管理平台，广泛应用于微服务架构中。
Nacos核心功能：
- 服务注册与发现：支持微服务动态注册、发现和负载均衡
- 动态配置管理：提供集中化的配置管理，支持动态更新配置，无需重启服务
- 服务管理：包括服务健康检查、流量管理、动态DNS等功能
Nacos架构分为：Nacos服务端（提供Nacos的核心服务）、Nacos客户端（注册的服务）、数据库（Nacos 默认使用内置数据库（Derby）存储数据，也支持 MySQL、PostgreSQL 等外部数据库。）、控制台
支持AP/CP两种模型切换，持久化实例使用CP，保证数据的强一致性，临时实例使用AP，保证高可用

在 Nacos 中，服务实例根据其注册方式和健康检查策略被分为 **临时实例**（Temporary Instance）和 **非临时实例（持久化实例）**（Persistent Instance）。这两种实例的主要区别在于它们的生命周期管理和健康检查机制。
- 临时实例是通过客户端主动注册到 Nacos 的服务实例，通常使用心跳机制来报告健康状态。
- 非临时实例是通过服务端持久化注册的服务实例，通常由 Nacos 服务端主动进行健康检查。

## Eureka和Nacos的区别？
在使用Nacos作为注册中心的项目中，我注意到Nacos与Eureka的共同点和区别：
- **共同点**：两者都支持服务注册与发现，以及心跳检测作为健康检查机制。
- **区别**：
    - Nacos支持服务端主动检测服务提供者状态，而Eureka依赖客户端自主心跳。
    - Nacos将客户端分为临时实例和非临时实例，采用不同的健康检查策略。
    - Nacos支持配置管理，配置实时变化
    - Nacos集群默认采用AP模式，但在存在非临时实例时，会采用CP模式；而Eureka始终采用AP模式。

## Ribbon
Ribbon 是一个客户端负载均衡器，通常用于注册中心服务方，在获取服务对应的实例列表，根据负载均衡算法选择具体实例提供服务。
核心功能：
- 负载均衡：在多个服务实例间分配请求，优化资源利用和性能。
核心组件：
- ServerList：服务对应的实例列表
- ServerListFilter：过滤可用实例列表
- IRule：负载均衡策略，默认的有轮询、权重、随机等
- IPing：检查服务实例状态，确保只选择可用实例
- LoadBalancer：核心组件，协调ServerList、ServerListFilter、IRule，执行负载均衡逻辑

负载均衡的核心流程：
1. 通过客户端向注册中心拉取服务实例列表
2. 使用ServerListFilter过滤可用实例列表
3. 根据负载均衡策略选择目标实例
4. 通过HTTP请求发送目标实例处理业务
5. 通过IPing定期检查实例状态


## Spring Cloud LoadBalancer
Spring Cloud LoadBalancer 是一个客户端负载均衡器，运行在服务消费者端，负责从服务注册中心（如 Nacos、Eureka）获取目标服务的实例列表，并根据负载均衡策略选择合适的实例进行请求分发。它是 Spring Cloud 2020.0.0 版本引入的 Ribbon 替代品，旨在提供更轻量、更现代化的负载均衡方案。
核心作用：
- **负载均衡**：在多个服务实例间分配请求，优化性能和资源利用。
- **动态服务发现**：与服务注册中心集成，感知实例的上下线。
- **容错支持**：通过健康检查和重试机制，确保请求分发到可用实例。
- **Spring Cloud 生态集成**：与 RestTemplate、WebClient 和 OpenFeign 无缝协作。
Spring Cloud LoadBalancer架构：
- ServiceInstanceListSupplier：负责从服务注册中心（如 Nacos、Eureka）获取目标服务的实例列表。
- LoadBalancerClinet：核心接口，协调实例选择和请求分发
- LoadBalancerStrategy：负载均衡策略，决定如何从实例列表中选择目标实例。
- HealthCheck：提供健康检查
- LoadBalancerCache：缓存实例列表

使用建议：
- **Spring Cloud LoadBalancer**：适合新项目或 Spring Boot 2.4+ 项目，追求轻量和现代化。
- **Ribbon**：适合现有 Spring Cloud 项目，依赖 Eureka 或需要复杂策略。

## 项目中的负载均衡是如何实现的？

当客户端想调用一个服务，先通过Nacos服务端获取服务的实例列表，过滤出可用的服务列表，通过负载均衡算法筛选出目标实例，通过HTTP请求向实例发送处理请求，等待处理完HTTP请求，通过IPing更新可用实例，客户端会缓存实例列表，减少对注册中心的频繁查询。可以通过Ribbon或者Spring Cloud LoadBalancer实现


## Ribbon的负载均衡策略？
Ribbon提供了多种负载均衡策略，包括：
- **RoundRobinRule**：简单的轮询策略。
- **WeightedResponseTimeRule**：根据响应时间加权选择服务器。
- **RandomRule**：随机选择服务器。
- **ZoneAvoidanceRule**：区域感知的负载均衡，优先选择同一区域中可用的服务器
- BestAvailableRule：选择当前连接数最少的实例。



## Ribbon自定义负载均衡规则如何实现？
Ribbon自定义Ribbon负载均衡策略有两种方式：
1. 创建一个类实现IRule接口，这将定义全局的负载均衡策略。
2. 在客户端配置文件中指定特定服务调用的负载均衡策略，这将仅对该服务生效。

## RestTemplate
RestTemplate 是 Spring 框架提供的同步 HTTP 客户端，用于简化与 RESTful 服务交互。
**替代方案**：
- **WebClient**：Spring 5 引入的非阻塞、响应式 HTTP 客户端，适合现代响应式应用。
- **OpenFeign**：声明式 HTTP 客户端，简化服务调用，集成负载均衡。


## WebClient
WebClient 是 Spring WebFlux 模块提供的响应式 HTTP 客户端，用于发起 HTTP 请求（如 GET、POST、PUT、DELETE）并处理响应。它基于 Netty（默认）或其他非阻塞 HTTP 客户端，支持异步调用，适合高并发、响应式微服务架构。WebClient 与 RestTemplate 的主要区别在于其非阻塞性、响应式编程模型和现代化设计。

## Feign？OpenFeign？
Feign 是 Netflix 开发的一个声明式 HTTP 客户端库，最初用于简化 REST API 调用。通过定义 Java 接口和注解（如 @RequestLine），开发者可以像调用本地方法一样发起 HTTP 请求。
OpenFeign 是 Spring Cloud 对 Feign 的封装和增强，专门为 Spring 生态设计。它继承了 Feign 的声明式调用风格，并深度集成了 Spring Boot、Spring Cloud 的功能（如服务发现、负载均衡、配置管理）。

核心功能：
- 声明式调用
- 服务发现集成，与 Nacos、Eureka 等注册中心结合，通过服务名调用
- 集成负载均衡，默认集成 Spring Cloud LoadBalancer 或 Ribbon，自动选择目标实例。
- 序列化和反序列化，自动处理 JSON、XML 等格式（依赖 Jackson 等）。
- 请求定制，支持请求头、查询参数、请求体配置。
- 支持异步处理，OpenFeign 支持异步调用（通过 FeignAsyncClient 或响应式包装）。
- 支持日志与监控，支持配置日志级别，记录请求和响应细节。

## 什么是服务雪崩？怎么解决？

服务雪崩是指一个服务的失败导致整个链路的服务相继失败。我们通常通过**服务降级和服务熔断**来解决这个问题：
- **服务降级**：降低服务的可用性，是指在系统资源紧张、某些服务不可用或响应缓慢时，主动降低某些非核心功能的可用性，以保证核心功能的正常运行。降级的目的是通过牺牲部分功能或服务质量来维持系统的整体稳定性。
- **服务熔断**：断开服务调用，一种保护机制，当某个服务频繁失败或不可用时，暂时“熔断”对该服务的调用，快速返回错误或降级结果，避免系统因持续调用失败服务而雪崩。熔断机制类似于电路中的保险丝，触发后会暂停调用，直到服务恢复。

服务降级的例子：
- 在电商系统中，商品详情页的推荐服务超时，系统直接返回空推荐列表或静态推荐数据，而不影响商品信息展示。
- 在高并发场景下，关闭实时日志记录功能，只保留核心的订单处理逻辑。
服务熔断例子：
- 在电商系统中，库存服务连续超时 10 次，熔断器触发，接下来的请求直接返回“库存服务不可用”，避免进一步调用导致系统压力增加。
- 熔断一段时间后，熔断器尝试放行少量请求，如果库存服务恢复正常，则恢复调用。

## Hystric
Hystrix 是一个基于 Java 的断路器库，设计目标是处理分布式系统中的延迟和故障问题。
核心功能：
- **服务隔离**：将服务调用隔离到线程池或信号量，防止单一服务故障影响整个系统。
- **服务熔断**：当服务调用失败率超过阈值时，断路器“打开”，暂停调用并返回降级响应。
- **服务降级**：提供备用逻辑（如默认值、缓存）确保系统在故障时仍可运行。
- **实时监控**：提供仪表盘（Hystrix Dashboard）和指标收集，监控服务调用状态。

Hystrix中的核心概念：
- 熔断器：监控服务调用的失败率，包含状态：关闭、打开、半打开
- 服务隔离：线程池隔离，每个服务使用单独的线程池；信号量隔离，适合高并发场景。

Hystrix现已进入维护阶段。推荐使用Sentinel
## Sentinel
Sentinel 是一个面向分布式系统的流量治理框架，专注于服务容错和流量管理。它通过监控服务调用的流量、延迟、异常等指标，动态调整请求分发，防止系统过载或故障扩散。Sentinel 提供实时监控、动态规则配置和强大的扩展性，特别适合与 Nacos 结合，用于微服务架构中的高可用性保障。

核心作用：
- 流量控制：控制请求速率
- 服务熔断：服务调用失败暂停
- 服务降级：使用服务的备用逻辑
- 系统保护：监控系统整体负载
- 实时监控：提供控制台和 API，实时查看流量和故障指标。

相比 Hystrix（维护模式）和 Resilience4j（轻量但无控制台），Sentinel 提供更全面的功能和直观的 Dashboard，是阿里巴巴生态的首选。

## 微服务如何监控的？
我们项目中采用了**SkyWalking**进行微服务监控：
1. SkyWalking能够监控接口、服务和物理实例的状态，帮助我们识别和优化慢服务。
2. 我们还设置了告警规则，一旦检测到异常，系统会通过短信或邮件通知相关负责人。


**Apache SkyWalking** 是一个开源的 **应用性能监控（APM，Application Performance Monitoring）** 和 **分布式追踪系统**，专为微服务、云原生和容器化架构（如 Docker、Kubernetes）设计。
它通过收集、分析和可视化分布式系统中的指标、追踪和日志数据，帮助开发者和运维人员监控服务性能、定位问题并优化系统。

## Spring Cloud Gateway
Spring Cloud Gateway 是一个现代化的 API 网关，旨在为微服务提供统一的入口点。它通过路由规则将客户端请求转发到后端服务，支持动态服务发现、过滤器链处理（如认证、限流）和高性能的非阻塞 I/O。基于 Spring WebFlux，Spring Cloud Gateway 利用 Reactor 的响应式模型，适合高并发场景。
核心功能：
- 路由转发：根据请求路径、主机、查询参数等，将请求路由到目标服务。
- 服务发现：与 Nacos、Eureka 集成，动态获取服务实例并进行负载均衡。
- 过滤器：提供全局和路由级别的过滤器，处理认证、限流、日志等。
- 高性能：基于 Netty 和响应式编程，适合高并发环境。
- 扩展性：支持自定义路由、过滤器和断言
SpringCloudGateway核心组件：
- 路由Route：定义请求如何映射到目标主机
- 断言Predicate：判断请求是否匹配路由规则的条件
- 过滤器：处理请求或响应的逻辑，支持前置（Pre）和后置（Post）处理。
- GatewayFilterFactory过滤器工厂
- RouteLocator路由定义，支持YAML格式定义



## 你们项目中有没有做过限流？怎么做的？
在我们的项目中，由于面临可能的突发流量，我们采用了限流策略：
- **版本1**：使用**Nginx**进行限流，通过漏桶算法控制请求处理速率，按照IP进行限流。
- **版本2**：使用**Spring Cloud Gateway**的**RequestRateLimiter**过滤器进行限流，采用令牌桶算法，可以基于IP或路径进行限流。

Nginx 是一个高性能的 Web 服务器和反向代理，内置了强大的限流模块（如 ngx_http_limit_req_module），可以有效控制请求速率，防止突发流量压垮后端服务。
漏桶算法（Leaky Bucket Algorithm）是一种流量控制算法，形象地比喻为一个底部有孔的桶，水（请求）以任意速率流入，但以固定速率流出。

Spring Cloud Gateway 是一个基于 Spring 的 API 网关，支持动态路由、过滤和限流。RequestRateLimiter 是 Spring Cloud Gateway 提供的内置过滤器，用于限制请求速率，通常基于 **Redis** 存储限流状态，支持令牌桶算法。
令牌桶算法（Token Bucket Algorithm）是一种流量控制算法，允许以固定速率处理请求，同时支持一定程度的突发流量。

Spring Cloud Gateway 可以通过多种方式实现限流（Rate Limiting），以保护后端服务免受过载或恶意请求的影响。Spring Cloud Gateway 内置了基于 Redis 的限流过滤器，并支持与外部工具（如 Sentinel、Resilience4j）集成来实现更复杂的限流策略。
Spring Cloud Gateway 提供以下主要限流方式：
1. **内置 Redis 限流器**：基于 Redis 的令牌桶算法，简单易用。
2. **Sentinel 限流**：与 Alibaba Sentinel 集成，支持复杂限流规则和动态配置。
3. **自定义限流过滤器**：基于 GatewayFilter 实现自定义逻辑。
4. **Resilience4j 限流**：结合 Resilience4j 的 RateLimiter 实现。
内置Redis限流器实现：Spring Cloud Gateway 提供 RequestRateLimiter 过滤器，基于 Redis 和令牌桶算法实现限流。令牌桶算法通过控制令牌生成速率和容量，限制请求频率。



## 限流常用的算法有哪些？
常见的限流算法包括：
- **漏桶算法**：以固定速率处理请求，平滑突发流量。
- **令牌桶算法**：按照一定速率生成令牌，请求在获得令牌后才被处理，适用于请求量有波动的场景。


## Seata
Seata 是一个分布式事务框架，用于在微服务架构中确保数据一致性。它通过全局事务管理器协调多个服务的事务操作，支持跨数据库、跨服务的分布式事务，提供 ACID（原子性、一致性、隔离性、持久性）保证。
核心功能：
- **分布式事务管理**：协调多个微服务的事务，确保全局一致性。
- **多种事务模式**：支持 AT（自动事务）、TCC（Try-Confirm-Cancel）、SAGA 和 XA 模式。
- **高性能**：基于日志和轻量级协调机制，降低性能开销。
- **生态集成**：与 Spring Cloud、Nacos、Dubbo 等无缝集成。
Seata 的分布式事务模型基于全局事务和分支事务，核心概念包括：
1. 全局事务：由业务发起的一个分布式事务，包含多个分支事务
2. 分支事务：全局事务中的每个本地事务
3. 事务协调器TC：Seata Server，负责协调全局事务的提交或回滚。
4. 事务管理器TM：发起全局事务的角色，通常是业务服务。
5. 资源管理器RM：管理分支事务的角色，通常是数据库操作客户端。
6. 事务模式：
	- AT：自动模式，基于 undo_log 实现，类似 XA 的两阶段提交，适合大多数场景。
	- TCC：手动模式，需实现 Try、Confirm、Cancel 逻辑，适合高性能场景。
	- SAGA：长事务模式，基于状态机，适合复杂业务流程。
	- XA：基于数据库 XA 协议，性能较低但支持广泛。
7. undo_log：AT 模式下用于存储数据快照，记录事务前后的状态，用于回滚。

工作原理：Seata 采用两阶段提交（2PC）思想，分为 准备阶段（Phase 1） 和 提交/回滚阶段（Phase 2）：
AT事务模式原理：
1. 准备阶段，TM发起全局事务，RM执行分支事务，RM注册分支事务，TC收集所有分支事务状态
2. 提交/回滚阶段，如果所有分支事务成功，TC 通知各 RM 提交本地事务（删除 undo_log）。如果分支事务失败，TC通知RM根据undo_log回滚数据

TCC事务模式原理：
1. Try阶段：各服务执行Try操作，TM向TC注册全局事务，RM报告Try状态
2. 提交/回滚阶段：如果Try都成功，TC通知RM执行确认资源操作；如果任一Try失败，TC通知各RM释放资源

## 采用哪种分布式事务解决方案？

可以采用Seata作为分布式事务的解决方案，可以选用AT模式或者TCC模式



## 分布式服务接口的幂等性如何设计？
可以通过Token和**Redis**来实现接口幂等性。
用户操作时，根据请求生成唯一Token，存储在Redis中，当用户提交操作时，系统会验证Token的存在性，并在验证通过后删除Token，确保每个Token只被处理一次。


## xxl-job路由策略有哪些？
XXL-Job 的路由策略决定了调度中心如何选择执行器（Executor）来执行任务
路由策略一般有：
- First首个：固定选择执行器中的第一台机器
- Last末尾
- Round轮询
- Random随机
- LFU最少使用
- LRU最近最少使用
- 分片广播：任务广播到集群中所有执行器，每台执行器根据分片参数（shardIndex 和 shardTotal）处理部分数据。

XXL-JOB 是一个开源的分布式任务调度平台，核心设计目标是 **开发迅速、学习简单、轻量级、易扩展**。
## xxl-job任务执行失败怎么解决？
任务执行失败可能由调度中心、执行器或业务逻辑问题引起。
面对任务执行失败，我们可以：
1. 选择故障转移路由策略，优先使用健康的实例执行任务。
2. 设置任务重试次数。
3. 通过日志记录和邮件告警通知相关负责人。


## XXL-JOB解决：如果有大数据量的任务同时执行，怎么解决？
我们可以通过部署多个实例并使用分片广播路由策略来分散任务负载。在任务执行代码中，根据分片信息和总数对任务进行分散处理。